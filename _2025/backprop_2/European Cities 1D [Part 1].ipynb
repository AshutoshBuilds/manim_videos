{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43d6531-a496-442a-ba46-dd3dd28c3e15",
   "metadata": {},
   "source": [
    "## European Cities 1D [Part 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeea083a-de2d-4f90-b2b9-7f5cb342315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "paris_coords = np.array([\n",
    "    [48.8575, 2.3514], #Center of Paris\n",
    "    [48.8584, 2.2945], # Eiffel Tower\n",
    "    [48.8530, 2.3499], #Notre Dame\n",
    "    [48.8606,  2.3376], #Louvre\n",
    "    [48.8606, 2.3522]  #Centre Pompidou\n",
    "])\n",
    "\n",
    "madrid_coords = np.array([\n",
    "    [40.4167, -3.7033],   # Center of Madrid\n",
    "    [40.4153, -3.6835],   # Retiro Park \n",
    "    [40.4180, -3.7143],   # Royal Palace \n",
    "    [40.4138, -3.6921],   # Prado Museum \n",
    "    [40.4169, -3.7033]   # Puerta del Sol \n",
    "])\n",
    "\n",
    "berlin_coords = np.array([\n",
    "    [52.5200, 13.4050], # Center of Berlin\n",
    "    [52.5163, 13.3777],   # Brandenburg Gate \n",
    "    [52.5169, 13.4019],   # Museum Island \n",
    "    [52.5074, 13.3904],   # Checkpoint Charlie \n",
    "    [52.5251, 13.3694]   # Berlin Central Station \n",
    "])\n",
    "\n",
    "colors=['c', 'y', 'm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d0126-86dc-4878-acdb-1dbfe0c9a3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ec18db-8745-4efb-882b-bb94cd62c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random_seed=52\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f7781c4-68c6-4e52-826a-52063002f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (15, 1)\n",
      "Shape of y: (15,)\n"
     ]
    }
   ],
   "source": [
    "# Combine data into one matrix X and labels y\n",
    "X_raw = np.vstack([madrid_coords, paris_coords, berlin_coords]) #, brussels_coords, vienna_coords])\n",
    "y = np.array([0, 0, 0, 0, 0,  #  Madrid labels (0)\n",
    "              1, 1, 1, 1, 1,  #  Paris labels (1)\n",
    "              2, 2, 2, 2, 2]) #, # Berlin labels (2)\n",
    "              #3, 3, 3, 3, 3, 3, 3, \n",
    "              #4, 4, 4, 4, 4, 4, 4]) \n",
    "\n",
    "# Let's use only longitude as input for the simple model\n",
    "X_lon = X_raw[:, 1].reshape(-1, 1)  # Extract longitude and reshape to column vector\n",
    "\n",
    "# Normalize data (simple scaling by dividing by 100, I guess I could do 10)\n",
    "X = X_lon # / 100 - Simple longitude only problem does not seem to require normalization, that's interesting!\n",
    "\n",
    "# Alternative normalization (uncomment to use)\n",
    "# mean = np.mean(X_lon)\n",
    "# std = np.std(X_lon)\n",
    "# X = (X_lon - mean) / std\n",
    "\n",
    "rI=np.arange(len(y))\n",
    "np.random.shuffle(rI)\n",
    "X=X[rI,:]\n",
    "y=y[rI]\n",
    "X_raw=X_raw[rI,:]\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d81d0a-a31e-409d-9f9f-3085a0e75aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyGPSModel(nn.Module):\n",
    "    def __init__(self, input_size=1, output_size=3):\n",
    "        super(TinyGPSModel, self).__init__()\n",
    "        self.output = nn.Linear(input_size, output_size) #, bias=False)  # 3 cities\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e9da523-dd7a-4316-8424-fe5ef72f05b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = TinyGPSModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "#I can manually initialize and still learns real good? yeah seems like it!\n",
    "with torch.no_grad():\n",
    "    model.output.weight[0,0]=1.0\n",
    "    model.output.weight[1,0]=0.0\n",
    "    model.output.weight[2,0]=-1.0\n",
    "    model.output.bias[0]=0\n",
    "    model.output.bias[1]=0\n",
    "    model.output.bias[2]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b503b219-18f2-484b-bb34-ffdebc0ff401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.3514,  0.0000, -2.3514])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits=model(torch.tensor([2.3514])).detach() #Center of Paris\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9dded99-9063-4eca-ba9c-aa2372e7c630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9055, 0.0862, 0.0082])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Softmax(0)(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a47156ff-bd45-45d4-9fbf-28833ae5dde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4510851013124895"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(0.0862)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c2c773-7c47-413b-b440-c762b8f1281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.output.weight[0,0]=1.0\n",
    "    model.output.weight[1,0]=0.1\n",
    "    model.output.weight[2,0]=-1.0\n",
    "    model.output.bias[0]=0\n",
    "    model.output.bias[1]=0\n",
    "    model.output.bias[2]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bab1d40c-fb12-41ae-8de5-fa57c7c07535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.3514,  0.2351, -2.3514])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits=model(torch.tensor([2.3514])).detach() #Center of Paris\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d168c6f0-ce52-4d89-946a-daa8ca804874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8853, 0.1067, 0.0080])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Softmax(0)(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cd31e08-fdce-45bb-bbe7-5eb60e1ea126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = TinyGPSModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "#I can manually initialize and still learns real good? yeah seems like it!\n",
    "with torch.no_grad():\n",
    "    model.output.weight[0,0]=1.0\n",
    "    model.output.weight[1,0]=0.0\n",
    "    model.output.weight[2,0]=-1.0\n",
    "    model.output.bias[0]=0\n",
    "    model.output.bias[1]=0\n",
    "    model.output.bias[2]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "449103d9-ed20-45cb-b6e6-96ade52f9f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.3514])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=14 #Center of Paris\n",
    "X[i%len(y)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "444c248a-7733-46c3-bdf0-15821eab5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(torch.tensor(X[i%len(y)]).float())\n",
    "loss = criterion(outputs, torch.tensor(y[i%len(y)])) \n",
    "loss.backward()  # backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ed1ba83-9af7-4d00-ad73-1bb32ef4c859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1293],\n",
       "        [-2.1486],\n",
       "        [ 0.0193]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "873c68ba-f9ca-4f65-9494-cc9912c71d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9055, -0.9138,  0.0082])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e1b23ee-ccc2-4875-b8b9-19e8b6ed4ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.14944036"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.0862-1)*2.3522"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485be6e-4c6e-479f-9c39-927fa6dc5768",
   "metadata": {},
   "source": [
    "## Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a378c903-2e8b-4c6e-a214-97ef0df1d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Where to save training heatmaps\n",
    "save_dir='/Users/stephen/Stephencwelch Dropbox/Stephen Welch/welch_labs/backprop2/graphics/to_manim/may_27_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41c26f7f-3bf6-4546-b3cd-69cdd703f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Swaggin - need to sync with Sam on exact numbers\n",
    "min_long=-7.0\n",
    "max_long=18.0\n",
    "min_lat=36.0\n",
    "max_lat=56.0\n",
    "num_steps=256\n",
    "heatmap_viz_logit_multiplier=8 #Makes things more winner take all for cleaner logit viz\n",
    "heatmaps=[np.zeros((num_steps, num_steps)) for i in range(6)]\n",
    "\n",
    "for i, lat in enumerate(np.linspace(max_lat, min_lat, num_steps)):\n",
    "    for j, long in enumerate(np.linspace(min_long, max_long, num_steps)):\n",
    "        with torch.no_grad():\n",
    "            logits=model(torch.tensor([long], dtype=torch.float)).detach()\n",
    "            yhat=torch.nn.Softmax(0)(heatmap_viz_logit_multiplier*logits).numpy()\n",
    "\n",
    "        for k in range(3):\n",
    "            heatmaps[k][i,j]=logits.numpy()[k]\n",
    "            heatmaps[k+3][i,j]=yhat[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d35a126-1878-443e-acf8-5a780f9d3a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmaps[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "940baa10-41a4-47f8-8ae8-5f37fde2d962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16a5e5a90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa8AAAGiCAYAAABQ9UnfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAh6UlEQVR4nO3dfWxUVeL/8c+daTvUpjSU2pmOlKYxkN21DYnFBRqV52J/ARYxATXZQEKMLg9JU4gR+cO6MdSQCCawstlvCI+y5R9QE4laAlRJQ4JdjMAaghGlbDrbyNY+YHcK9Pz+mPZ2bjstFFq6p32/khvPPU/33MNdPjuda3WMMUYAAFjEN9ILAABgsAgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdUY0vD744APl5+dr3LhxKioq0ldffTWSywEAWGLEwuvIkSMqKyvTli1bdP78eT3zzDMqLS3VtWvXRmpJAABLOCP1i3lnzJihJ598Urt373brfvvb32rZsmWqrKwciSUBACyRNBIX7ejoUF1dnd544w1PfUlJiWpra/v0j0ajikaj7nlnZ6f+85//aOLEiXIcZ9jXCwAYWsYYtba2KhwOy+cb/A8BRyS8fv75Z925c0fBYNBTHwwGFYlE+vSvrKzU22+//bCWBwB4SOrr6zVp0qRBjxuR8OrW+1OTMSbhJ6nNmzervLzcPW9ubtbkyZP1tP6fkpyUrsl8cnyO5HQluM+RO5XPJ/fE54tdw+e449w2p/d4J26c4+3nix/TUza9zvsbb9x6bz/jOD3fRDrqqe+awx0X3xZXlk+ePrH1qKefL26M4scr8Rif4sb3msvpnqf7nuLXHTef+pk7rl9/ZfcaCfs5A1wnwRwJyv3ej/q29RnfZz7j6ddnfPd53Nz9jU88xvSZOzY+QX3C9SQab2KPTlybo7hyfD9JjtvPeNvcR9v0evyNOyb2+Jm4frGyz+mZ1yfT7xifZ4zpqe8a0zO3PG0+p9MzxtvWPV+nfEpc73eM+z9Jn9MZN77Tsza/eq7jj58vruyPG++PW5tfRo7T6Z2jqxybq7tsYutTzzh/9/2p0y37ZeTEjffH3ZNfsfM+a/P0iV3HH3fe/cftj/sryi/J7zhx5477d7hfjnxdLbE+Pvm6ZvE7PrW0dSrvyR+Vnp6u+zEi4ZWVlSW/39/nU1ZjY2OfT2OSFAgEFAgE+tQnKVlJTnLsxOkKpe7wcXo20RtQ3f3i2jxB1F949Qq5/sKrd8g9UHjF12vow8szXonH3Gd49V/uO8dA5UGFVz9jhiW8+gmfgeZ+oPDqN3yGIbw85bh+ShxeTp9yT4gMOrycXkEUN+Zew6tvQN1bePkHqPcEUVwI3Et49SnHBUzv8r2EV+y6jjvO31X2yXHLsfDpKjtOr2spLrx6yncLLzegnIHDq2dtA4dXt/v96mdE3jZMSUlRUVGRqqurPfXV1dUqLi4eiSUBACwyYj82LC8v1x//+EdNnz5ds2bN0t/+9jddu3ZNr7322kgtCQBgiRELr5UrV+rGjRv685//rIaGBhUUFOj48ePKy8sbqSUBACwxoi9srF27VmvXrh3JJQAALMTvNgQAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWIfwAgBYh/ACAFiH8AIAWGfIw6uiokKO43iOUCjkthtjVFFRoXA4rNTUVM2ZM0eXLl0a6mUAAEaxYfnk9cQTT6ihocE9Lly44LZt27ZN27dv165du3Tu3DmFQiEtXLhQra2tw7EUAMAoNCzhlZSUpFAo5B6PPvqopNinrvfff19btmzR8uXLVVBQoP379+vXX3/V4cOHh2MpAIBRaFjC68qVKwqHw8rPz9eLL76oH374QZJ09epVRSIRlZSUuH0DgYBmz56t2tra4VgKAGAUShrqCWfMmKEDBw5o6tSp+ve//6133nlHxcXFunTpkiKRiCQpGAx6xgSDQf3000/9zhmNRhWNRt3zlpaWoV42AMAiQx5epaWlbrmwsFCzZs3S448/rv3792vmzJmSJMdxPGOMMX3q4lVWVurtt98e6qUCACw17K/Kp6WlqbCwUFeuXHHfOuz+BNatsbGxz6exeJs3b1Zzc7N71NfXD+uaAQD/24Y9vKLRqL777jvl5OQoPz9foVBI1dXVbntHR4dqampUXFzc7xyBQEDjx4/3HACAsWvIf2y4adMmLVmyRJMnT1ZjY6PeeecdtbS0aNWqVXIcR2VlZdq6daumTJmiKVOmaOvWrXrkkUf08ssvD/VSAACj1JCH1/Xr1/XSSy/p559/1qOPPqqZM2fq7NmzysvLkyS9/vrram9v19q1a9XU1KQZM2boiy++UHp6+lAvBQAwSg15eFVVVQ3Y7jiOKioqVFFRMdSXBgCMEfxuQwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQgvAIB1CC8AgHUILwCAdQYdXl9++aWWLFmicDgsx3H00UcfedqNMaqoqFA4HFZqaqrmzJmjS5cuefpEo1Ft2LBBWVlZSktL09KlS3X9+vUHuhEAwNgx6PC6efOmpk2bpl27diVs37Ztm7Zv365du3bp3LlzCoVCWrhwoVpbW90+ZWVlOnbsmKqqqnTmzBm1tbVp8eLFunPnzv3fCQBgzEga7IDS0lKVlpYmbDPG6P3339eWLVu0fPlySdL+/fsVDAZ1+PBhvfrqq2pubtaePXt08OBBLViwQJJ06NAh5ebm6sSJE1q0aNED3A4AYCwY0u+8rl69qkgkopKSErcuEAho9uzZqq2tlSTV1dXp1q1bnj7hcFgFBQVuHwAABjLoT14DiUQikqRgMOipDwaD+umnn9w+KSkpmjBhQp8+3eN7i0ajikaj7nlLS8tQLhsAYJlhedvQcRzPuTGmT11vA/WprKxURkaGe+Tm5g7ZWgEA9hnS8AqFQpLU5xNUY2Oj+2ksFAqpo6NDTU1N/fbpbfPmzWpubnaP+vr6oVw2AMAyQxpe+fn5CoVCqq6udus6OjpUU1Oj4uJiSVJRUZGSk5M9fRoaGnTx4kW3T2+BQEDjx4/3HACAsWvQ33m1tbXp+++/d8+vXr2qb775RpmZmZo8ebLKysq0detWTZkyRVOmTNHWrVv1yCOP6OWXX5YkZWRkaM2aNdq4caMmTpyozMxMbdq0SYWFhe7bhwAADGTQ4fX1119r7ty57nl5ebkkadWqVdq3b59ef/11tbe3a+3atWpqatKMGTP0xRdfKD093R2zY8cOJSUlacWKFWpvb9f8+fO1b98++f3+IbglAMBo5xhjzEgvYrBaWlqUkZGhOfqDknwpsUrHJ8fnSE7XT0J9Ts8LID6fFFd2HEfyOe64nnKC8Ynm8Ix3PPXG5z3vGd+rn1vv7Wccp+eHuZ762BzuOEfetrj54vsYx4n1jZuj95hYWYnH+BQ3vtdcTtc/3XuKn6O/ct85Biq74xP2c/r2SzBmoPX0ez/q23b3uc2Ac7vn6n98v2OcrvZec8fGJ6jvNZ/6HW9ij0Fcm+Mpx/VTfJuJe5x7l01Xude5JJ/b1lPvi7umr6vel2CMzzOmp49P3jG923xOp6fe29Y9plP+Aep96jnvbvOr03NNv3qu43c63TF9yl3r8cetrbvsmaOrHBvfXTZd1+0Z5+++P3W6Zb9M3JjOXteKnbv31722uPuOjTfunsTO1TVfz19Rfkl+x4k7d+Trehj8cuTraon18cnX9eD5HZ9aWjs1YeoPam5uvq+vgvjdhgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrDDq8vvzySy1ZskThcFiO4+ijjz7ytK9evVqO43iOmTNnevpEo1Ft2LBBWVlZSktL09KlS3X9+vUHuhEAwNgx6PC6efOmpk2bpl27dvXb57nnnlNDQ4N7HD9+3NNeVlamY8eOqaqqSmfOnFFbW5sWL16sO3fuDP4OAABjTtJgB5SWlqq0tHTAPoFAQKFQKGFbc3Oz9uzZo4MHD2rBggWSpEOHDik3N1cnTpzQokWLBrskAMAYMyzfeZ0+fVrZ2dmaOnWqXnnlFTU2NrptdXV1unXrlkpKSty6cDisgoIC1dbWJpwvGo2qpaXFcwAAxq4hD6/S0lJ9+OGHOnnypN577z2dO3dO8+bNUzQalSRFIhGlpKRowoQJnnHBYFCRSCThnJWVlcrIyHCP3NzcoV42AMAig/6x4d2sXLnSLRcUFGj69OnKy8vTp59+quXLl/c7zhgjx3EStm3evFnl5eXueUtLCwEGAGPYsL8qn5OTo7y8PF25ckWSFAqF1NHRoaamJk+/xsZGBYPBhHMEAgGNHz/ecwAAxq5hD68bN26ovr5eOTk5kqSioiIlJyerurra7dPQ0KCLFy+quLh4uJcDABgFBv1jw7a2Nn3//ffu+dWrV/XNN98oMzNTmZmZqqio0AsvvKCcnBz9+OOPevPNN5WVlaXnn39ekpSRkaE1a9Zo48aNmjhxojIzM7Vp0yYVFha6bx8CADCQQYfX119/rblz57rn3d9FrVq1Srt379aFCxd04MAB/fLLL8rJydHcuXN15MgRpaenu2N27NihpKQkrVixQu3t7Zo/f7727dsnv98/BLcEABjtBh1ec+bMkTGm3/bPP//8rnOMGzdOO3fu1M6dOwd7eQAA+N2GAAD7EF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrEF4AAOsQXgAA6xBeAADrDCq8Kisr9dRTTyk9PV3Z2dlatmyZLl++7OljjFFFRYXC4bBSU1M1Z84cXbp0ydMnGo1qw4YNysrKUlpampYuXarr168/+N0AAMaEQYVXTU2N1q1bp7Nnz6q6ulq3b99WSUmJbt686fbZtm2btm/frl27duncuXMKhUJauHChWltb3T5lZWU6duyYqqqqdObMGbW1tWnx4sW6c+fO0N0ZAGDUShpM588++8xzvnfvXmVnZ6uurk7PPvusjDF6//33tWXLFi1fvlyStH//fgWDQR0+fFivvvqqmpubtWfPHh08eFALFiyQJB06dEi5ubk6ceKEFi1aNES3BgAYrR7oO6/m5mZJUmZmpiTp6tWrikQiKikpcfsEAgHNnj1btbW1kqS6ujrdunXL0yccDqugoMDt01s0GlVLS4vnAACMXfcdXsYYlZeX6+mnn1ZBQYEkKRKJSJKCwaCnbzAYdNsikYhSUlI0YcKEfvv0VllZqYyMDPfIzc2932UDAEaB+w6v9evX69tvv9Xf//73Pm2O43jOjTF96nobqM/mzZvV3NzsHvX19fe7bADAKHBf4bVhwwZ98sknOnXqlCZNmuTWh0IhSerzCaqxsdH9NBYKhdTR0aGmpqZ++/QWCAQ0fvx4zwEAGLsGFV7GGK1fv15Hjx7VyZMnlZ+f72nPz89XKBRSdXW1W9fR0aGamhoVFxdLkoqKipScnOzp09DQoIsXL7p9AAAYyKDeNly3bp0OHz6sjz/+WOnp6e4nrIyMDKWmpspxHJWVlWnr1q2aMmWKpkyZoq1bt+qRRx7Ryy+/7PZds2aNNm7cqIkTJyozM1ObNm1SYWGh+/YhAAADGVR47d69W5I0Z84cT/3evXu1evVqSdLrr7+u9vZ2rV27Vk1NTZoxY4a++OILpaenu/137NihpKQkrVixQu3t7Zo/f7727dsnv9//YHcDABgTHGOMGelFDFZLS4syMjI0R39Qki8lVun45Pgcyen6SajP6XkBxOeT4sqO40g+xx3XU04wPtEcnvGOp974vOc943v1c+u9/Yzj9Pww11Mfm8Md58jbFjdffB/jOLG+cXP0HhMrK/EYn+LG95rL6fqne0/xc/RX7jvHQGV3fMJ+Tt9+CcYMtJ5+70d92+4+txlwbvdc/Y/vd4zT1d5r7tj4BPW95lO/403sMYhrczzluH6KbzNxj3Pvsukq9zqX5HPbeup9cdf0ddX7Eozxecb09PHJO6Z3m8/p9NR727rHdMo/QL1PPefdbX51eq7pV891/E6nO6ZPuWs9/ri1dZc9c3SVY+O7y6bruj3j/N33p0637JeJG9PZ61qxc/f+utcWd9+x8cbdk9i5uubr+SvKL8nvOHHnjnxdD4NfjnxdLbE+Pvm6Hjy/41NLa6cmTP1Bzc3N9/UeA7/bEABgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgHcILAGAdwgsAYB3CCwBgnUGFV2VlpZ566imlp6crOztby5Yt0+XLlz19Vq9eLcdxPMfMmTM9faLRqDZs2KCsrCylpaVp6dKlun79+oPfDQBgTBhUeNXU1GjdunU6e/asqqurdfv2bZWUlOjmzZuefs8995waGhrc4/jx4572srIyHTt2TFVVVTpz5oza2tq0ePFi3blz58HvCAAw6iUNpvNnn33mOd+7d6+ys7NVV1enZ5991q0PBAIKhUIJ52hubtaePXt08OBBLViwQJJ06NAh5ebm6sSJE1q0aNFg7wEAMMY80Hdezc3NkqTMzExP/enTp5Wdna2pU6fqlVdeUWNjo9tWV1enW7duqaSkxK0Lh8MqKChQbW1twutEo1G1tLR4DgDA2HXf4WWMUXl5uZ5++mkVFBS49aWlpfrwww918uRJvffeezp37pzmzZunaDQqSYpEIkpJSdGECRM88wWDQUUikYTXqqysVEZGhnvk5ube77IBAKPAoH5sGG/9+vX69ttvdebMGU/9ypUr3XJBQYGmT5+uvLw8ffrpp1q+fHm/8xlj5DhOwrbNmzervLzcPW9paSHAAGAMu69PXhs2bNAnn3yiU6dOadKkSQP2zcnJUV5enq5cuSJJCoVC6ujoUFNTk6dfY2OjgsFgwjkCgYDGjx/vOQAAY9egwssYo/Xr1+vo0aM6efKk8vPz7zrmxo0bqq+vV05OjiSpqKhIycnJqq6udvs0NDTo4sWLKi4uHuTyAQBj0aB+bLhu3TodPnxYH3/8sdLT093vqDIyMpSamqq2tjZVVFTohRdeUE5Ojn788Ue9+eabysrK0vPPP+/2XbNmjTZu3KiJEycqMzNTmzZtUmFhofv2IQAAAxlUeO3evVuSNGfOHE/93r17tXr1avn9fl24cEEHDhzQL7/8opycHM2dO1dHjhxRenq623/Hjh1KSkrSihUr1N7ervnz52vfvn3y+/0PfkcAgFFvUOFljBmwPTU1VZ9//vld5xk3bpx27typnTt3DubyAABIeoC3DUdSd4je1i3JdL+h6JNjHLlf4xlH7ruLxid1nxmfHDmecersKjuO5HR/DRj71VZy34CMKztOz3yOt96YXv26y73qjVvv7WccJ1bXdUm3XpJ8cePi2+LK8snTxzhOz607sTncsuLHK/GY+K3rPVf8NjpOXLnXfOpn7rh+/ZXdayTs5wxwnQRzJCj3ez/q29ZnfJ/5jKdfn/Fxf+SJ12buMsb0mTs2PkF9wvUkGm+6HueeNkdx5fh+khy3n/G2uY+26fX4G3eMo561xtcbp2deo1h9Z9wYX1fZFzfG55ie+q4xPnduedp8TqdnjLete75O3VHier9j3JcDfE5n3PhOz9r86rmO3+mUTz1zdJf9ceP9cWvzy8hxOr1zdJVjc3WXTWx96hnn774/dbplv4ycuPH+uHvyK3beZ22ePrHr+OPOu/+4/U7PyxJ+SX7HiTt33LfG/Yqr7+rj65rF70gtbbH13e1DUX+sDK/W1lZJ0hkd7/kby0hdf1YAAEu0trYqIyNj0OMcc7+xN4I6Ozt1+fJl/e53v1N9fT2vzifQ/e/CsT+JsT93xx4NjP0Z2N32xxij1tZWhcNh+XyD/7e2rPzk5fP59Nhjj0kS/97XXbA/A2N/7o49Ghj7M7CB9ud+PnF147/nBQCwDuEFALCOteEVCAT01ltvKRAIjPRS/iexPwNjf+6OPRoY+zOw4d4fK1/YAACMbdZ+8gIAjF2EFwDAOoQXAMA6hBcAwDrWhtcHH3yg/Px8jRs3TkVFRfrqq69GekkPXUVFhRzH8RyhUMhtN8aooqJC4XBYqampmjNnji5dujSCKx5+X375pZYsWaJwOCzHcfTRRx952u9lT6LRqDZs2KCsrCylpaVp6dKlun79+kO8i+Fzt/1ZvXp1n2dq5syZnj6jeX8qKyv11FNPKT09XdnZ2Vq2bJkuX77s6TOWn6F72Z+H9QxZGV5HjhxRWVmZtmzZovPnz+uZZ55RaWmprl27NtJLe+ieeOIJNTQ0uMeFCxfctm3btmn79u3atWuXzp07p1AopIULF7q/G3I0unnzpqZNm6Zdu3YlbL+XPSkrK9OxY8dUVVWlM2fOqK2tTYsXL9adO3ce1m0Mm7vtjyQ999xznmfq+PHjnvbRvD81NTVat26dzp49q+rqat2+fVslJSW6efOm22csP0P3sj/SQ3qGjIV+//vfm9dee81T95vf/Ma88cYbI7SikfHWW2+ZadOmJWzr7Ow0oVDIvPvuu27df//7X5ORkWH++te/PqQVjixJ5tixY+75vezJL7/8YpKTk01VVZXb51//+pfx+Xzms88+e2hrfxh6748xxqxatcr84Q9/6HfMWNofY4xpbGw0kkxNTY0xhmeot977Y8zDe4as++TV0dGhuro6lZSUeOpLSkpUW1s7QqsaOVeuXFE4HFZ+fr5efPFF/fDDD5Kkq1evKhKJePYpEAho9uzZY3KfpHvbk7q6Ot26dcvTJxwOq6CgYMzs2+nTp5Wdna2pU6fqlVdeUWNjo9s21vanublZkpSZmSmJZ6i33vvT7WE8Q9aF188//6w7d+4oGAx66oPBoCKRyAitamTMmDFDBw4c0Oeff67/+7//UyQSUXFxsW7cuOHuBfvU4172JBKJKCUlRRMmTOi3z2hWWlqqDz/8UCdPntR7772nc+fOad68eYpGo5LG1v4YY1ReXq6nn35aBQUFkniG4iXaH+nhPUNW/lZ5Se5/8KybMaZP3WhXWlrqlgsLCzVr1iw9/vjj2r9/v/sFKfvU1/3syVjZt5UrV7rlgoICTZ8+XXl5efr000+1fPnyfseNxv1Zv369vv32W505c6ZPG89Q//vzsJ4h6z55ZWVlye/390noxsbGPv9vaKxJS0tTYWGhrly54r51yD71uJc9CYVC6ujoUFNTU799xpKcnBzl5eXpypUrksbO/mzYsEGffPKJTp06pUmTJrn1PEMx/e1PIsP1DFkXXikpKSoqKlJ1dbWnvrq6WsXFxSO0qv8N0WhU3333nXJycpSfn69QKOTZp46ODtXU1IzZfbqXPSkqKlJycrKnT0NDgy5evDgm9+3GjRuqr69XTk6OpNG/P8YYrV+/XkePHtXJkyeVn5/vaR/rz9Dd9ieRYXuG7vnVjv8hVVVVJjk52ezZs8f885//NGVlZSYtLc38+OOPI720h2rjxo3m9OnT5ocffjBnz541ixcvNunp6e4+vPvuuyYjI8McPXrUXLhwwbz00ksmJyfHtLS0jPDKh09ra6s5f/68OX/+vJFktm/fbs6fP29++uknY8y97clrr71mJk2aZE6cOGH+8Y9/mHnz5plp06aZ27dvj9RtDZmB9qe1tdVs3LjR1NbWmqtXr5pTp06ZWbNmmccee2zM7M+f/vQnk5GRYU6fPm0aGhrc49dff3X7jOVn6G778zCfISvDyxhj/vKXv5i8vDyTkpJinnzySc+rmmPFypUrTU5OjklOTjbhcNgsX77cXLp0yW3v7Ow0b731lgmFQiYQCJhnn33WXLhwYQRXPPxOnTplJPU5Vq1aZYy5tz1pb28369evN5mZmSY1NdUsXrzYXLt2bQTuZugNtD+//vqrKSkpMY8++qhJTk42kydPNqtWrepz76N5fxLtjSSzd+9et89Yfobutj8P8xniP4kCALCOdd95AQBAeAEArEN4AQCsQ3gBAKxDeAEArEN4AQCsQ3gBAKxDeAEArEN4AQCsQ3gBAKxDeAEArEN4AQCs8/8B14hPFUTrzt0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(heatmaps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f550ac2-c803-4d18-bee7-09e63723a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "def create_transparent_colormap(color='cyan', name='transparent_to_color'):\n",
    "    # Convert color name to RGBA\n",
    "    base_color = mcolors.to_rgba(color)\n",
    "    \n",
    "    # Create colormap: transparent (alpha=0) to full color (alpha=1)\n",
    "    colors = [(base_color[0], base_color[1], base_color[2], 0),  # transparent\n",
    "              (base_color[0], base_color[1], base_color[2], 1)]  # full color\n",
    "    \n",
    "    n_bins = 256\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(name, colors, N=n_bins)\n",
    "    return cmap\n",
    "\n",
    "# Create the colormap\n",
    "transparent_cyan_cmap = create_transparent_colormap('cyan')\n",
    "transparent_yellow_cmap = create_transparent_colormap('#ffd35a')\n",
    "transparent_green_cmap = create_transparent_colormap('#00a14b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6de9335-9805-4352-8225-60934a4cd9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaps=[transparent_cyan_cmap, transparent_yellow_cmap, transparent_green_cmap, transparent_cyan_cmap, transparent_yellow_cmap, transparent_green_cmap]\n",
    "save_names=['_logits_1.png', '_logits_2.png', '_logits_3.png', '_yhat_1.png', '_yhat_2.png', '_yhat_3.png']\n",
    "\n",
    "# for l in range(6):\n",
    "#     plt.clf()\n",
    "#     plt.figure(frameon=False)\n",
    "#     ax = plt.Axes(plt.gcf(), [0., 0., 1., 1.])\n",
    "#     ax.set_axis_off()\n",
    "#     plt.gcf().add_axes(ax)\n",
    "#     plt.imshow(heatmaps[l],  cmap=cmaps[l]) #np.rot90(heatmaps[0])) #Wait and see if I need to rotate or transpose\n",
    "#     plt.savefig(save_dir+save_names[l], bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5b1db17-b965-4fcb-9b0f-c5aeee9d45b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10/9, Loss: 18.4130, 'Accuracy: 0.0000\n",
      "Step 20/19, Loss: 0.4497, 'Accuracy: 0.3333\n",
      "Step 30/29, Loss: 0.6749, 'Accuracy: 0.6667\n",
      "Step 40/39, Loss: 0.0136, 'Accuracy: 0.6667\n",
      "Step 50/49, Loss: 1.1908, 'Accuracy: 0.6667\n",
      "Step 60/59, Loss: 0.9695, 'Accuracy: 0.6667\n",
      "Step 70/69, Loss: 0.0462, 'Accuracy: 1.0000\n",
      "Step 80/79, Loss: 0.5044, 'Accuracy: 1.0000\n",
      "Step 90/89, Loss: 0.4567, 'Accuracy: 1.0000\n",
      "Step 100/99, Loss: 0.0863, 'Accuracy: 1.0000\n",
      "Step 110/109, Loss: 0.4022, 'Accuracy: 1.0000\n",
      "Step 120/119, Loss: 0.3662, 'Accuracy: 1.0000\n",
      "Step 130/129, Loss: 0.0736, 'Accuracy: 1.0000\n",
      "Step 140/139, Loss: 0.2948, 'Accuracy: 1.0000\n",
      "Step 150/149, Loss: 0.2764, 'Accuracy: 1.0000\n",
      "Step 160/159, Loss: 0.0570, 'Accuracy: 1.0000\n",
      "Step 170/169, Loss: 0.2327, 'Accuracy: 1.0000\n",
      "Step 180/179, Loss: 0.2188, 'Accuracy: 1.0000\n",
      "Step 190/189, Loss: 0.0473, 'Accuracy: 1.0000\n",
      "Step 200/199, Loss: 0.1871, 'Accuracy: 1.0000\n",
      "Step 210/209, Loss: 0.1774, 'Accuracy: 1.0000\n",
      "Step 220/219, Loss: 0.0393, 'Accuracy: 1.0000\n",
      "Step 230/229, Loss: 0.1543, 'Accuracy: 1.0000\n",
      "Step 240/239, Loss: 0.1471, 'Accuracy: 1.0000\n",
      "Step 250/249, Loss: 0.0332, 'Accuracy: 1.0000\n",
      "Step 260/259, Loss: 0.1297, 'Accuracy: 1.0000\n",
      "Step 270/269, Loss: 0.1242, 'Accuracy: 1.0000\n",
      "Step 280/279, Loss: 0.0285, 'Accuracy: 1.0000\n",
      "Step 290/289, Loss: 0.1107, 'Accuracy: 1.0000\n",
      "Step 300/299, Loss: 0.1064, 'Accuracy: 1.0000\n",
      "Step 310/309, Loss: 0.0247, 'Accuracy: 1.0000\n",
      "Step 320/319, Loss: 0.0958, 'Accuracy: 1.0000\n",
      "Step 330/329, Loss: 0.0924, 'Accuracy: 1.0000\n",
      "Step 340/339, Loss: 0.0217, 'Accuracy: 1.0000\n",
      "Step 350/349, Loss: 0.0838, 'Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = TinyGPSModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
    "\n",
    "#I can manually initialize and still learns real good? yeah seems like it!\n",
    "with torch.no_grad():\n",
    "    model.output.weight[0,0]=1.0\n",
    "    model.output.weight[1,0]=0.0\n",
    "    model.output.weight[2,0]=-1.0\n",
    "    model.output.bias[0]=0\n",
    "    model.output.bias[1]=0\n",
    "    model.output.bias[2]=0\n",
    "\n",
    "weights=[]\n",
    "grads=[]\n",
    "xs=[]\n",
    "ys=[]\n",
    "logitss=[]\n",
    "yhats=[]\n",
    "\n",
    "# Training loop\n",
    "for i in range(350):\n",
    "    xs.append(X_raw[i%len(y)])\n",
    "    ys.append(y[i%len(y)])\n",
    "    weights.append(np.concatenate([model.output.weight.detach().numpy().ravel(), model.output.bias.detach().numpy().ravel()]))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Stochastic - i think this is a better starting point pedagogically. \n",
    "    outputs = model(torch.tensor(X[i%len(y)]).float())\n",
    "    loss = criterion(outputs, torch.tensor(y[i%len(y)])) \n",
    "\n",
    "    logitss.append(outputs.detach().numpy())\n",
    "    yhats.append(torch.nn.Softmax(0)(outputs.detach()).numpy())\n",
    "    \n",
    "    loss.backward()  # backpropagation\n",
    "    grads.append(np.concatenate([model.output.weight.grad.detach().numpy().ravel(), model.output.bias.grad.detach().numpy().ravel()]))\n",
    "    optimizer.step() #\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            logits=model(torch.tensor(X, dtype=torch.float)) \n",
    "            accuracy=(torch.argmax(logits, dim=1)==torch.tensor(y)).sum().item()/len(y)\n",
    "        print(f\"Step {i+1}/{i}, Loss: {loss.item():.4f}, 'Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "weights=np.array(weights)\n",
    "grads=np.array(grads)\n",
    "xs=np.array(xs)\n",
    "ys=np.array(ys)\n",
    "logitss=np.array(logitss)\n",
    "yhats=np.array(yhats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa1f0f5e-453c-4ee0-9a9c-7499a0b23dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits=model(torch.tensor(X, dtype=torch.float)) \n",
    "    accuracy=(torch.argmax(logits, dim=1)==torch.tensor(y)).sum().item()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07034258-8633-4887-8111-fff4f276e510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.14982929e-02, 9.20528710e-01, 6.79729357e-02],\n",
       "       [9.74519372e-01, 2.54267249e-02, 5.39280627e-05],\n",
       "       [9.73857045e-01, 2.60869917e-02, 5.59759756e-05],\n",
       "       [1.01542531e-10, 1.98761225e-02, 9.80123878e-01],\n",
       "       [1.12732165e-02, 9.20193195e-01, 6.85336590e-02],\n",
       "       [9.74146783e-01, 2.57981811e-02, 5.50772493e-05],\n",
       "       [9.74880159e-01, 2.50669625e-02, 5.28224555e-05],\n",
       "       [1.08667519e-10, 2.02878062e-02, 9.79712129e-01],\n",
       "       [9.74519372e-01, 2.54267249e-02, 5.39280627e-05],\n",
       "       [1.04406414e-10, 2.00439580e-02, 9.79956031e-01],\n",
       "       [1.21886507e-02, 9.21470642e-01, 6.63407296e-02],\n",
       "       [1.13083804e-02, 9.20246482e-01, 6.84450641e-02],\n",
       "       [1.06962959e-10, 2.01910790e-02, 9.79808986e-01],\n",
       "       [1.02143738e-10, 1.99116357e-02, 9.80088413e-01],\n",
       "       [1.12854363e-02, 9.20211673e-01, 6.85028285e-02]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Softmax(1)(logits.detach()).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fbe5f9-fb8e-41ed-8749-a6f92ef0aad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50feb367-c8a4-45ff-9c3d-dd42fb3a1c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759f5ca7-62da-42bd-8979-d0490272cb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83829580-04d3-4908-bdfb-2feb5b584a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10/9, Loss: 18.4130, 'Accuracy: 0.0000\n",
      "Step 20/19, Loss: 0.4497, 'Accuracy: 0.3333\n",
      "Step 30/29, Loss: 0.6749, 'Accuracy: 0.6667\n",
      "Step 40/39, Loss: 0.0136, 'Accuracy: 0.6667\n",
      "Step 50/49, Loss: 1.1908, 'Accuracy: 0.6667\n",
      "Step 60/59, Loss: 0.9695, 'Accuracy: 0.6667\n",
      "Step 70/69, Loss: 0.0462, 'Accuracy: 1.0000\n",
      "Step 80/79, Loss: 0.5044, 'Accuracy: 1.0000\n",
      "Step 90/89, Loss: 0.4567, 'Accuracy: 1.0000\n",
      "Step 100/99, Loss: 0.0863, 'Accuracy: 1.0000\n",
      "Step 110/109, Loss: 0.4022, 'Accuracy: 1.0000\n",
      "Step 120/119, Loss: 0.3662, 'Accuracy: 1.0000\n",
      "Step 130/129, Loss: 0.0736, 'Accuracy: 1.0000\n",
      "Step 140/139, Loss: 0.2948, 'Accuracy: 1.0000\n",
      "Step 150/149, Loss: 0.2764, 'Accuracy: 1.0000\n",
      "Step 160/159, Loss: 0.0570, 'Accuracy: 1.0000\n",
      "Step 170/169, Loss: 0.2327, 'Accuracy: 1.0000\n",
      "Step 180/179, Loss: 0.2188, 'Accuracy: 1.0000\n",
      "Step 190/189, Loss: 0.0473, 'Accuracy: 1.0000\n",
      "Step 200/199, Loss: 0.1871, 'Accuracy: 1.0000\n",
      "Step 210/209, Loss: 0.1774, 'Accuracy: 1.0000\n",
      "Step 220/219, Loss: 0.0393, 'Accuracy: 1.0000\n",
      "Step 230/229, Loss: 0.1543, 'Accuracy: 1.0000\n",
      "Step 240/239, Loss: 0.1471, 'Accuracy: 1.0000\n",
      "Step 250/249, Loss: 0.0332, 'Accuracy: 1.0000\n",
      "Step 260/259, Loss: 0.1297, 'Accuracy: 1.0000\n",
      "Step 270/269, Loss: 0.1242, 'Accuracy: 1.0000\n",
      "Step 280/279, Loss: 0.0285, 'Accuracy: 1.0000\n",
      "Step 290/289, Loss: 0.1107, 'Accuracy: 1.0000\n",
      "Step 300/299, Loss: 0.1064, 'Accuracy: 1.0000\n",
      "Step 310/309, Loss: 0.0247, 'Accuracy: 1.0000\n",
      "Step 320/319, Loss: 0.0958, 'Accuracy: 1.0000\n",
      "Step 330/329, Loss: 0.0924, 'Accuracy: 1.0000\n",
      "Step 340/339, Loss: 0.0217, 'Accuracy: 1.0000\n",
      "Step 350/349, Loss: 0.0838, 'Accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = TinyGPSModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
    "\n",
    "#I can manually initialize and still learns real good? yeah seems like it!\n",
    "with torch.no_grad():\n",
    "    model.output.weight[0,0]=1.0\n",
    "    model.output.weight[1,0]=0.0\n",
    "    model.output.weight[2,0]=-1.0\n",
    "    model.output.bias[0]=0\n",
    "    model.output.bias[1]=0\n",
    "    model.output.bias[2]=0\n",
    "\n",
    "weights=[]\n",
    "grads=[]\n",
    "xs=[]\n",
    "ys=[]\n",
    "logitss=[]\n",
    "yhats=[]\n",
    "\n",
    "# Training loop\n",
    "for i in range(350):\n",
    "    xs.append(X_raw[i%len(y)])\n",
    "    ys.append(y[i%len(y)])\n",
    "    weights.append(np.concatenate([model.output.weight.detach().numpy().ravel(), model.output.bias.detach().numpy().ravel()]))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Stochastic - i think this is a better starting point pedagogically. \n",
    "    outputs = model(torch.tensor(X[i%len(y)]).float())\n",
    "    loss = criterion(outputs, torch.tensor(y[i%len(y)])) \n",
    "\n",
    "    logitss.append(outputs.detach().numpy())\n",
    "    yhats.append(torch.nn.Softmax(0)(outputs.detach()).numpy())\n",
    "\n",
    "    #Heatmaps\n",
    "    heatmaps=[np.zeros((num_steps, num_steps)) for i in range(6)]\n",
    "    for j, lat in enumerate(np.linspace(max_lat, min_lat, num_steps)):\n",
    "        for k, long in enumerate(np.linspace(min_long, max_long, num_steps)):\n",
    "            with torch.no_grad():\n",
    "                logits=model(torch.tensor([long], dtype=torch.float)).detach()\n",
    "                yhat=torch.nn.Softmax(0)(heatmap_viz_logit_multiplier*logits).numpy()\n",
    "    \n",
    "            for l in range(3):\n",
    "                heatmaps[l][j, k]=logits.numpy()[l]\n",
    "                heatmaps[l+3][j,k]=yhat[l]\n",
    "\n",
    "    for l in range(6):\n",
    "        plt.clf()\n",
    "        plt.figure(frameon=False)\n",
    "        ax = plt.Axes(plt.gcf(), [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        plt.gcf().add_axes(ax)\n",
    "        plt.imshow(heatmaps[l],  cmap=cmaps[l]) #np.rot90(heatmaps[0])) #Wait and see if I need to rotate or transpose\n",
    "        plt.savefig(save_dir+'/'+str(i)+save_names[l], bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    loss.backward()  # backpropagation\n",
    "    grads.append(np.concatenate([model.output.weight.grad.detach().numpy().ravel(), model.output.bias.grad.detach().numpy().ravel()]))\n",
    "    optimizer.step() #\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            logits=model(torch.tensor(X, dtype=torch.float)) \n",
    "            accuracy=(torch.argmax(logits, dim=1)==torch.tensor(y)).sum().item()/len(y)\n",
    "        print(f\"Step {i+1}/{i}, Loss: {loss.item():.4f}, 'Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "weights=np.array(weights)\n",
    "grads=np.array(grads)\n",
    "xs=np.array(xs)\n",
    "ys=np.array(ys)\n",
    "logitss=np.array(logitss)\n",
    "yhats=np.array(yhats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48db04ac-6002-4516-a7cf-ef3207f28aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_data=np.hstack((xs, ys.reshape(-1, 1), weights, grads, logitss, yhats))\n",
    "np.save('/Users/stephen/Stephencwelch Dropbox/Stephen Welch/welch_labs/backprop2/hackin/cities_1d_3', all_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d3cfe-8bca-4de1-bffa-aa798506737a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0925682-fd1f-4b10-aaca-f7f6804de2c3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d9da08-cf0e-422b-bcb3-a55dbf1eac1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf7fce-877f-4679-95e5-757fa95328ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28aaadd-8c29-4167-b41a-85f231bc6ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb18ebc-0c55-481d-8200-0d70b577388e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d75f04-b635-4792-bb81-2963307e5932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
