{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5cd6ef-40bf-4038-a7a3-06719e3227ac",
   "metadata": {},
   "source": [
    "# Hackin 3\n",
    "- I think this is a good reference to hack through, even though it doesn't use gradients, will help me ground in something here!\n",
    "- https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter1_transformer_interp/exercises/part41_indirect_object_identification/1.4.1_Indirect_Object_Identification_solutions.ipynb?t=20250330#scrollTo=y6MDKRsNKqpj\n",
    "\n",
    "Eh maybe actually dis? \n",
    "https://colab.research.google.com/drive/13HDQ6o-TN7PcKCk4DlKgQ9O6jEeHbUW0?usp=sharing#scrollTo=U3JwUkOFATn-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c51dd1e-7636-456e-bdae-053bb60c8993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import llm_utils\n",
    "# import opt_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c07b8a3c-42de-4488-9d04-1a258ebb37be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--device'], dest='device', nargs=None, const=None, default=device(type='cuda'), type=<class 'str'>, choices=None, required=False, help=None, metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "# the following demo is sutiable for gpt2 (all sizes),  OPT, GPT-j and Llama-2-7b\n",
    "# we recommend on using gpt2 or OPT, since they have small versions that can be run without GPUs\n",
    "parser.add_argument('--model_name', type=str, default='gpt2', help='model name (only models from HuggingFace that are supported by llm_utils)')\n",
    "# parser.add_argument('--model_name', type=str, default='facebook/opt-350m', help='model name (only models from HuggingFace that are supported by llm_utils)')\n",
    "parser.add_argument('--model_args', type=str, default='')\n",
    "parser.add_argument('--disable_pad_token', action='store_true')\n",
    "parser.add_argument('--device', type=str, default=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "183eef8b-8068-4e0c-b8d3-1fc011d79c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown args: ['-f', '/home/stephen/.local/share/jupyter/runtime/kernel-bd715ae3-72db-41cf-b0bb-0484bb800b4b.json']\n",
      "args: Namespace(model_name='gpt2', model_args='', disable_pad_token=False, device=device(type='cuda'))\n"
     ]
    }
   ],
   "source": [
    "args, unknown = parser.parse_known_args()\n",
    "print('unknown args:', unknown)\n",
    "print('args:', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a5c9a5-78a2-430d-af1f-e7cc35a42966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding pad token: <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
    "if not args.disable_pad_token:\n",
    "    print(f'adding pad token: {tokenizer.eos_token}')\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "try:\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"  # not blocking, just to prevent warnings and faster tokenization\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9226b10d-9665-4d23-bc9c-5470daff9061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda [cuda available? => True, cuda version: 12.4, args.device = \"cuda\"]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(args.device)\n",
    "print(f'Using device: {device} [cuda available? => {torch.cuda.is_available()}, cuda version: {torch.version.cuda}, args.device = \"{args.device}\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a63f4dba-c503-40d6-bca0-7146d78ca634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_extra_args: {}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'llm_utils' has no attribute 'model_extra'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmodel_extra_args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_extra_args\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m model = AutoModelForCausalLM.from_pretrained(args.model_name, **model_extra_args).eval().requires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m).to(device)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m model_aux = \u001b[43mllm_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_extra\u001b[49m(model=model, device=device)\n\u001b[32m     11\u001b[39m config = model_aux.config  \u001b[38;5;66;03m# should be the same as auto_model_to_config(args.model_name)\u001b[39;00m\n\u001b[32m     13\u001b[39m n_embd = model_aux.n_embd\n",
      "\u001b[31mAttributeError\u001b[39m: module 'llm_utils' has no attribute 'model_extra'"
     ]
    }
   ],
   "source": [
    "model_extra_args = {}\n",
    "for arg in args.model_args.split(','):\n",
    "    if arg == '':\n",
    "        continue\n",
    "    k, v = arg.split('=')\n",
    "    model_extra_args[k] = v\n",
    "print(f'model_extra_args: {model_extra_args}')\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(args.model_name, **model_extra_args).eval().requires_grad_(False).to(device)\n",
    "model_aux = llm_utils.model_extra(model=model, device=device)\n",
    "config = model_aux.config  # should be the same as auto_model_to_config(args.model_name)\n",
    "\n",
    "n_embd = model_aux.n_embd\n",
    "n_head = model_aux.n_head\n",
    "head_size = model_aux.head_size\n",
    "n_layer = model_aux.n_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7630a08-9a44-4ddf-9902-1bb5e9e8f8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a82936-d545-4bca-af28-4572950aa701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a5c90-4712-4feb-ab78-6e1402cff6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab378b-6f4a-4fbf-9094-ad5ca794b618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1824c65c-4ed7-4410-aea6-c375602a3549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fbf078-4b98-40b8-b37a-0d5fc8cb9f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca414790-b6c8-400b-894d-98625de2c0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e9e28-eaea-4e4b-9b60-8802d9243547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af3a16-090d-470e-8aa5-7fc44e9a9ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21f8144a-2a27-4bcb-9fbe-1167a75d1575",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb0b3831-bc31-4c58-96be-50689c395937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from typing import Callable, Literal\n",
    "\n",
    "import circuitsvis as cv\n",
    "import einops\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import torch as t\n",
    "from IPython.display import HTML, display\n",
    "from jaxtyping import Bool, Float, Int\n",
    "from rich import print as rprint\n",
    "from rich.table import Column, Table\n",
    "from torch import Tensor\n",
    "from tqdm.notebook import tqdm\n",
    "from transformer_lens import ActivationCache, HookedTransformer, utils\n",
    "from transformer_lens.components import MLP, Embed, LayerNorm, Unembed\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "t.set_grad_enabled(False)\n",
    "device = t.device(\"mps\" if t.backends.mps.is_available() else \"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Make sure exercises are in the path\n",
    "# chapter = \"chapter1_transformer_interp\"\n",
    "# section = \"part41_indirect_object_identification\"\n",
    "# root_dir = next(p for p in Path.cwd().parents if (p / chapter).exists())\n",
    "# exercises_dir = root_dir / chapter / \"exercises\"\n",
    "# section_dir = exercises_dir / section\n",
    "\n",
    "# import part41_indirect_object_identification.tests as tests\n",
    "# from plotly_utils import line # bar, imshow, line, scatter\n",
    "\n",
    "# MAIN = __name__ == \"__main__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6841ef9-2110-4a7d-aa10-1188efa82ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "You can't refactor the QK circuit when using rotary embeddings (as the QK matrix depends on the position of the query and key)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mHookedTransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmeta-llama/Llama-3.2-1B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcenter_unembed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcenter_writing_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfold_ln\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrefactor_factored_attn_matrices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/backprop/lib/python3.11/site-packages/transformer_lens/HookedTransformer.py:1371\u001b[39m, in \u001b[36mHookedTransformer.from_pretrained\u001b[39m\u001b[34m(cls, model_name, fold_ln, center_writing_weights, center_unembed, refactor_factored_attn_matrices, checkpoint_index, checkpoint_value, hf_model, device, n_devices, tokenizer, move_to_device, fold_value_biases, default_prepend_bos, default_padding_side, dtype, first_n_layers, **from_pretrained_kwargs)\u001b[39m\n\u001b[32m   1363\u001b[39m \u001b[38;5;66;03m# Create the HookedTransformer object\u001b[39;00m\n\u001b[32m   1364\u001b[39m model = \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m   1365\u001b[39m     cfg,\n\u001b[32m   1366\u001b[39m     tokenizer,\n\u001b[32m   1367\u001b[39m     move_to_device=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1368\u001b[39m     default_padding_side=default_padding_side,\n\u001b[32m   1369\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_and_process_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfold_ln\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold_ln\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcenter_writing_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcenter_writing_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcenter_unembed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcenter_unembed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfold_value_biases\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold_value_biases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrefactor_factored_attn_matrices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrefactor_factored_attn_matrices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m move_to_device:\n\u001b[32m   1381\u001b[39m     model.move_model_modules_to_device()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/backprop/lib/python3.11/site-packages/transformer_lens/HookedTransformer.py:1629\u001b[39m, in \u001b[36mHookedTransformer.load_and_process_state_dict\u001b[39m\u001b[34m(self, state_dict, fold_ln, center_writing_weights, center_unembed, fold_value_biases, refactor_factored_attn_matrices)\u001b[39m\n\u001b[32m   1627\u001b[39m     state_dict = \u001b[38;5;28mself\u001b[39m.fold_value_biases(state_dict)\n\u001b[32m   1628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m refactor_factored_attn_matrices:\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m     state_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrefactor_factored_attn_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.load_in_4bit:\n\u001b[32m   1632\u001b[39m     \u001b[38;5;66;03m# with quantization, parameters should be assigned\u001b[39;00m\n\u001b[32m   1633\u001b[39m     \u001b[38;5;66;03m# so that quantization settings are not lost\u001b[39;00m\n\u001b[32m   1634\u001b[39m     \u001b[38;5;28mself\u001b[39m.load_state_dict(state_dict, assign=\u001b[38;5;28;01mTrue\u001b[39;00m, strict=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/backprop/lib/python3.11/site-packages/transformer_lens/HookedTransformer.py:1926\u001b[39m, in \u001b[36mHookedTransformer.refactor_factored_attn_matrices\u001b[39m\u001b[34m(self, state_dict)\u001b[39m\n\u001b[32m   1888\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrefactor_factored_attn_matrices\u001b[39m(\u001b[38;5;28mself\u001b[39m, state_dict: Dict[\u001b[38;5;28mstr\u001b[39m, torch.Tensor]):\n\u001b[32m   1889\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Experimental method for managing queries, keys and values.\u001b[39;00m\n\u001b[32m   1890\u001b[39m \n\u001b[32m   1891\u001b[39m \u001b[33;03m    As argued in [A Mathematical Framework for Transformer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1923\u001b[39m \u001b[33;03m    factorization on this effective matrix, then separate out into final weights and biases.\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1926\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   1927\u001b[39m         \u001b[38;5;28mself\u001b[39m.cfg.positional_embedding_type != \u001b[33m\"\u001b[39m\u001b[33mrotary\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1928\u001b[39m     ), \u001b[33m\"\u001b[39m\u001b[33mYou can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt refactor the QK circuit when using rotary embeddings (as the QK matrix depends on the position of the query and key)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1930\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.cfg.n_layers):\n\u001b[32m   1931\u001b[39m         \u001b[38;5;66;03m# W_QK = W_Q @ W_K.T\u001b[39;00m\n\u001b[32m   1932\u001b[39m         \u001b[38;5;66;03m# Concatenate biases to make a d_model+1 input dimension\u001b[39;00m\n\u001b[32m   1933\u001b[39m         W_Q_eff = torch.cat(\n\u001b[32m   1934\u001b[39m             [\n\u001b[32m   1935\u001b[39m                 state_dict[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mblocks.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.attn.W_Q\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1938\u001b[39m             dim=\u001b[32m1\u001b[39m,\n\u001b[32m   1939\u001b[39m         )\n",
      "\u001b[31mAssertionError\u001b[39m: You can't refactor the QK circuit when using rotary embeddings (as the QK matrix depends on the position of the query and key)"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    \"meta-llama/Llama-3.2-1B\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ceca04-be05-464a-b971-9943686b763f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'After', ' John', ' and', ' Mary', ' went', ' to', ' the', ' store', ',', ' John', ' gave', ' a', ' bottle', ' of', ' milk', ' to']\n",
      "Tokenized answer: [' Mary']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.09</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70.07</span><span style=\"font-weight: bold\">% Token: | Mary|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m18.09\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m70.07\u001b[0m\u001b[1m% Token: | Mary|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 18.09 Prob: 70.07% Token: | Mary|\n",
      "Top 1th token. Logit: 15.38 Prob:  4.67% Token: | the|\n",
      "Top 2th token. Logit: 15.35 Prob:  4.54% Token: | John|\n",
      "Top 3th token. Logit: 15.25 Prob:  4.11% Token: | them|\n",
      "Top 4th token. Logit: 14.84 Prob:  2.73% Token: | his|\n",
      "Top 5th token. Logit: 14.06 Prob:  1.24% Token: | her|\n",
      "Top 6th token. Logit: 13.54 Prob:  0.74% Token: | a|\n",
      "Top 7th token. Logit: 13.52 Prob:  0.73% Token: | their|\n",
      "Top 8th token. Logit: 13.13 Prob:  0.49% Token: | Jesus|\n",
      "Top 9th token. Logit: 12.97 Prob:  0.42% Token: | him|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Mary'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Mary'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here is where we test on a single prompt\n",
    "# Result: 70% probability on Mary, as we expect\n",
    "\n",
    "example_prompt = \"After John and Mary went to the store, John gave a bottle of milk to\"\n",
    "example_answer = \" Mary\"\n",
    "utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dcd208e-e302-440e-b630-88e8c34d8201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'When John and Mary went to the shops, John gave the bag to'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'When John and Mary went to the shops, Mary gave the bag to'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'When Tom and James went to the park, James gave the ball to'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'When Tom and James went to the park, Tom gave the ball to'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'When Dan and Sid went to the shops, Sid gave an apple to'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'When Dan and Sid went to the shops, Dan gave an apple to'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'After Martin and Amy went to the park, Amy gave a drink to'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'After Martin and Amy went to the park, Martin gave a drink to'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'When John and Mary went to the shops, John gave the bag to'\u001b[0m,\n",
       "    \u001b[32m'When John and Mary went to the shops, Mary gave the bag to'\u001b[0m,\n",
       "    \u001b[32m'When Tom and James went to the park, James gave the ball to'\u001b[0m,\n",
       "    \u001b[32m'When Tom and James went to the park, Tom gave the ball to'\u001b[0m,\n",
       "    \u001b[32m'When Dan and Sid went to the shops, Sid gave an apple to'\u001b[0m,\n",
       "    \u001b[32m'When Dan and Sid went to the shops, Dan gave an apple to'\u001b[0m,\n",
       "    \u001b[32m'After Martin and Amy went to the park, Amy gave a drink to'\u001b[0m,\n",
       "    \u001b[32m'After Martin and Amy went to the park, Martin gave a drink to'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Mary'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">' John'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">' John'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">' Mary'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Tom'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">' James'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">' James'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">' Tom'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Dan'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">' Sid'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Sid'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">' Dan'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Martin'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">' Amy'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Amy'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">' Martin'</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[32m' Mary'\u001b[0m, \u001b[32m' John'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[32m' John'\u001b[0m, \u001b[32m' Mary'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[32m' Tom'\u001b[0m, \u001b[32m' James'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[32m' James'\u001b[0m, \u001b[32m' Tom'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[32m' Dan'\u001b[0m, \u001b[32m' Sid'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[32m' Sid'\u001b[0m, \u001b[32m' Dan'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[32m' Martin'\u001b[0m, \u001b[32m' Amy'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[32m' Amy'\u001b[0m, \u001b[32m' Martin'\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5335</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1757</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1757</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5335</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4186</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3700</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3700</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4186</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6035</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15686</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15686</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6035</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5780</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14235</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14235</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5780</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m5335\u001b[0m,  \u001b[1;36m1757\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m1757\u001b[0m,  \u001b[1;36m5335\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m4186\u001b[0m,  \u001b[1;36m3700\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m3700\u001b[0m,  \u001b[1;36m4186\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m6035\u001b[0m, \u001b[1;36m15686\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m15686\u001b[0m,  \u001b[1;36m6035\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m5780\u001b[0m, \u001b[1;36m14235\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m14235\u001b[0m,  \u001b[1;36m5780\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                   Prompts &amp; Answers:                                    </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Prompt                                                        </span>┃<span style=\"font-weight: bold\"> Correct   </span>┃<span style=\"font-weight: bold\"> Incorrect </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│ When John and Mary went to the shops, John gave the bag to    │ ' Mary'   │ ' John'   │\n",
       "│ When John and Mary went to the shops, Mary gave the bag to    │ ' John'   │ ' Mary'   │\n",
       "│ When Tom and James went to the park, James gave the ball to   │ ' Tom'    │ ' James'  │\n",
       "│ When Tom and James went to the park, Tom gave the ball to     │ ' James'  │ ' Tom'    │\n",
       "│ When Dan and Sid went to the shops, Sid gave an apple to      │ ' Dan'    │ ' Sid'    │\n",
       "│ When Dan and Sid went to the shops, Dan gave an apple to      │ ' Sid'    │ ' Dan'    │\n",
       "│ After Martin and Amy went to the park, Amy gave a drink to    │ ' Martin' │ ' Amy'    │\n",
       "│ After Martin and Amy went to the park, Martin gave a drink to │ ' Amy'    │ ' Martin' │\n",
       "└───────────────────────────────────────────────────────────────┴───────────┴───────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                   Prompts & Answers:                                    \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mPrompt                                                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCorrect  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mIncorrect\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
       "│ When John and Mary went to the shops, John gave the bag to    │ ' Mary'   │ ' John'   │\n",
       "│ When John and Mary went to the shops, Mary gave the bag to    │ ' John'   │ ' Mary'   │\n",
       "│ When Tom and James went to the park, James gave the ball to   │ ' Tom'    │ ' James'  │\n",
       "│ When Tom and James went to the park, Tom gave the ball to     │ ' James'  │ ' Tom'    │\n",
       "│ When Dan and Sid went to the shops, Sid gave an apple to      │ ' Dan'    │ ' Sid'    │\n",
       "│ When Dan and Sid went to the shops, Dan gave an apple to      │ ' Sid'    │ ' Dan'    │\n",
       "│ After Martin and Amy went to the park, Amy gave a drink to    │ ' Martin' │ ' Amy'    │\n",
       "│ After Martin and Amy went to the park, Martin gave a drink to │ ' Amy'    │ ' Martin' │\n",
       "└───────────────────────────────────────────────────────────────┴───────────┴───────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_format = [\n",
    "    \"When John and Mary went to the shops,{} gave the bag to\",\n",
    "    \"When Tom and James went to the park,{} gave the ball to\",\n",
    "    \"When Dan and Sid went to the shops,{} gave an apple to\",\n",
    "    \"After Martin and Amy went to the park,{} gave a drink to\",\n",
    "]\n",
    "name_pairs = [\n",
    "    (\" Mary\", \" John\"),\n",
    "    (\" Tom\", \" James\"),\n",
    "    (\" Dan\", \" Sid\"),\n",
    "    (\" Martin\", \" Amy\"),\n",
    "]\n",
    "\n",
    "# Define 8 prompts, in 4 groups of 2 (with adjacent prompts having answers swapped)\n",
    "prompts = [prompt.format(name) for (prompt, names) in zip(prompt_format, name_pairs) for name in names[::-1]]\n",
    "# Define the answers for each prompt, in the form (correct, incorrect)\n",
    "answers = [names[::i] for names in name_pairs for i in (1, -1)]\n",
    "# Define the answer tokens (same shape as the answers)\n",
    "answer_tokens = t.concat([model.to_tokens(names, prepend_bos=False).T for names in answers])\n",
    "\n",
    "rprint(prompts)\n",
    "rprint(answers)\n",
    "rprint(answer_tokens)\n",
    "\n",
    "table = Table(\"Prompt\", \"Correct\", \"Incorrect\", title=\"Prompts & Answers:\")\n",
    "\n",
    "for prompt, answer in zip(prompts, answers):\n",
    "    table.add_row(prompt, repr(answer[0]), repr(answer[1]))\n",
    "\n",
    "rprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99661ca6-d12e-4e9b-b695-47a0eb603076",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tokens = \u001b[43mmodel\u001b[49m.to_tokens(prompts, prepend_bos=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Move the tokens to the GPU\u001b[39;00m\n\u001b[32m      3\u001b[39m tokens = tokens.to(device)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "tokens = model.to_tokens(prompts, prepend_bos=True)\n",
    "# Move the tokens to the GPU\n",
    "tokens = tokens.to(device)\n",
    "# Run the model and cache all activations\n",
    "original_logits, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "754a53ed-220b-4f58-9921-1c672f28346f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per prompt logit difference: tensor([3.3367, 3.2016, 2.7094, 3.7974, 1.7204, 5.2812, 2.6008, 5.7674],\n",
      "       device='cuda:0')\n",
      "Average logit difference: tensor(3.5519, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                             Logit differences                                              </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Prompt                                                        </span>┃<span style=\"font-weight: bold\"> Correct   </span>┃<span style=\"font-weight: bold\"> Incorrect </span>┃<span style=\"font-weight: bold\"> Logit Difference </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ When John and Mary went to the shops, John gave the bag to    │<span style=\"color: #00c800; text-decoration-color: #00c800; font-weight: bold\"> ' Mary'   </span>│<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\"> ' John'   </span>│<span style=\"font-weight: bold\"> 3.337            </span>│\n",
       "│ When John and Mary went to the shops, Mary gave the bag to    │<span style=\"color: #00c800; text-decoration-color: #00c800; font-weight: bold\"> ' John'   </span>│<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\"> ' Mary'   </span>│<span style=\"font-weight: bold\"> 3.202            </span>│\n",
       "│ When Tom and James went to the park, James gave the ball to   │<span style=\"color: #00c800; text-decoration-color: #00c800; font-weight: bold\"> ' Tom'    </span>│<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\"> ' James'  </span>│<span style=\"font-weight: bold\"> 2.709            </span>│\n",
       "│ When Tom and James went to the park, Tom gave the ball to     │<span style=\"color: #00c800; text-decoration-color: #00c800; font-weight: bold\"> ' James'  </span>│<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\"> ' Tom'    </span>│<span style=\"font-weight: bold\"> 3.797            </span>│\n",
       "│ When Dan and Sid went to the shops, Sid gave an apple to      │<span style=\"color: #00c800; text-decoration-color: #00c800; font-weight: bold\"> ' Dan'    </span>│<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\"> ' Sid'    </span>│<span style=\"font-weight: bold\"> 1.720            </span>│\n",
       "│ When Dan and Sid went to the shops, Dan gave an apple to      │<span style=\"color: #00c800; text-decoration-color: #00c800; font-weight: bold\"> ' Sid'    </span>│<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\"> ' Dan'    </span>│<span style=\"font-weight: bold\"> 5.281            </span>│\n",
       "│ After Martin and Amy went to the park, Amy gave a drink to    │<span style=\"color: #00c800; text-decoration-color: #00c800; font-weight: bold\"> ' Martin' </span>│<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\"> ' Amy'    </span>│<span style=\"font-weight: bold\"> 2.601            </span>│\n",
       "│ After Martin and Amy went to the park, Martin gave a drink to │<span style=\"color: #00c800; text-decoration-color: #00c800; font-weight: bold\"> ' Amy'    </span>│<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\"> ' Martin' </span>│<span style=\"font-weight: bold\"> 5.767            </span>│\n",
       "└───────────────────────────────────────────────────────────────┴───────────┴───────────┴──────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                             Logit differences                                              \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mPrompt                                                       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCorrect  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mIncorrect\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mLogit Difference\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ When John and Mary went to the shops, John gave the bag to    │\u001b[1;38;2;0;200;0m \u001b[0m\u001b[1;38;2;0;200;0m' Mary'  \u001b[0m\u001b[1;38;2;0;200;0m \u001b[0m│\u001b[1;38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0m' John'  \u001b[0m\u001b[1;38;2;255;0;0m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m3.337           \u001b[0m\u001b[1m \u001b[0m│\n",
       "│ When John and Mary went to the shops, Mary gave the bag to    │\u001b[1;38;2;0;200;0m \u001b[0m\u001b[1;38;2;0;200;0m' John'  \u001b[0m\u001b[1;38;2;0;200;0m \u001b[0m│\u001b[1;38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0m' Mary'  \u001b[0m\u001b[1;38;2;255;0;0m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m3.202           \u001b[0m\u001b[1m \u001b[0m│\n",
       "│ When Tom and James went to the park, James gave the ball to   │\u001b[1;38;2;0;200;0m \u001b[0m\u001b[1;38;2;0;200;0m' Tom'   \u001b[0m\u001b[1;38;2;0;200;0m \u001b[0m│\u001b[1;38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0m' James' \u001b[0m\u001b[1;38;2;255;0;0m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m2.709           \u001b[0m\u001b[1m \u001b[0m│\n",
       "│ When Tom and James went to the park, Tom gave the ball to     │\u001b[1;38;2;0;200;0m \u001b[0m\u001b[1;38;2;0;200;0m' James' \u001b[0m\u001b[1;38;2;0;200;0m \u001b[0m│\u001b[1;38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0m' Tom'   \u001b[0m\u001b[1;38;2;255;0;0m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m3.797           \u001b[0m\u001b[1m \u001b[0m│\n",
       "│ When Dan and Sid went to the shops, Sid gave an apple to      │\u001b[1;38;2;0;200;0m \u001b[0m\u001b[1;38;2;0;200;0m' Dan'   \u001b[0m\u001b[1;38;2;0;200;0m \u001b[0m│\u001b[1;38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0m' Sid'   \u001b[0m\u001b[1;38;2;255;0;0m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m1.720           \u001b[0m\u001b[1m \u001b[0m│\n",
       "│ When Dan and Sid went to the shops, Dan gave an apple to      │\u001b[1;38;2;0;200;0m \u001b[0m\u001b[1;38;2;0;200;0m' Sid'   \u001b[0m\u001b[1;38;2;0;200;0m \u001b[0m│\u001b[1;38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0m' Dan'   \u001b[0m\u001b[1;38;2;255;0;0m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m5.281           \u001b[0m\u001b[1m \u001b[0m│\n",
       "│ After Martin and Amy went to the park, Amy gave a drink to    │\u001b[1;38;2;0;200;0m \u001b[0m\u001b[1;38;2;0;200;0m' Martin'\u001b[0m\u001b[1;38;2;0;200;0m \u001b[0m│\u001b[1;38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0m' Amy'   \u001b[0m\u001b[1;38;2;255;0;0m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m2.601           \u001b[0m\u001b[1m \u001b[0m│\n",
       "│ After Martin and Amy went to the park, Martin gave a drink to │\u001b[1;38;2;0;200;0m \u001b[0m\u001b[1;38;2;0;200;0m' Amy'   \u001b[0m\u001b[1;38;2;0;200;0m \u001b[0m│\u001b[1;38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0m' Martin'\u001b[0m\u001b[1;38;2;255;0;0m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m5.767           \u001b[0m\u001b[1m \u001b[0m│\n",
       "└───────────────────────────────────────────────────────────────┴───────────┴───────────┴──────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def logits_to_ave_logit_diff(\n",
    "    logits: Float[Tensor, \"batch seq d_vocab\"],\n",
    "    answer_tokens: Float[Tensor, \"batch 2\"] = answer_tokens,\n",
    "    per_prompt: bool = False,\n",
    ") -> Float[Tensor, \"*batch\"]:\n",
    "    \"\"\"\n",
    "    Returns logit difference between the correct and incorrect answer.\n",
    "\n",
    "    If per_prompt=True, return the array of differences rather than the average.\n",
    "    \"\"\"\n",
    "    # Only the final logits are relevant for the answer\n",
    "    final_logits: Float[Tensor, \"batch d_vocab\"] = logits[:, -1, :]\n",
    "    # Get the logits corresponding to the indirect object / subject tokens respectively\n",
    "    answer_logits: Float[Tensor, \"batch 2\"] = final_logits.gather(dim=-1, index=answer_tokens)\n",
    "    # Find logit difference\n",
    "    correct_logits, incorrect_logits = answer_logits.unbind(dim=-1)\n",
    "    answer_logit_diff = correct_logits - incorrect_logits\n",
    "    return answer_logit_diff if per_prompt else answer_logit_diff.mean()\n",
    "\n",
    "\n",
    "# tests.test_logits_to_ave_logit_diff(logits_to_ave_logit_diff)\n",
    "\n",
    "original_per_prompt_diff = logits_to_ave_logit_diff(original_logits, answer_tokens, per_prompt=True)\n",
    "print(\"Per prompt logit difference:\", original_per_prompt_diff)\n",
    "original_average_logit_diff = logits_to_ave_logit_diff(original_logits, answer_tokens)\n",
    "print(\"Average logit difference:\", original_average_logit_diff)\n",
    "\n",
    "cols = [\n",
    "    \"Prompt\",\n",
    "    Column(\"Correct\", style=\"rgb(0,200,0) bold\"),\n",
    "    Column(\"Incorrect\", style=\"rgb(255,0,0) bold\"),\n",
    "    Column(\"Logit Difference\", style=\"bold\"),\n",
    "]\n",
    "table = Table(*cols, title=\"Logit differences\")\n",
    "\n",
    "for prompt, answer, logit_diff in zip(prompts, answers, original_per_prompt_diff):\n",
    "    table.add_row(prompt, repr(answer[0]), repr(answer[1]), f\"{logit_diff.item():.3f}\")\n",
    "\n",
    "rprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a39f0d78-d502-4df6-9b5e-a8af395acc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer residual directions shape: torch.Size([8, 2, 768])\n",
      "Logit difference directions shape: torch.Size([8, 768])\n"
     ]
    }
   ],
   "source": [
    "answer_residual_directions = model.tokens_to_residual_directions(answer_tokens)  # [batch 2 d_model]\n",
    "print(\"Answer residual directions shape:\", answer_residual_directions.shape)\n",
    "\n",
    "correct_residual_directions, incorrect_residual_directions = answer_residual_directions.unbind(dim=1)\n",
    "logit_diff_directions = correct_residual_directions - incorrect_residual_directions  # [batch d_model]\n",
    "print(\"Logit difference directions shape:\", logit_diff_directions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9cea9c0-f19f-4c96-90ab-83a90eecd36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final residual stream shape: torch.Size([8, 15, 768])\n",
      "Calculated average logit diff: 3.5518696308\n",
      "Original logit difference:     3.5518684387\n"
     ]
    }
   ],
   "source": [
    "# cache syntax - resid_post is the residual stream at the end of the layer, -1 gets the final layer. The general syntax is [activation_name, layer_index, sub_layer_type].\n",
    "final_residual_stream: Float[Tensor, \"batch seq d_model\"] = cache[\"resid_post\", -1]\n",
    "print(f\"Final residual stream shape: {final_residual_stream.shape}\")\n",
    "final_token_residual_stream: Float[Tensor, \"batch d_model\"] = final_residual_stream[:, -1, :]\n",
    "\n",
    "# Apply LayerNorm scaling (to just the final sequence position)\n",
    "# pos_slice is the subset of the positions we take - here the final token of each prompt\n",
    "scaled_final_token_residual_stream = cache.apply_ln_to_stack(final_token_residual_stream, layer=-1, pos_slice=-1)\n",
    "\n",
    "average_logit_diff = einops.einsum(\n",
    "    scaled_final_token_residual_stream, logit_diff_directions, \"batch d_model, batch d_model ->\"\n",
    ") / len(prompts)\n",
    "\n",
    "print(f\"Calculated average logit diff: {average_logit_diff:.10f}\")\n",
    "print(f\"Original logit difference:     {original_average_logit_diff:.10f}\")\n",
    "\n",
    "t.testing.assert_close(average_logit_diff, original_average_logit_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0bfd4d9-9a6b-4b83-86ab-495815145b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_stack_to_logit_diff(\n",
    "    residual_stack: Float[Tensor, \"... batch d_model\"],\n",
    "    cache: ActivationCache,\n",
    "    logit_diff_directions: Float[Tensor, \"batch d_model\"] = logit_diff_directions,\n",
    ") -> Float[Tensor, \"...\"]:\n",
    "    \"\"\"\n",
    "    Gets the avg logit difference between the correct and incorrect answer for a given stack of components in the\n",
    "    residual stream.\n",
    "    \"\"\"\n",
    "    batch_size = residual_stack.size(-2)\n",
    "    scaled_residual_stack = cache.apply_ln_to_stack(residual_stack, layer=-1, pos_slice=-1)\n",
    "    return (\n",
    "        einops.einsum(scaled_residual_stack, logit_diff_directions, \"... batch d_model, batch d_model -> ...\")\n",
    "        / batch_size\n",
    "    )\n",
    "\n",
    "\n",
    "# Test function by checking that it gives the same result as the original logit difference\n",
    "t.testing.assert_close(residual_stack_to_logit_diff(final_token_residual_stream, cache), original_average_logit_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2193830-32ba-4aa0-beeb-8c74e6d09b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_residual, labels = cache.accumulated_resid(layer=-1, incl_mid=True, pos_slice=-1, return_labels=True)\n",
    "# accumulated_residual has shape (component, batch, d_model)\n",
    "\n",
    "logit_lens_logit_diffs: Float[Tensor, \"component\"] = residual_stack_to_logit_diff(accumulated_residual, cache)\n",
    "\n",
    "# line(\n",
    "#     logit_lens_logit_diffs,\n",
    "#     hovermode=\"x unified\",\n",
    "#     title=\"Logit Difference From Accumulated Residual Stream\",\n",
    "#     labels={\"x\": \"Layer\", \"y\": \"Logit Diff\"},\n",
    "#     xaxis_tickvals=labels,\n",
    "#     width=800,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "821def3d-748b-4adf-8951-6a3d6c7eb4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_layer_residual, labels = cache.decompose_resid(layer=-1, pos_slice=-1, return_labels=True)\n",
    "per_layer_logit_diffs = residual_stack_to_logit_diff(per_layer_residual, cache)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93acd998-12db-4243-a507-f90ab80cacfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tried to stack head results when they weren't cached. Computing head results now\n"
     ]
    }
   ],
   "source": [
    "per_head_residual, labels = cache.stack_head_results(layer=-1, pos_slice=-1, return_labels=True)\n",
    "per_head_residual = einops.rearrange(per_head_residual, \"(layer head) ... -> layer head ...\", layer=model.cfg.n_layers)\n",
    "per_head_logit_diffs = residual_stack_to_logit_diff(per_head_residual, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfc755cb-9412-4819-b68b-f054096932af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7a0fe22e8ad0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(per_head_logit_diffs.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "737e0fdc-3eec-4ec6-8c3a-43db0fb83851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Top 3 Positive Logit Attribution Heads</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-cfcfe173-cdba\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-cfcfe173-cdba\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \"When\", \" John\", \" and\", \" Mary\", \" went\", \" to\", \" the\", \" shops\", \",\", \" John\", \" gave\", \" the\", \" bag\", \" to\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9979302883148193, 0.0020696574356406927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9971864819526672, 0.0010516750626266003, 0.001761856721714139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9594851732254028, 0.001310740946792066, 0.03694352135062218, 0.0022604891564697027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891610741615295, 0.0010526456171646714, 0.004854255821555853, 0.0011043800041079521, 0.0038276268169283867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9963597655296326, 0.0007981891976669431, 0.0007764353649690747, 0.00019262675778008997, 0.00024162165937013924, 0.0016313742380589247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9812860488891602, 0.0018638030160218477, 0.006344228982925415, 0.00029609783086925745, 0.004605034366250038, 0.0013967242557555437, 0.00420800969004631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9950010180473328, 0.00132306560408324, 0.0007920842035673559, 0.0002464478893671185, 0.0003405180177651346, 0.00016826413047965616, 0.0002837782958522439, 0.0018447755137458444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9920290112495422, 0.0013540094951167703, 0.0007168457377701998, 9.214348392561078e-05, 0.00013419461902230978, 0.00019706717284861952, 0.00035278929863125086, 0.00024261532234959304, 0.0048812334425747395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5483179092407227, 0.007583828642964363, 0.2826615273952484, 0.002968575805425644, 0.14815659821033478, 0.0008173024980351329, 0.0006479969597421587, 0.0017078632954508066, 0.004129345528781414, 0.0030090559739619493, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8642549514770508, 0.0036493383813649416, 0.004925897810608149, 0.06957487761974335, 0.0386832132935524, 0.009610000997781754, 0.0008548799087293446, 0.0005643124459311366, 0.003707169322296977, 0.0013952977024018764, 0.0027801080141216516, 0.0, 0.0, 0.0, 0.0], [0.30253034830093384, 0.0065845646895468235, 0.14017726480960846, 0.030065806582570076, 0.4806668758392334, 0.0005923672579228878, 0.0005309798289090395, 0.002413487294688821, 0.008505746722221375, 0.0013766398187726736, 0.023765118792653084, 0.002790814731270075, 0.0, 0.0, 0.0], [0.7773902416229248, 0.003722929395735264, 0.02237827703356743, 0.015139562077820301, 0.017408322542905807, 0.002416671020910144, 0.0007095644832588732, 0.0007399633759632707, 0.13850092887878418, 0.0023606563918292522, 0.005776885896921158, 0.0028014297131448984, 0.010654664598405361, 0.0, 0.0], [0.9735957384109497, 0.0012812750646844506, 0.0026179642882198095, 9.892038360703737e-05, 0.0005098591209389269, 0.00012000880087725818, 0.00045230379328131676, 0.0001077986671589315, 0.0029545666184276342, 0.001644411589950323, 0.0012141393963247538, 0.00018637524044606835, 0.0008510933839716017, 0.014365475624799728, 0.0], [0.09903005510568619, 0.0009711061138659716, 0.06413349509239197, 0.005246996413916349, 0.8110386729240417, 8.250449172919616e-05, 6.596904859179631e-05, 0.0011991501087322831, 0.0008852812461555004, 0.00024891449720598757, 0.010336536914110184, 7.952356827445328e-05, 0.004943361505866051, 0.00028919035685248673, 0.0014492335030809045]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9985041618347168, 0.0014959096442908049, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9966639876365662, 0.0004695798270404339, 0.0028664555866271257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9208277463912964, 0.0007845060317777097, 0.0767703428864479, 0.001617366331629455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9835836291313171, 0.0006018328131176531, 0.0030123081523925066, 0.00618812395259738, 0.006614036858081818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9950476884841919, 0.0007798060541972518, 0.0007059494382701814, 0.0003824868763331324, 0.0007798856240697205, 0.00230417144484818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9838818311691284, 0.0015907586785033345, 0.006336260586977005, 0.0004584632406476885, 0.0048299371264874935, 0.0009966776706278324, 0.0019061180064454675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954808950424194, 0.0010436414740979671, 0.0005037526716478169, 0.0005756227183155715, 0.0004619508399628103, 0.0004267240292392671, 0.0006751841283403337, 0.0008320981287397444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9798212051391602, 0.008518300019204617, 0.0010190331377089024, 0.00029933013138361275, 0.0003097988374065608, 0.00033305527176707983, 0.0015420035924762487, 0.0008126543252728879, 0.007344581186771393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6489218473434448, 0.008722413331270218, 0.10266055166721344, 0.003890578169375658, 0.2269505113363266, 0.0011350996792316437, 0.0004588229930959642, 0.00042166849016211927, 0.005373912863433361, 0.001464584842324257, 0.0, 0.0, 0.0, 0.0, 0.0], [0.91560298204422, 0.0013435548171401024, 0.0011674058623611927, 0.04532076045870781, 0.020157957449555397, 0.007576519623398781, 0.001130574499256909, 0.0002488064637873322, 0.004846368916332722, 0.0007249622140079737, 0.0018800573889166117, 0.0, 0.0, 0.0, 0.0], [0.49621060490608215, 0.0019782998133450747, 0.05844201520085335, 0.007836966775357723, 0.4037568271160126, 0.0005728182150050998, 0.00029640106367878616, 0.0009752835612744093, 0.0046508233062922955, 0.0003252352762501687, 0.023185668513178825, 0.0017690022941678762, 0.0, 0.0, 0.0], [0.8397692441940308, 0.0018636860186234117, 0.005577584262937307, 0.020380808040499687, 0.02927330881357193, 0.004448783118277788, 0.0011503307614475489, 0.00024191474949475378, 0.08715201169252396, 0.0013588611036539078, 0.002641631057485938, 0.001926650875248015, 0.004215241875499487, 0.0, 0.0], [0.9744170308113098, 0.002402115846052766, 0.004550540819764137, 0.00020547828171402216, 0.0026625171303749084, 0.00021827245655003935, 0.0008242573821917176, 0.00040549799450673163, 0.0026430434081703424, 0.001523563521914184, 0.003108841832727194, 7.676507084397599e-05, 0.0018502764869481325, 0.0051118009723722935, 0.0], [0.1847032755613327, 0.00038850854616612196, 0.06518135219812393, 0.0014534833608195186, 0.731876015663147, 0.00010888417455134913, 2.748586848611012e-05, 0.00011231117241550237, 0.001367211458273232, 4.01623583456967e-05, 0.01254377979785204, 5.958610199741088e-05, 0.0007756513659842312, 0.0010575471678748727, 0.00030486308969557285]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9776752591133118, 0.022324776276946068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9430756568908691, 0.018822958692908287, 0.038101375102996826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.896321177482605, 0.006171706598252058, 0.07676305621862411, 0.02074412815272808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8522241711616516, 0.017844323068857193, 0.05478629469871521, 0.012976141646504402, 0.062169015407562256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9669023752212524, 0.004049539566040039, 0.0020623207092285156, 0.007766348775476217, 0.007081771269440651, 0.01213759370148182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7676399350166321, 0.018502196297049522, 0.045012932270765305, 0.012471646070480347, 0.10591268539428711, 0.018323473632335663, 0.03213706612586975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8918291926383972, 0.010069557465612888, 0.013089951127767563, 0.01068512350320816, 0.031169114634394646, 0.006502206437289715, 0.021038364619016647, 0.01561648491770029, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.945720911026001, 0.004500505514442921, 0.013905851170420647, 0.0013248930918052793, 0.015576539561152458, 0.0011156953405588865, 0.0007837468292564154, 0.0007244523731060326, 0.01634732447564602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5131949186325073, 0.006032093893736601, 0.11406749486923218, 0.009519193321466446, 0.3061319589614868, 0.003442242043092847, 0.002601660555228591, 0.002665372099727392, 0.03412357717752457, 0.00822147261351347, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8395135998725891, 0.008326195180416107, 0.012920821085572243, 0.012827681377530098, 0.02993439882993698, 0.013884013518691063, 0.003483882173895836, 0.0018691428704187274, 0.039465803653001785, 0.011843939311802387, 0.02593047358095646, 0.0, 0.0, 0.0, 0.0], [0.35850244760513306, 0.004236225970089436, 0.10680357366800308, 0.015598638914525509, 0.41607749462127686, 0.0024919225834310055, 0.003585710423067212, 0.003899891395121813, 0.015854986384510994, 0.005938132293522358, 0.06202777475118637, 0.00498326076194644, 0.0, 0.0, 0.0], [0.612543523311615, 0.004679457750171423, 0.029155263677239418, 0.02824036218225956, 0.0825885534286499, 0.007909809239208698, 0.011129301972687244, 0.0034775754902511835, 0.17027777433395386, 0.010538891889154911, 0.015773490071296692, 0.013294965028762817, 0.01039106771349907, 0.0, 0.0], [0.8758103847503662, 0.007089299149811268, 0.012082770466804504, 0.002599594183266163, 0.02126934751868248, 0.0016535613685846329, 0.001903663040138781, 0.0016309920465573668, 0.028230536729097366, 0.008473532274365425, 0.011080275289714336, 0.0027609430253505707, 0.0025940928608179092, 0.022820932790637016, 0.0], [0.5415257215499878, 0.003397527849301696, 0.03888292983174324, 0.007577119395136833, 0.36139047145843506, 0.0013810622040182352, 0.0010475171729922295, 0.0012340109096840024, 0.006947673857212067, 0.003757003229111433, 0.017671890556812286, 0.0011743915965780616, 0.0036232604179531336, 0.002192464889958501, 0.008196891285479069]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7a0fbcd133d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Top 3 Negative Logit Attribution Heads</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-d7193f0c-4920\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.3/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-d7193f0c-4920\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \"When\", \" John\", \" and\", \" Mary\", \" went\", \" to\", \" the\", \" shops\", \",\", \" John\", \" gave\", \" the\", \" bag\", \" to\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9628916382789612, 0.03710830211639404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.97783362865448, 0.0034863885957747698, 0.018679950386285782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8737695813179016, 0.005964324343949556, 0.08126766979694366, 0.03899839147925377, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8745142221450806, 0.01727614365518093, 0.018874641507864, 0.05426820367574692, 0.035066869109869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9704692363739014, 0.0035177874378859997, 0.0003239824727643281, 0.004373450763523579, 0.00039530108915641904, 0.020920265465974808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7694652676582336, 0.006685873959213495, 0.011966489255428314, 0.040966205298900604, 0.03344452381134033, 0.0440102182328701, 0.09346141666173935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8177720308303833, 0.009112606756389141, 0.0042336732149124146, 0.03900322690606117, 0.012653290294110775, 0.007337829098105431, 0.0741003155708313, 0.03578704595565796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8309930562973022, 0.0187966488301754, 0.0033032651990652084, 0.01983211375772953, 0.004009494557976723, 0.012078325264155865, 0.03246011212468147, 0.010322291404008865, 0.06820466369390488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3140319287776947, 0.015227881260216236, 0.19789326190948486, 0.059379372745752335, 0.32360535860061646, 0.009037692099809647, 0.01991768553853035, 0.012475235387682915, 0.013939538970589638, 0.03449206054210663, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7319567799568176, 0.030870404094457626, 0.005064097233116627, 0.08703793585300446, 0.0049827429465949535, 0.0447254441678524, 0.02350630611181259, 0.00639777397736907, 0.003469679271802306, 0.04865330085158348, 0.013335555791854858, 0.0, 0.0, 0.0, 0.0], [0.1371050924062729, 0.012017916887998581, 0.14592409133911133, 0.015683425590395927, 0.44125211238861084, 0.004342435393482447, 0.011117907240986824, 0.007466595154255629, 0.0012341596884652972, 0.01946013793349266, 0.16842901706695557, 0.035967182368040085, 0.0, 0.0, 0.0], [0.4052470028400421, 0.009720957837998867, 0.031581368297338486, 0.09247094392776489, 0.048808492720127106, 0.008174197748303413, 0.031708355993032455, 0.02787911705672741, 0.1412813514471054, 0.030233988538384438, 0.03392869606614113, 0.031713880598545074, 0.10725171864032745, 0.0, 0.0], [0.808469831943512, 0.005670273210853338, 0.006755990907549858, 0.008696549572050571, 0.010473433881998062, 0.0034647106658667326, 0.006760985590517521, 0.002588916104286909, 0.015097683295607567, 0.016035962849855423, 0.011288031004369259, 0.017277320846915245, 0.007799158338457346, 0.07962114363908768, 0.0], [0.029390787705779076, 0.001606046687811613, 0.06005566567182541, 0.008175662718713284, 0.8099172711372375, 0.00039796120836399496, 0.002828239928930998, 0.0033632414415478706, 0.00015690879081375897, 0.003645898075774312, 0.054940614849328995, 0.0016660233959555626, 0.015368876047432423, 5.016613067709841e-05, 0.008436694741249084]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9124022722244263, 0.08759771287441254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.97407466173172, 0.014344141818583012, 0.011581209488213062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8240238428115845, 0.03700514882802963, 0.06644025444984436, 0.07253081351518631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.537079393863678, 0.15483354032039642, 0.0903128907084465, 0.12131211906671524, 0.09646201133728027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9388002157211304, 0.02873316779732704, 0.00034310188493691385, 0.010481216013431549, 0.0008399254293181002, 0.020802341401576996, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.631881058216095, 0.05930289253592491, 0.035179253667593, 0.0317409485578537, 0.11746842414140701, 0.06869626045227051, 0.0557311549782753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7625215649604797, 0.04435176029801369, 0.010552995838224888, 0.034276317805051804, 0.01420392282307148, 0.012703560292720795, 0.07259674370288849, 0.048793137073516846, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5725992918014526, 0.12681788206100464, 0.03727070987224579, 0.04314146563410759, 0.041295696049928665, 0.04644741117954254, 0.02916431799530983, 0.03751206770539284, 0.06575114279985428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12316957861185074, 0.02634713239967823, 0.27960649132728577, 0.04198963940143585, 0.44105640053749084, 0.006138985976576805, 0.007793010678142309, 0.007175319362431765, 0.011286850087344646, 0.05543657764792442, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4485587179660797, 0.14324873685836792, 0.010774288326501846, 0.07855074107646942, 0.014047852717339993, 0.01486463937908411, 0.008633689023554325, 0.003014681627973914, 0.012792154215276241, 0.16408570110797882, 0.1014288142323494, 0.0, 0.0, 0.0, 0.0], [0.10228115320205688, 0.023883281275629997, 0.05525115877389908, 0.05206834152340889, 0.5759828686714172, 0.0011948102619498968, 0.0013662487035617232, 0.0025677932426333427, 0.0018699943320825696, 0.04316004738211632, 0.10887309908866882, 0.031501125544309616, 0.0, 0.0, 0.0], [0.3931322395801544, 0.04406285285949707, 0.04009920731186867, 0.07407452911138535, 0.04061642289161682, 0.007346804719418287, 0.009507193230092525, 0.0138652753084898, 0.0640539601445198, 0.048942387104034424, 0.06277528405189514, 0.0999642163515091, 0.10155955702066422, 0.0, 0.0], [0.7573202252388, 0.015095751732587814, 0.007350183557718992, 0.013156462460756302, 0.0057263984344899654, 0.008556436747312546, 0.008282599970698357, 0.010307138785719872, 0.002904886845499277, 0.017329098656773567, 0.015188907273113728, 0.07965701073408127, 0.03024440072476864, 0.028880400583148003, 0.0], [0.08579465001821518, 0.023773645982146263, 0.02875984087586403, 0.050304073840379715, 0.6746447086334229, 0.0010763874743133783, 0.0011514846701174974, 0.002721977885812521, 0.0005617660353891551, 0.03909147158265114, 0.048620060086250305, 0.015520035289227962, 0.004084523301571608, 0.00043291322072036564, 0.023462524637579918]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9691730737686157, 0.030826952308416367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9864584803581238, 0.007659855764359236, 0.0058815740048885345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9318374991416931, 0.011915609240531921, 0.020531827583909035, 0.03571503609418869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8786703944206238, 0.034276023507118225, 0.01315788272768259, 0.027051273733377457, 0.046844497323036194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9850097298622131, 0.005019488278776407, 0.0013920110650360584, 0.0018760517705231905, 0.0041711218655109406, 0.0025315748061984777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8907086849212646, 0.020262572914361954, 0.02090451493859291, 0.00913463905453682, 0.040578145533800125, 0.003215117147192359, 0.015196310356259346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9318528175354004, 0.012423844076693058, 0.007052895613014698, 0.006267641205340624, 0.00971571821719408, 0.0013882764615118504, 0.012697519734501839, 0.018601160496473312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7722938060760498, 0.03829515352845192, 0.039436422288417816, 0.00972924754023552, 0.11019407957792282, 0.00977348629385233, 0.0088681410998106, 0.003977757878601551, 0.007432024925947189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.665926992893219, 0.019893761724233627, 0.057482343167066574, 0.026046596467494965, 0.18978683650493622, 0.001734031829982996, 0.004116138443350792, 0.004545135423541069, 0.007496092468500137, 0.022972136735916138, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8588332533836365, 0.018521588295698166, 0.010080354288220406, 0.016174644231796265, 0.044801272451877594, 0.018235506489872932, 0.002693294547498226, 0.0009044691687449813, 0.0043382528237998486, 0.010200370103120804, 0.015216940082609653, 0.0, 0.0, 0.0, 0.0], [0.7452793717384338, 0.02059231884777546, 0.03344888240098953, 0.04560337960720062, 0.09397704899311066, 0.0019108090782538056, 0.003916213288903236, 0.004672226030379534, 0.0032161050476133823, 0.018068086355924606, 0.016300618648529053, 0.013014956377446651, 0.0, 0.0, 0.0], [0.7450798749923706, 0.016003012657165527, 0.025643333792686462, 0.03000515140593052, 0.0669110044836998, 0.003224311862140894, 0.006530732847750187, 0.006865643430501223, 0.043553367257118225, 0.012662963010370731, 0.010547313839197159, 0.010315618477761745, 0.022657662630081177, 0.0, 0.0], [0.836358904838562, 0.01351254153996706, 0.016558749601244926, 0.008880327455699444, 0.056306950747966766, 0.0022557538468390703, 0.002398413373157382, 0.0012933540856465697, 0.003150224918499589, 0.013540887273848057, 0.0216501634567976, 0.005392769817262888, 0.004322773776948452, 0.014378229156136513, 0.0], [0.7888540625572205, 0.014087649993598461, 0.02216111309826374, 0.04220639914274216, 0.06532423943281174, 0.001114497659727931, 0.0019568083807826042, 0.002514245454221964, 0.0014487040461972356, 0.012026156298816204, 0.0096076475456357, 0.006895543076097965, 0.004557115025818348, 0.0032633584924042225, 0.023982439190149307]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7a0fbcd604d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def topk_of_Nd_tensor(tensor: Float[Tensor, \"rows cols\"], k: int):\n",
    "    \"\"\"\n",
    "    Helper function: does same as tensor.topk(k).indices, but works over 2D tensors.\n",
    "    Returns a list of indices, i.e. shape [k, tensor.ndim].\n",
    "\n",
    "    Example: if tensor is 2D array of values for each head in each layer, this will\n",
    "    return a list of heads.\n",
    "    \"\"\"\n",
    "    i = t.topk(tensor.flatten(), k).indices\n",
    "    return np.array(np.unravel_index(utils.to_numpy(i), tensor.shape)).T.tolist()\n",
    "\n",
    "\n",
    "k = 3\n",
    "\n",
    "for head_type in [\"Positive\", \"Negative\"]:\n",
    "    # Get the heads with largest (or smallest) contribution to the logit difference\n",
    "    top_heads = topk_of_Nd_tensor(per_head_logit_diffs * (1 if head_type == \"Positive\" else -1), k)\n",
    "\n",
    "    # Get all their attention patterns\n",
    "    attn_patterns_for_important_heads: Float[Tensor, \"head q k\"] = t.stack(\n",
    "        [cache[\"pattern\", layer][:, head][0] for layer, head in top_heads]\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    display(HTML(f\"<h2>Top {k} {head_type} Logit Attribution Heads</h2>\"))\n",
    "    display(\n",
    "        cv.attention.attention_patterns(\n",
    "            attention=attn_patterns_for_important_heads,\n",
    "            tokens=model.to_str_tokens(tokens[0]),\n",
    "            # attention_head_names=[f\"{layer}.{head}\" for layer, head in top_heads],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d1ebe02-a1f9-4bc2-ae7d-b7272e4c57a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.attention.attention_patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ece798f-d205-4456-8dbc-4ba1b8e1323b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 7], [11, 10], [11, 2]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b4ea1e-8639-4864-8f04-502bc091c1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afa87d4-902b-4f45-80ef-9d8e633967dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e108a7-fa36-417c-a763-453e9e11dbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c38a13-22e3-4d41-b9d8-a1eb7e67d557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82652936-9769-49ac-b500-e542fd7a5f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "688cf1c9-295c-4caa-b67d-1b1a3cd6abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import ActivationCache, HookedTransformer, utils\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdea8c0d-9a6f-4953-b502-19ec05851596",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f5f13a-6687-428c-a145-e16c1f5fe433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model meta-llama/Llama-3.2-1B into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"meta-llama/Llama-3.2-1B\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c9b0ad-2b69-4317-b2ef-4b3ad1e7e05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|begin_of_text|>', 'The', ' capital', ' of', ' France', ' is']\n",
      "Tokenized answer: [' Paris']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.43</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39.08</span><span style=\"font-weight: bold\">% Token: | Paris|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m18.43\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m39.08\u001b[0m\u001b[1m% Token: | Paris|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 18.43 Prob: 39.08% Token: | Paris|\n",
      "Top 1th token. Logit: 16.89 Prob:  8.43% Token: | a|\n",
      "Top 2th token. Logit: 16.71 Prob:  7.05% Token: | the|\n",
      "Top 3th token. Logit: 15.89 Prob:  3.10% Token: | one|\n",
      "Top 4th token. Logit: 15.88 Prob:  3.06% Token: | also|\n",
      "Top 5th token. Logit: 15.69 Prob:  2.53% Token: | home|\n",
      "Top 6th token. Logit: 15.66 Prob:  2.46% Token: | known|\n",
      "Top 7th token. Logit: 15.27 Prob:  1.66% Token: | not|\n",
      "Top 8th token. Logit: 14.98 Prob:  1.24% Token: | an|\n",
      "Top 9th token. Logit: 14.92 Prob:  1.17% Token: | often|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Paris'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Paris'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"The capital of France is\"\n",
    "answer = \" Paris\"\n",
    "utils.test_prompt(prompt, answer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d1395-aa69-42cf-88c9-68a3fad1adba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "968c64eb-94a1-473f-a06a-5489d3ee435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The capital of France is Paris\"\n",
    "tokens = model.to_tokens(text)\n",
    "# logits, cache = model.run_with_cache(tokens, remove_batch_dim=True)\n",
    "original_logits, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e692d70f-fc38-4c29-8cb6-1852a4566204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 7, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['blocks.0.attn.hook_attn_scores'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe301703-4496-4162-8900-d8e588168e05",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answer_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlogits_to_ave_logit_diff\u001b[39m(\n\u001b[32m      2\u001b[39m     logits: Float[Tensor, \u001b[33m\"\u001b[39m\u001b[33mbatch seq d_vocab\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     answer_tokens: Float[Tensor, \u001b[33m\"\u001b[39m\u001b[33mbatch 2\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43manswer_tokens\u001b[49m,\n\u001b[32m      4\u001b[39m     per_prompt: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m      5\u001b[39m ) -> Float[Tensor, \u001b[33m\"\u001b[39m\u001b[33m*batch\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      6\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    Returns logit difference between the correct and incorrect answer.\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[33;03m    If per_prompt=True, return the array of differences rather than the average.\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Only the final logits are relevant for the answer\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'answer_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "def logits_to_ave_logit_diff(\n",
    "    logits: Float[Tensor, \"batch seq d_vocab\"],\n",
    "    answer_tokens: Float[Tensor, \"batch 2\"] = answer_tokens,\n",
    "    per_prompt: bool = False,\n",
    ") -> Float[Tensor, \"*batch\"]:\n",
    "    \"\"\"\n",
    "    Returns logit difference between the correct and incorrect answer.\n",
    "\n",
    "    If per_prompt=True, return the array of differences rather than the average.\n",
    "    \"\"\"\n",
    "    # Only the final logits are relevant for the answer\n",
    "    final_logits: Float[Tensor, \"batch d_vocab\"] = logits[:, -1, :]\n",
    "    # Get the logits corresponding to the indirect object / subject tokens respectively\n",
    "    answer_logits: Float[Tensor, \"batch 2\"] = final_logits.gather(dim=-1, index=answer_tokens)\n",
    "    # Find logit difference\n",
    "    correct_logits, incorrect_logits = answer_logits.unbind(dim=-1)\n",
    "    answer_logit_diff = correct_logits - incorrect_logits\n",
    "    return answer_logit_diff if per_prompt else answer_logit_diff.mean()\n",
    "\n",
    "\n",
    "tests.test_logits_to_ave_logit_diff(logits_to_ave_logit_diff)\n",
    "\n",
    "original_per_prompt_diff = logits_to_ave_logit_diff(original_logits, answer_tokens, per_prompt=True)\n",
    "print(\"Per prompt logit difference:\", original_per_prompt_diff)\n",
    "original_average_logit_diff = logits_to_ave_logit_diff(original_logits, answer_tokens)\n",
    "print(\"Average logit difference:\", original_average_logit_diff)\n",
    "\n",
    "cols = [\n",
    "    \"Prompt\",\n",
    "    Column(\"Correct\", style=\"rgb(0,200,0) bold\"),\n",
    "    Column(\"Incorrect\", style=\"rgb(255,0,0) bold\"),\n",
    "    Column(\"Logit Difference\", style=\"bold\"),\n",
    "]\n",
    "table = Table(*cols, title=\"Logit differences\")\n",
    "\n",
    "for prompt, answer, logit_diff in zip(prompts, answers, original_per_prompt_diff):\n",
    "    table.add_row(prompt, repr(answer[0]), repr(answer[1]), f\"{logit_diff.item():.3f}\")\n",
    "\n",
    "rprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e984d-7c5f-45ed-aa15-184e201d0025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d218df53-af99-4fad-888e-f277d9a84c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302424e9-0d98-4a40-8bbc-5efc0139c00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b01809c-c187-4b5a-8f66-afc4fbab7f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace847b4-1964-4dfc-b813-42b90a6d44ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceed866-9cf0-4992-81c2-50e522b224a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443fe704-576f-4e6e-9e2a-2b951e6d578b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e8f8b7d-b672-4dbf-a122-fd4f300f21a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logit_diff_directions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresidual_stack_to_logit_diff\u001b[39m(\n\u001b[32m      2\u001b[39m     residual_stack: Float[Tensor, \u001b[33m\"\u001b[39m\u001b[33m... batch d_model\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      3\u001b[39m     cache: ActivationCache,\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     logit_diff_directions: Float[Tensor, \u001b[33m\"\u001b[39m\u001b[33mbatch d_model\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mlogit_diff_directions\u001b[49m,\n\u001b[32m      5\u001b[39m ) -> Float[Tensor, \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      6\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    Gets the avg logit difference between the correct and incorrect answer for a given stack of components in the\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m    residual stream.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     10\u001b[39m     batch_size = residual_stack.size(-\u001b[32m2\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'logit_diff_directions' is not defined"
     ]
    }
   ],
   "source": [
    "def residual_stack_to_logit_diff(\n",
    "    residual_stack: Float[Tensor, \"... batch d_model\"],\n",
    "    cache: ActivationCache,\n",
    "    logit_diff_directions: Float[Tensor, \"batch d_model\"] = logit_diff_directions,\n",
    ") -> Float[Tensor, \"...\"]:\n",
    "    \"\"\"\n",
    "    Gets the avg logit difference between the correct and incorrect answer for a given stack of components in the\n",
    "    residual stream.\n",
    "    \"\"\"\n",
    "    batch_size = residual_stack.size(-2)\n",
    "    scaled_residual_stack = cache.apply_ln_to_stack(residual_stack, layer=-1, pos_slice=-1)\n",
    "    return (\n",
    "        einops.einsum(scaled_residual_stack, logit_diff_directions, \"... batch d_model, batch d_model -> ...\")\n",
    "        / batch_size\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cb62e1e-f673-4c68-b608-a36f96127cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tried to stack head results when they weren't cached. Computing head results now\n"
     ]
    }
   ],
   "source": [
    "per_head_residual, labels = cache.stack_head_results(layer=-1, pos_slice=-1, return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0907897f-f5c1-4edd-994f-cb795c5ebe28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 2048])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_head_residual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2abefc95-328a-40c6-825d-1dc189533509",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_head_residual = einops.rearrange(per_head_residual, \"(layer head) ... -> layer head ...\", layer=model.cfg.n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e30dd54f-9f2c-4e6f-9a81-85e54e723ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 2048])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_head_residual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e89166f3-af26-4997-92a4-ba627de4f6a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'residual_stack_to_logit_diff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m per_head_logit_diffs = \u001b[43mresidual_stack_to_logit_diff\u001b[49m(per_head_residual, cache)\n",
      "\u001b[31mNameError\u001b[39m: name 'residual_stack_to_logit_diff' is not defined"
     ]
    }
   ],
   "source": [
    "per_head_logit_diffs = residual_stack_to_logit_diff(per_head_residual, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d10ad-e6e4-4a0a-b9f7-25e332b44a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2645817b-b4ac-4987-8d25-d62c6733b8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2684103-6802-424d-a0f9-148e03ef0ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa9b455-8be0-4084-ae50-d032f3f4b29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a646f2-c18c-4449-ab41-70434fbae947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5ec6c5f-1cff-426e-b345-94d8722d1049",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8ed48-a686-4847-bfe6-5bdf482623ed",
   "metadata": {},
   "source": [
    "- Hmm may want to omit the BOS token, we'll see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c321f7-7ef9-44b2-af87-815e43f4ee70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1423,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "        [ 7.9602,  6.1469,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "        [ 7.4229,  7.5983,  5.2591,    -inf,    -inf,    -inf,    -inf],\n",
       "        [ 9.6763, 11.3018,  8.9480,  7.3416,    -inf,    -inf,    -inf],\n",
       "        [ 7.1744,  6.5851,  6.5272,  6.5630,  5.7304,    -inf,    -inf],\n",
       "        [ 9.6897,  9.7189,  9.3344, 10.3011,  8.9203,  7.9233,    -inf],\n",
       "        [ 7.1293,  4.9105,  5.1334,  5.6712,  6.1795,  6.0592,  5.5973]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['blocks.0.attn.hook_attn_scores'].detach().cpu()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c163d-0a65-44b7-b988-32aefc8923ed",
   "metadata": {},
   "source": [
    "- Hmm so, becuase these suckers have been softmaxed, it's going to abe a little difficult to figure out which is \"most imporrtant\", right? Maybe this is where the gradients come in -> seems like the output attention matrix weights/activations/gradients could be pretty important here...\n",
    "- Maybe we decouple looking at MLP vs attention temporarily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09525f29-4130-4278-b1dd-d79f56ba0120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 8192])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['blocks.0.mlp.hook_pre'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b55fe86-421d-49a8-b592-083bc394f134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 8192])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['blocks.0.mlp.hook_pre_linear'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a91e8c1-9b94-4892-904c-178f013e2b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 8192])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['blocks.0.mlp.hook_post'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a0e25c5-49dc-4474-a975-df2772d67bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 2048])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['blocks.0.hook_mlp_out'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a9dc75f-22c6-4d1a-8d22-af640a9f2842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0.attn.hook_q torch.Size([7, 32, 64])\n",
      "blocks.0.attn.hook_k torch.Size([7, 8, 64])\n",
      "blocks.0.attn.hook_v torch.Size([7, 8, 64])\n",
      "blocks.0.attn.hook_rot_q torch.Size([7, 32, 64])\n",
      "blocks.0.attn.hook_rot_k torch.Size([7, 8, 64])\n",
      "blocks.0.attn.hook_attn_scores torch.Size([32, 7, 7])\n",
      "blocks.0.attn.hook_pattern torch.Size([32, 7, 7])\n",
      "blocks.0.attn.hook_z torch.Size([7, 32, 64])\n",
      "blocks.0.hook_attn_out torch.Size([7, 2048])\n"
     ]
    }
   ],
   "source": [
    "keys=['blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_rot_q', 'blocks.0.attn.hook_rot_k', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out']\n",
    "for k in keys: \n",
    "    print(k, cache[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e95cc7e4-a66f-4686-b577-87f540ad4001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8598, 0.1402, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4335, 0.5166, 0.0498, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1501, 0.7628, 0.0725, 0.0145, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3500, 0.1942, 0.1833, 0.1899, 0.0826, 0.0000, 0.0000],\n",
       "        [0.1920, 0.1977, 0.1346, 0.3539, 0.0890, 0.0328, 0.0000],\n",
       "        [0.4127, 0.0449, 0.0561, 0.0960, 0.1596, 0.1415, 0.0892]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['blocks.0.attn.hook_pattern'].detach().cpu()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62245149-46f8-4f4f-bc0a-40368de811f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_params = {name: p for name, p in model.named_parameters() if p.requires_grad}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b03c08d8-01e9-4307-9635-acdf6deab08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 2048])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_params['blocks.0.attn.W_O'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82239bfd-3811-454a-9cf0-2bbe78ce320b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['embed.W_E', 'blocks.0.attn.W_Q', 'blocks.0.attn.W_O', 'blocks.0.attn.b_Q', 'blocks.0.attn.b_O', 'blocks.0.attn._W_K', 'blocks.0.attn._W_V', 'blocks.0.attn._b_K', 'blocks.0.attn._b_V', 'blocks.0.mlp.W_in', 'blocks.0.mlp.W_out', 'blocks.0.mlp.W_gate', 'blocks.0.mlp.b_in', 'blocks.0.mlp.b_out', 'blocks.1.attn.W_Q', 'blocks.1.attn.W_O', 'blocks.1.attn.b_Q', 'blocks.1.attn.b_O', 'blocks.1.attn._W_K', 'blocks.1.attn._W_V', 'blocks.1.attn._b_K', 'blocks.1.attn._b_V', 'blocks.1.mlp.W_in', 'blocks.1.mlp.W_out', 'blocks.1.mlp.W_gate', 'blocks.1.mlp.b_in', 'blocks.1.mlp.b_out', 'blocks.2.attn.W_Q', 'blocks.2.attn.W_O', 'blocks.2.attn.b_Q', 'blocks.2.attn.b_O', 'blocks.2.attn._W_K', 'blocks.2.attn._W_V', 'blocks.2.attn._b_K', 'blocks.2.attn._b_V', 'blocks.2.mlp.W_in', 'blocks.2.mlp.W_out', 'blocks.2.mlp.W_gate', 'blocks.2.mlp.b_in', 'blocks.2.mlp.b_out', 'blocks.3.attn.W_Q', 'blocks.3.attn.W_O', 'blocks.3.attn.b_Q', 'blocks.3.attn.b_O', 'blocks.3.attn._W_K', 'blocks.3.attn._W_V', 'blocks.3.attn._b_K', 'blocks.3.attn._b_V', 'blocks.3.mlp.W_in', 'blocks.3.mlp.W_out', 'blocks.3.mlp.W_gate', 'blocks.3.mlp.b_in', 'blocks.3.mlp.b_out', 'blocks.4.attn.W_Q', 'blocks.4.attn.W_O', 'blocks.4.attn.b_Q', 'blocks.4.attn.b_O', 'blocks.4.attn._W_K', 'blocks.4.attn._W_V', 'blocks.4.attn._b_K', 'blocks.4.attn._b_V', 'blocks.4.mlp.W_in', 'blocks.4.mlp.W_out', 'blocks.4.mlp.W_gate', 'blocks.4.mlp.b_in', 'blocks.4.mlp.b_out', 'blocks.5.attn.W_Q', 'blocks.5.attn.W_O', 'blocks.5.attn.b_Q', 'blocks.5.attn.b_O', 'blocks.5.attn._W_K', 'blocks.5.attn._W_V', 'blocks.5.attn._b_K', 'blocks.5.attn._b_V', 'blocks.5.mlp.W_in', 'blocks.5.mlp.W_out', 'blocks.5.mlp.W_gate', 'blocks.5.mlp.b_in', 'blocks.5.mlp.b_out', 'blocks.6.attn.W_Q', 'blocks.6.attn.W_O', 'blocks.6.attn.b_Q', 'blocks.6.attn.b_O', 'blocks.6.attn._W_K', 'blocks.6.attn._W_V', 'blocks.6.attn._b_K', 'blocks.6.attn._b_V', 'blocks.6.mlp.W_in', 'blocks.6.mlp.W_out', 'blocks.6.mlp.W_gate', 'blocks.6.mlp.b_in', 'blocks.6.mlp.b_out', 'blocks.7.attn.W_Q', 'blocks.7.attn.W_O', 'blocks.7.attn.b_Q', 'blocks.7.attn.b_O', 'blocks.7.attn._W_K', 'blocks.7.attn._W_V', 'blocks.7.attn._b_K', 'blocks.7.attn._b_V', 'blocks.7.mlp.W_in', 'blocks.7.mlp.W_out', 'blocks.7.mlp.W_gate', 'blocks.7.mlp.b_in', 'blocks.7.mlp.b_out', 'blocks.8.attn.W_Q', 'blocks.8.attn.W_O', 'blocks.8.attn.b_Q', 'blocks.8.attn.b_O', 'blocks.8.attn._W_K', 'blocks.8.attn._W_V', 'blocks.8.attn._b_K', 'blocks.8.attn._b_V', 'blocks.8.mlp.W_in', 'blocks.8.mlp.W_out', 'blocks.8.mlp.W_gate', 'blocks.8.mlp.b_in', 'blocks.8.mlp.b_out', 'blocks.9.attn.W_Q', 'blocks.9.attn.W_O', 'blocks.9.attn.b_Q', 'blocks.9.attn.b_O', 'blocks.9.attn._W_K', 'blocks.9.attn._W_V', 'blocks.9.attn._b_K', 'blocks.9.attn._b_V', 'blocks.9.mlp.W_in', 'blocks.9.mlp.W_out', 'blocks.9.mlp.W_gate', 'blocks.9.mlp.b_in', 'blocks.9.mlp.b_out', 'blocks.10.attn.W_Q', 'blocks.10.attn.W_O', 'blocks.10.attn.b_Q', 'blocks.10.attn.b_O', 'blocks.10.attn._W_K', 'blocks.10.attn._W_V', 'blocks.10.attn._b_K', 'blocks.10.attn._b_V', 'blocks.10.mlp.W_in', 'blocks.10.mlp.W_out', 'blocks.10.mlp.W_gate', 'blocks.10.mlp.b_in', 'blocks.10.mlp.b_out', 'blocks.11.attn.W_Q', 'blocks.11.attn.W_O', 'blocks.11.attn.b_Q', 'blocks.11.attn.b_O', 'blocks.11.attn._W_K', 'blocks.11.attn._W_V', 'blocks.11.attn._b_K', 'blocks.11.attn._b_V', 'blocks.11.mlp.W_in', 'blocks.11.mlp.W_out', 'blocks.11.mlp.W_gate', 'blocks.11.mlp.b_in', 'blocks.11.mlp.b_out', 'blocks.12.attn.W_Q', 'blocks.12.attn.W_O', 'blocks.12.attn.b_Q', 'blocks.12.attn.b_O', 'blocks.12.attn._W_K', 'blocks.12.attn._W_V', 'blocks.12.attn._b_K', 'blocks.12.attn._b_V', 'blocks.12.mlp.W_in', 'blocks.12.mlp.W_out', 'blocks.12.mlp.W_gate', 'blocks.12.mlp.b_in', 'blocks.12.mlp.b_out', 'blocks.13.attn.W_Q', 'blocks.13.attn.W_O', 'blocks.13.attn.b_Q', 'blocks.13.attn.b_O', 'blocks.13.attn._W_K', 'blocks.13.attn._W_V', 'blocks.13.attn._b_K', 'blocks.13.attn._b_V', 'blocks.13.mlp.W_in', 'blocks.13.mlp.W_out', 'blocks.13.mlp.W_gate', 'blocks.13.mlp.b_in', 'blocks.13.mlp.b_out', 'blocks.14.attn.W_Q', 'blocks.14.attn.W_O', 'blocks.14.attn.b_Q', 'blocks.14.attn.b_O', 'blocks.14.attn._W_K', 'blocks.14.attn._W_V', 'blocks.14.attn._b_K', 'blocks.14.attn._b_V', 'blocks.14.mlp.W_in', 'blocks.14.mlp.W_out', 'blocks.14.mlp.W_gate', 'blocks.14.mlp.b_in', 'blocks.14.mlp.b_out', 'blocks.15.attn.W_Q', 'blocks.15.attn.W_O', 'blocks.15.attn.b_Q', 'blocks.15.attn.b_O', 'blocks.15.attn._W_K', 'blocks.15.attn._W_V', 'blocks.15.attn._b_K', 'blocks.15.attn._b_V', 'blocks.15.mlp.W_in', 'blocks.15.mlp.W_out', 'blocks.15.mlp.W_gate', 'blocks.15.mlp.b_in', 'blocks.15.mlp.b_out', 'unembed.W_U', 'unembed.b_U'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacbbf32-62ea-4a71-95e9-1b3ba6498e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e58ef-87af-47ff-83e2-d5fe774de27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
