{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dca83bcd-d0d9-44be-908c-78d4953993df",
   "metadata": {},
   "source": [
    "## P39 to 41 Search Pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95824e0f-303c-487b-9d95-3e59845547ff",
   "metadata": {},
   "source": [
    "- Ok ok ok ok ok\n",
    "- Time to nail down 2-4 interestin directions in parameter space\n",
    "- I want to put 2 together to make a cool/interesting global view\n",
    "- Then I'll need to fake gradient descent on that, that should be interesting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78825418-ec35-4d73-8f01-068056ca3525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install transformers matplotlib tqdm huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0925ca-23d1-4c94-81d7-b610765110ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdbd896-7f3d-4486-b684-25f4d5f95e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "from transformers import LlamaForCausalLM, PreTrainedTokenizerFast, LlamaConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5f0ed4-cfe9-426e-a6c7-58ffe7ecea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "# model_id = \"openai-community/gpt2\"\n",
    "# model_id = \"google/gemma-3-1b-pt\"\n",
    "# model_id = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1548715-dfc6-415e-a4e8-3a005998226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Only needed for llama random initialization\n",
    "# config_dict = {\n",
    "#   \"_attn_implementation_autoset\": True,\n",
    "#   \"architectures\": [\n",
    "#     \"LlamaForCausalLM\"\n",
    "#   ],\n",
    "#   \"attention_bias\": False,\n",
    "#   \"attention_dropout\": 0.0,\n",
    "#   \"bos_token_id\": 128000,\n",
    "#   \"eos_token_id\": 128001,\n",
    "#   \"head_dim\": 64,\n",
    "#   \"hidden_act\": \"silu\",\n",
    "#   \"hidden_size\": 2048,\n",
    "#   \"initializer_range\": 0.02,\n",
    "#   \"intermediate_size\": 8192,\n",
    "#   \"max_position_embeddings\": 131072,\n",
    "#   \"mlp_bias\": False,\n",
    "#   \"model_type\": \"llama\",\n",
    "#   \"num_attention_heads\": 32,\n",
    "#   \"num_hidden_layers\": 16,\n",
    "#   \"num_key_value_heads\": 8,\n",
    "#   \"pretraining_tp\": 1,\n",
    "#   \"rms_norm_eps\": 1e-05,\n",
    "#   \"rope_scaling\": {\n",
    "#     \"factor\": 32.0,\n",
    "#     \"high_freq_factor\": 4.0,\n",
    "#     \"low_freq_factor\": 1.0,\n",
    "#     \"original_max_position_embeddings\": 8192,\n",
    "#     \"rope_type\": \"llama3\"\n",
    "#   },\n",
    "#   \"rope_theta\": 500000.0,\n",
    "#   \"tie_word_embeddings\": True,\n",
    "#   \"torch_dtype\": \"float32\",\n",
    "#   \"transformers_version\": \"4.50.3\",\n",
    "#   \"use_cache\": True,\n",
    "#   \"vocab_size\": 128256\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8673a-412d-4294-83c2-78dc28467208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random init\n",
    "# model_config = GPT2Config() #Full sized model\n",
    "# model = GPT2LMHeadModel(model_config).to(device) #Ok i should see what happens with full and pretrained model. \n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# # Llama with random initialization\n",
    "# model_config  = LlamaConfig.from_dict(config_dict)\n",
    "# model = LlamaForCausalLM(model_config).to(device) \n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "#Pretrained\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb85eb-bbed-4fec-9993-d394da9541d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The capital of France is Paris\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "input_ids = inputs[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8239154-bc7d-4dbf-8b76-a057a62d00ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, labels=input_ids)\n",
    "\n",
    "my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "y_one_hot=F.one_hot(input_ids, num_classes=model.config.vocab_size)\n",
    "correct_next_token_probs = (my_probs[:,:-1]*y_one_hot[:,1:]).sum(-1) #I'm sure there's waaay more efficient ways to do this\n",
    "my_loss=-torch.log(correct_next_token_probs).mean()\n",
    "print(my_loss.item(), outputs.loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3002006-861a-4c11-ab45-9c97a2629da3",
   "metadata": {},
   "source": [
    "- To Do -> try with just loss on Paris token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f756c1f2-c5bf-4523-8242-32e9bbb129e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, labels=input_ids)\n",
    "\n",
    "my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "y_one_hot=F.one_hot(input_ids, num_classes=model.config.vocab_size)\n",
    "correct_next_token_probs = (my_probs[:,:-1]*y_one_hot[:,1:]).sum(-1) #I'm sure there's waaay more efficient ways to do this\n",
    "my_loss=-torch.log(correct_next_token_probs).mean()\n",
    "\n",
    "paris_only_loss=-np.log(my_probs[0, 5, 12366].item())\n",
    "print(my_loss.item(), outputs.loss.item(), paris_only_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25bf9b4-759b-473b-a4b1-0b548501e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_directions(params, seed=None):\n",
    "    \"\"\"\n",
    "    Generate random direction vectors for each parameter tensor.\n",
    "    \n",
    "    Args:\n",
    "        params: List of (name, parameter) tuples from model.named_parameters()\n",
    "        seed: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        direction: OrderedDict mapping parameter names to random direction tensors\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    direction = OrderedDict()\n",
    "    for name, param in params:\n",
    "        if param.requires_grad:\n",
    "            direction[name] = torch.randn_like(param.data)\n",
    "    \n",
    "    return direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1669ce6-0205-4edb-bd41-f24faac895f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_direction(direction, params):\n",
    "    \"\"\"\n",
    "    Normalize the direction tensors to match the norm of each parameter tensor.\n",
    "    \n",
    "    Args:\n",
    "        direction: OrderedDict mapping parameter names to direction tensors\n",
    "        params: List of (name, parameter) tuples from model.named_parameters()\n",
    "        \n",
    "    Returns:\n",
    "        normalized_direction: OrderedDict with normalized direction tensors\n",
    "    \"\"\"\n",
    "    param_dict = OrderedDict(params)\n",
    "    normalized_direction = OrderedDict()\n",
    "    \n",
    "    for name, dir_tensor in direction.items():\n",
    "        param_norm = torch.norm(param_dict[name].data)\n",
    "        dir_norm = torch.norm(dir_tensor)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if dir_norm > 0:\n",
    "            normalized_direction[name] = dir_tensor * (param_norm / dir_norm)\n",
    "        else:\n",
    "            normalized_direction[name] = dir_tensor\n",
    "    \n",
    "    return normalized_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dccf112-6530-4cf3-835b-f1b383b4cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir='/home/stephen/backparopagation/apr_23_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a562d-dfbc-4174-9e9a-960ed1655771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855e484-d6e7-42bc-b262-552362f460ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix='pretrained_'\n",
    "filtered_params = [(name, p) for name, p in model.named_parameters() if p.requires_grad]\n",
    "# layers_name='all'\n",
    "\n",
    "layers_name='first_8'\n",
    "filtered_params = filtered_params[1:73] #First 8 layers - I like this - facorite so far\n",
    "\n",
    "# layers_name='last_8'\n",
    "# filtered_params = filtered_params[73:] #Last 8 layers - some nice structue, but yeah more parabolic than I would like\n",
    "\n",
    "num_points=12\n",
    "num_samples=5\n",
    "\n",
    "random_seeds=[[i, i+100] for i in range(num_samples)]\n",
    "\n",
    "for random_seed_1, random_seed_2 in random_seeds:\n",
    "    print(random_seed_1, random_seed_2)\n",
    "    \n",
    "    # Generate and normalize random directions\n",
    "    direction1 = get_random_directions(filtered_params, seed=random_seed_1)\n",
    "    direction2 = get_random_directions(filtered_params, seed=random_seed_2)\n",
    "    \n",
    "    direction1 = normalize_direction(direction1, filtered_params)\n",
    "    direction2 = normalize_direction(direction2, filtered_params)\n",
    "    \n",
    "    original_params = OrderedDict()\n",
    "    for name, param in filtered_params:\n",
    "        original_params[name] = param.data.clone()\n",
    "    \n",
    "    alphas=np.linspace(-2.5, 2.5, num_points)\n",
    "    betas=np.linspace(-2.5, 2.5, num_points)\n",
    "    losses=[]\n",
    "    with torch.no_grad():\n",
    "        for i, alpha in enumerate(tqdm(alphas)):\n",
    "            losses.append([])\n",
    "            for j, beta in enumerate(betas):\n",
    "                for name, param in model.named_parameters():\n",
    "                    if name in direction1:\n",
    "                        param.data = original_params[name] + alpha * direction1[name] + beta*direction2[name]\n",
    "                \n",
    "                outputs = model(input_ids, labels=input_ids)\n",
    "                my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "                paris_only_loss=-np.log(my_probs[0, 5, 12366].item())\n",
    "                losses[-1].append(paris_only_loss)\n",
    "        \n",
    "        for name, param in model.named_parameters(): # Restore original parameters\n",
    "            if name in original_params: \n",
    "                param.data.copy_(original_params[name])\n",
    "    \n",
    "    losses=np.array(losses)\n",
    "    \n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    surface = ax.plot_surface(alphas, betas, losses, cmap='viridis', edgecolor='none', alpha=0.8)\n",
    "    plt.savefig(save_dir +'/'+prefix+str(random_seed_1)+'_'+str(random_seed_2)+'_'+layers_name+'_3d.png')\n",
    "    \n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    contourf = ax.contourf(alphas, betas, losses, 20, cmap='viridis', alpha=0.8)\n",
    "    contour = ax.contour(alphas, betas, losses, 30, colors='white', linewidths=0.5)\n",
    "    plt.savefig(save_dir +'/'+prefix+str(random_seed_1)+'_'+str(random_seed_2)+'_'+layers_name+'_2d.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedfeeed-60f9-4f16-899b-3a052103353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_params = [(name, p) for name, p in model.named_parameters() if p.requires_grad]\n",
    "# layers_name='all'\n",
    "\n",
    "# layers_name='first_8'\n",
    "# filtered_params = filtered_params[1:73] #First 8 layers - I like this - facorite so far\n",
    "\n",
    "layers_name='last_8'\n",
    "filtered_params = filtered_params[73:] #Last 8 layers - some nice structue, but yeah more parabolic than I would like\n",
    "\n",
    "# num_points=12\n",
    "# num_samples=5\n",
    "\n",
    "random_seeds=[[i, i+100] for i in range(num_samples)]\n",
    "\n",
    "for random_seed_1, random_seed_2 in random_seeds:\n",
    "    print(random_seed_1, random_seed_2)\n",
    "    \n",
    "    # Generate and normalize random directions\n",
    "    direction1 = get_random_directions(filtered_params, seed=random_seed_1)\n",
    "    direction2 = get_random_directions(filtered_params, seed=random_seed_2)\n",
    "    \n",
    "    direction1 = normalize_direction(direction1, filtered_params)\n",
    "    direction2 = normalize_direction(direction2, filtered_params)\n",
    "    \n",
    "    original_params = OrderedDict()\n",
    "    for name, param in filtered_params:\n",
    "        original_params[name] = param.data.clone()\n",
    "    \n",
    "    alphas=np.linspace(-2.5, 2.5, num_points)\n",
    "    betas=np.linspace(-2.5, 2.5, num_points)\n",
    "    losses=[]\n",
    "    with torch.no_grad():\n",
    "        for i, alpha in enumerate(tqdm(alphas)):\n",
    "            losses.append([])\n",
    "            for j, beta in enumerate(betas):\n",
    "                for name, param in model.named_parameters():\n",
    "                    if name in direction1:\n",
    "                        param.data = original_params[name] + alpha * direction1[name] + beta*direction2[name]\n",
    "                \n",
    "                outputs = model(input_ids, labels=input_ids)\n",
    "                my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "                paris_only_loss=-np.log(my_probs[0, 5, 12366].item())\n",
    "                losses[-1].append(paris_only_loss)\n",
    "        \n",
    "        for name, param in model.named_parameters(): # Restore original parameters\n",
    "            if name in original_params: \n",
    "                param.data.copy_(original_params[name])\n",
    "    \n",
    "    losses=np.array(losses)\n",
    "    \n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    surface = ax.plot_surface(alphas, betas, losses, cmap='viridis', edgecolor='none', alpha=0.8)\n",
    "    plt.savefig(save_dir +'/'+prefix+str(random_seed_1)+'_'+str(random_seed_2)+'_'+layers_name+'_3d.png')\n",
    "    \n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    contourf = ax.contourf(alphas, betas, losses, 20, cmap='viridis', alpha=0.8)\n",
    "    contour = ax.contour(alphas, betas, losses, 30, colors='white', linewidths=0.5)\n",
    "    plt.savefig(save_dir +'/'+prefix+str(random_seed_1)+'_'+str(random_seed_2)+'_'+layers_name+'_2d.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641022ea-bdc0-4fc5-b9c9-a9ca70b4ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_params = [(name, p) for name, p in model.named_parameters() if p.requires_grad]\n",
    "layers_name='all'\n",
    "\n",
    "# layers_name='first_8'\n",
    "# filtered_params = filtered_params[1:73] #First 8 layers - I like this - facorite so far\n",
    "\n",
    "# layers_name='last_8'\n",
    "# filtered_params = filtered_params[73:] #Last 8 layers - some nice structue, but yeah more parabolic than I would like\n",
    "\n",
    "# num_points=12\n",
    "# num_samples=5\n",
    "\n",
    "random_seeds=[[i, i+100] for i in range(num_samples)]\n",
    "\n",
    "for random_seed_1, random_seed_2 in random_seeds:\n",
    "    print(random_seed_1, random_seed_2)\n",
    "    \n",
    "    # Generate and normalize random directions\n",
    "    direction1 = get_random_directions(filtered_params, seed=random_seed_1)\n",
    "    direction2 = get_random_directions(filtered_params, seed=random_seed_2)\n",
    "    \n",
    "    direction1 = normalize_direction(direction1, filtered_params)\n",
    "    direction2 = normalize_direction(direction2, filtered_params)\n",
    "    \n",
    "    original_params = OrderedDict()\n",
    "    for name, param in filtered_params:\n",
    "        original_params[name] = param.data.clone()\n",
    "    \n",
    "    alphas=np.linspace(-2.5, 2.5, num_points)\n",
    "    betas=np.linspace(-2.5, 2.5, num_points)\n",
    "    losses=[]\n",
    "    with torch.no_grad():\n",
    "        for i, alpha in enumerate(tqdm(alphas)):\n",
    "            losses.append([])\n",
    "            for j, beta in enumerate(betas):\n",
    "                for name, param in model.named_parameters():\n",
    "                    if name in direction1:\n",
    "                        param.data = original_params[name] + alpha * direction1[name] + beta*direction2[name]\n",
    "                \n",
    "                outputs = model(input_ids, labels=input_ids)\n",
    "                my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "                paris_only_loss=-np.log(my_probs[0, 5, 12366].item())\n",
    "                losses[-1].append(paris_only_loss)\n",
    "        \n",
    "        for name, param in model.named_parameters(): # Restore original parameters\n",
    "            if name in original_params: \n",
    "                param.data.copy_(original_params[name])\n",
    "    \n",
    "    losses=np.array(losses)\n",
    "    \n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    surface = ax.plot_surface(alphas, betas, losses, cmap='viridis', edgecolor='none', alpha=0.8)\n",
    "    plt.savefig(save_dir +'/'+prefix+str(random_seed_1)+'_'+str(random_seed_2)+'_'+layers_name+'_3d.png')\n",
    "    \n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    contourf = ax.contourf(alphas, betas, losses, 20, cmap='viridis', alpha=0.8)\n",
    "    contour = ax.contour(alphas, betas, losses, 30, colors='white', linewidths=0.5)\n",
    "    plt.savefig(save_dir +'/'+prefix+str(random_seed_1)+'_'+str(random_seed_2)+'_'+layers_name+'_2d.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f72be5-e7a8-40eb-b80e-9c5867957e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a724f-3547-48f1-b70c-44814ca14815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d94bab9-cbc7-44fe-b45d-2b4873b711aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d09323-831e-4a37-86fd-da08939f989b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e84217-2596-417b-9022-55eb3e291cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
