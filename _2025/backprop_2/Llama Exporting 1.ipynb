{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ecddf37-b96e-4da7-a7d4-e59f09963b25",
   "metadata": {},
   "source": [
    "## Llama Exporting 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb27ab-ef65-4101-8e51-5d8ee057b14b",
   "metadata": {},
   "source": [
    "- Ok need to figure out exactly what to export here - there's a lot of ways to project all this information on to the animation\n",
    "- Starting on my linux machine then will need to move to runpod I think when I get into gradients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b41b13-f01c-46ec-b8bd-cfbee7a9d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from transformers import LlamaForCausalLM, PreTrainedTokenizerFast, LlamaConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76711176-6e78-43ac-953e-6967bf330889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import ActivationCache, HookedTransformer, utils\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f322029b-6227-42fe-ba47-2e2e985ea9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_dataset_so_cute=[\n",
    "    #jibberish\n",
    "    \"as dflkja sdf\",\n",
    "    \"18 9sdfsf 8sdf8sns\",\n",
    "    \"as dfasdf uowo fof\",\n",
    "    \n",
    "    # Arithmetic (10 examples)\n",
    "    \"2 + 2 = 4\",\n",
    "    \"4 + 3 = 7\",\n",
    "    \"2 + 9 = 11\",\n",
    "    \"11 - 10 = 1\",\n",
    "    \"3 - 6 = -3\",  # Gets this one wrong\n",
    "    \"3 * 6 = 18\",\n",
    "    \"3 * 2 = 6\",\n",
    "    \"8 / 2 = 4\",\n",
    "    \"128 / 32 = 4\",\n",
    "    \"9 * 7 = 63\",\n",
    "    \n",
    "    # Geography facts (8 examples)\n",
    "    \"The capital of France is Paris\",\n",
    "    \"The capital of Japan is Tokyo\",\n",
    "    \"The capital of Brazil is BrasÃ­lia\",\n",
    "    \"Mount Everest is located in the Himalayas\",\n",
    "    \"The Amazon River flows through South America\",\n",
    "    \"The largest continent is Asia\",\n",
    "    \"The Pacific Ocean borders Asia, Australia, North America, and South America\",\n",
    "    \"The currency of China is the yuan\",\n",
    "    \n",
    "    # Sports facts (8 examples)\n",
    "    \"The Lakers play in Los Angeles\",\n",
    "    \"The World Cup is held every 4 years\",\n",
    "    \"Serena Williams plays tennis\",\n",
    "    \"The Super Bowl happens in February\",\n",
    "    \"A basketball team has 5 players on the court\",\n",
    "    \"The Olympics occur every 2 years\",\n",
    "    \"Tiger Woods is famous for golf\",\n",
    "    \"Cristiano Ronaldo plays soccer\",\n",
    "    \n",
    "    # Code\n",
    "    \"def add_numbers(a, b):\",\n",
    "    \"import numpy as np\",\n",
    "    \"for i in range(\",\n",
    "    \"if x > 0:\",\n",
    "    \"print('Hello')\",\n",
    "    \"class Dog:\",\n",
    "    \"return x + y\",\n",
    "    \"from datetime import datetime\",\n",
    "    \"x = [1, 2, 3\",\n",
    "    \n",
    "    # Creative writing (10 examples)\n",
    "    \"Once upon a time, in a magical forest\",\n",
    "    \"The old wizard looked up at the stars and\",\n",
    "    \"She opened the mysterious door and found\",\n",
    "    \"The dragon's eyes glowed softly as\",\n",
    "    \"In the bustling marketplace, children\",\n",
    "    \"As the sun set behind the mountains,\",\n",
    "    \"The little robot whirred to life and\",\n",
    "    \"Deep in the ocean, a mermaid\",\n",
    "    \"The spaceship landed with a gentle\",\n",
    "    \"Through the mist came the sound of\",\n",
    "\n",
    "    # Logical reasoning/word relationships\n",
    "    \"If all cats are animals, and Fluffy is a cat, then Fluffy is an animal\",\n",
    "    \"Apple is to fruit as carrot is to vegtable\",\n",
    "    \"Hot is the opposite of cold\",\n",
    "    \"Bird is to fly as fish is to swim\",\n",
    "    \"Monday, Tuesday, Wednesday, Thursday\",\n",
    "    \"January comes before February\",\n",
    "\n",
    "    #Indirect Object Identification\n",
    "    \"When John and Mary went to the shops, John gave the bag to Mary\",\n",
    "    \"When Tom and James went to the park, Tom gave the ball to James\",\n",
    "    \"When Dan and Sid went to the shops, Dan gave an apple to Sid\",\n",
    "    \"After Martin and Amy went to the park, Martin gave a drink to Amy\",\n",
    "    \"When John and Mary went to the shops, Mary gave the bag to John\",\n",
    "    \"When Tom and James went to the park, James gave the ball to Tom\",\n",
    "    \"When Dan and Sid went to the shops, Sid gave an apple to Dan\",\n",
    "    \"After Martin and Amy went to the park, Amy gave a drink to Martin\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf0cd62-b0e0-4ef3-ba95-d7f5205bb273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model meta-llama/Llama-3.2-1B into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "model = HookedTransformer.from_pretrained(model_id, device=device) #Transfomer lens version\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0458c5b-7122-4e57-8339-3cb955639a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|begin_of_text|>', 'The', ' capt', 'ial', ' of', ' France', ' is']\n",
      "Tokenized answer: [' Paris']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.94</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34.99</span><span style=\"font-weight: bold\">% Token: | Paris|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m16.94\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m34.99\u001b[0m\u001b[1m% Token: | Paris|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.94 Prob: 34.99% Token: | Paris|\n",
      "Top 1th token. Logit: 15.24 Prob:  6.42% Token: | the|\n",
      "Top 2th token. Logit: 14.96 Prob:  4.83% Token: | a|\n",
      "Top 3th token. Logit: 14.47 Prob:  2.97% Token: | also|\n",
      "Top 4th token. Logit: 14.23 Prob:  2.34% Token: | located|\n",
      "Top 5th token. Logit: 14.08 Prob:  2.01% Token: | known|\n",
      "Top 6th token. Logit: 14.03 Prob:  1.92% Token: | not|\n",
      "Top 7th token. Logit: 13.73 Prob:  1.42% Token: | in|\n",
      "Top 8th token. Logit: 13.68 Prob:  1.35% Token: | situated|\n",
      "Top 9th token. Logit: 13.56 Prob:  1.20% Token: | called|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Paris'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Paris'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"The captial of France is\"\n",
    "answer = \" Paris\"\n",
    "utils.test_prompt(prompt, answer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9c0941e-f9cc-4d6e-a2d3-be70d7820d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"The captial of France is\", return_tensors=\"pt\").to(device)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "logits, cache = model.run_with_cache(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80b6a72b-e77f-4cd7-8921-c4d1d1609ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [k for k in cache.keys() if 'blocks.3' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db437a4-55f9-4389-9b58-bf135bbd3a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blocks.3.hook_resid_pre',\n",
       " 'blocks.3.ln1.hook_scale',\n",
       " 'blocks.3.ln1.hook_normalized',\n",
       " 'blocks.3.attn.hook_q',\n",
       " 'blocks.3.attn.hook_k',\n",
       " 'blocks.3.attn.hook_v',\n",
       " 'blocks.3.attn.hook_rot_q',\n",
       " 'blocks.3.attn.hook_rot_k',\n",
       " 'blocks.3.attn.hook_attn_scores',\n",
       " 'blocks.3.attn.hook_pattern',\n",
       " 'blocks.3.attn.hook_z',\n",
       " 'blocks.3.hook_attn_out',\n",
       " 'blocks.3.hook_resid_mid',\n",
       " 'blocks.3.ln2.hook_scale',\n",
       " 'blocks.3.ln2.hook_normalized',\n",
       " 'blocks.3.mlp.hook_pre',\n",
       " 'blocks.3.mlp.hook_pre_linear',\n",
       " 'blocks.3.mlp.hook_post',\n",
       " 'blocks.3.hook_mlp_out',\n",
       " 'blocks.3.hook_resid_post']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0b3d71a-5a3e-43f5-a97f-47bd00dc6619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 2048])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['blocks.3.hook_resid_mid'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f1b9a6c-cdad-4995-97bb-c1001424d796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 8192])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['blocks.3.mlp.hook_pre'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e885c7b4-07e7-4d50-83ec-2aac95c0f503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 8192])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['blocks.3.mlp.hook_pre_linear'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ca425a4-0b0f-48ca-9c5b-55c90b546631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 8192])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['blocks.3.mlp.hook_post'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "862f4f1a-3016-4502-b5b3-b2a10d66e2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 2048])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['blocks.3.hook_mlp_out'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2678d75-bd5b-4a3b-bb20-0ddc267b5575",
   "metadata": {},
   "source": [
    "- Ok so I need to decide which of the 7 positions to show, that's a bit tricky, let's try the last position!\n",
    "- I think the caches I want are: `blocks.3.hook_resid_mid`, `blocks.3.mlp.hook_post`, and `blocks.3.hook_mlp_out'`\n",
    "- This is just for activations, so downsampling should be actually pretty easy I think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10d36eb5-7460-4a57-b673-6ae9a4863471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2048])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['blocks.3.hook_resid_mid'][:,-1].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0203f6e4-89fb-4988-84b1-3d3e34b8931a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.,  4.,  6.,  8., 10.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MaxPool1d(kernel_size=2, stride=2)(torch.tensor([[[1.,2,3,4,5,6,7,8,9,10]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e861151a-ef26-4da9-8fa7-52542bf27dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MaxPool1d(kernel_size=64, stride=64)(cache['blocks.3.hook_resid_mid'][:,-1].unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bae46617-be9a-415c-9bf0-5f9fd58d976b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8192])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache['blocks.3.mlp.hook_post'][:,-1].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c06b85fe-941d-46b1-b83b-b0c60316dd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 34])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MaxPool1d(kernel_size=240, stride=240)(cache['blocks.3.mlp.hook_post'][:,-1].unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fcbd0be-a31b-4244-a614-41bea9f52ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir='/home/stephen/backprop2/may_31_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4142dc5b-d458-42ce-ab13-24ab15560899",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_num in range(16):\n",
    "    # print(cache['blocks.'+str(layer_num)+'.hook_resid_mid'][:,-1].unsqueeze(0).shape)\n",
    "    cache_name='blocks.'+str(layer_num)+'.hook_resid_mid'\n",
    "    a=torch.nn.MaxPool1d(kernel_size=64, stride=64)(cache[cache_name][:,-1].unsqueeze(0)).cpu().ravel().numpy()\n",
    "    np.save(save_dir+'/'+cache_name, a)\n",
    "\n",
    "    cache_name='blocks.'+str(layer_num)+'.mlp.hook_post'\n",
    "    torch.nn.MaxPool1d(kernel_size=240, stride=240)(cache[cache_name][:,-1].unsqueeze(0)).shape\n",
    "    np.save(save_dir+'/'+cache_name, a)\n",
    "\n",
    "    cache_name='blocks.'+str(layer_num)+'.hook_mlp_out'\n",
    "    torch.nn.MaxPool1d(kernel_size=64, stride=64)(cache[cache_name][:,-1].unsqueeze(0)).shape\n",
    "    np.save(save_dir+'/'+cache_name, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261f20c-4c96-41b2-96db-b6cf7bd4235d",
   "metadata": {},
   "source": [
    "- Ok I think that should be good for activations for now -> I can come back and add input and output stuff later - that will be cool!\n",
    "- Ok now how should I pool down weights? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d42c4669-37bb-4cbc-bc9c-b6a79e3ea2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GatedMLP(\n",
       "  (hook_pre): HookPoint()\n",
       "  (hook_pre_linear): HookPoint()\n",
       "  (hook_post): HookPoint()\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[0].mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13ccdd1e-4b40-4bf9-83da-0cc6121be3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params={n:v for n,v in model.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1383a5a9-0932-4c5f-9a37-c10aef59616b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 8192)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_params['blocks.0.mlp.W_in'].detach().cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a70cfd9f-a399-4d7b-8b7b-67913bccae4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8192, 2048)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_params['blocks.0.mlp.W_out'].detach().cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c445bb03-c8dc-4874-956b-aa2a349461b2",
   "metadata": {},
   "source": [
    "Ok cool so I need to get these puppies down to 32x34 and 34x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "12c14bd1-90ee-4574-a178-a8286b8f046d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 34)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MaxPool2d(kernel_size=(64,240), stride=(64,240))(all_params['blocks.0.mlp.W_in'].detach().cpu().unsqueeze(0)).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f2dd0d3-3411-4ccd-9786-a22f8d08b300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 34, 32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MaxPool2d(kernel_size=(240,64), stride=(240,64))(all_params['blocks.0.mlp.W_out'].detach().cpu().unsqueeze(0)).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4f6f188-8032-4d67-b42a-71cce226db3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2048, 8192)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_params['blocks.0.mlp.W_in'].detach().cpu().unsqueeze(0).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3144ea79-03d8-40c2-95a8-c11317141127",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_num in range(16):\n",
    "    param_name='blocks.'+str(layer_num)+'.mlp.W_in'\n",
    "    a=torch.nn.MaxPool2d(kernel_size=(64,240), stride=(64,240))(all_params[param_name].detach().cpu().unsqueeze(0)).numpy()\n",
    "    np.save(save_dir+'/'+param_name, a)\n",
    "\n",
    "    param_name='blocks.'+str(layer_num)+'.mlp.W_out'\n",
    "    a=torch.nn.MaxPool2d(kernel_size=(240, 64), stride=(240, 64))(all_params[param_name].detach().cpu().unsqueeze(0)).numpy()\n",
    "    np.save(save_dir+'/'+param_name, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc0525f-f47c-4754-9eeb-9727213af10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17923e08-e24c-4eda-8268-ea62833e79fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69469bd-97eb-4bfe-bd3a-6c3bfa938656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93767b03-6311-44a5-85dc-b1ae7218c2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb54826-a7de-4ed4-8108-dda2c92ae035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe342e-d0f4-4f97-90b4-4aabbc844430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa14300-24b9-48ba-b61d-206375fce5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1262a1-4093-450b-bb3a-8055f6b260e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
