{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56d1131-3818-4959-993e-8a39597af93e",
   "metadata": {},
   "source": [
    "## P47 Wormhole \n",
    "- Cleaned up version w/ original param replacement bug fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a72b6a-70cd-4d5c-b04c-6325114699aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install transformers matplotlib tqdm huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918cc7c3-74f2-438c-ad8a-2cfb26f1e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85155a3b-c331-41c0-9402-8c3d05354ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "from transformers import LlamaForCausalLM, PreTrainedTokenizerFast, LlamaConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897e993-77db-4f3f-982f-b66740971ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "# model_id = \"openai-community/gpt2\"\n",
    "# model_id = \"google/gemma-3-1b-pt\"\n",
    "model_id = \"gpt2\"\n",
    "\n",
    "#Pretrained\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2b3cf-ae54-46b5-977f-3ae70981f487",
   "metadata": {},
   "source": [
    "## Configuration for this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88763c12-4b95-423e-ad59-6d0004ea456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir='/workspace/may_6_1'\n",
    "output_dir='/home/stephen/backparopagation/may_6_5_gpt2'\n",
    "num_points=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6507c2f0-89bb-4757-868d-e385d359e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301a3663-f0de-44f4-9c85-380c2a574107",
   "metadata": {},
   "source": [
    "## Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f4c1c5-1423-4880-969a-81a5c88d823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_directions(params, seed=None):\n",
    "    \"\"\"\n",
    "    Generate random direction vectors for each parameter tensor.\n",
    "    \n",
    "    Args:\n",
    "        params: List of (name, parameter) tuples from model.named_parameters()\n",
    "        seed: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        direction: OrderedDict mapping parameter names to random direction tensors\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    direction = OrderedDict()\n",
    "    for name, param in params:\n",
    "        if param.requires_grad:\n",
    "            direction[name] = torch.randn_like(param.data)\n",
    "    \n",
    "    return direction\n",
    "\n",
    "def normalize_direction(direction, params):\n",
    "    \"\"\"\n",
    "    Normalize the direction tensors to match the norm of each parameter tensor.\n",
    "    \n",
    "    Args:\n",
    "        direction: OrderedDict mapping parameter names to direction tensors\n",
    "        params: List of (name, parameter) tuples from model.named_parameters()\n",
    "        \n",
    "    Returns:\n",
    "        normalized_direction: OrderedDict with normalized direction tensors\n",
    "    \"\"\"\n",
    "    param_dict = OrderedDict(params)\n",
    "    normalized_direction = OrderedDict()\n",
    "    \n",
    "    for name, dir_tensor in direction.items():\n",
    "        param_norm = torch.norm(param_dict[name].data)\n",
    "        dir_norm = torch.norm(dir_tensor)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if dir_norm > 0:\n",
    "            normalized_direction[name] = dir_tensor * (param_norm / dir_norm)\n",
    "        else:\n",
    "            normalized_direction[name] = dir_tensor\n",
    "    \n",
    "    return normalized_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a4b292-7861-4942-91b2-482ea1ac1a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c197f99d-d206-470a-baf9-78d6e87f6cd4",
   "metadata": {},
   "source": [
    "### Setup example and run some Computation Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d857cc4e-504b-43fa-a474-f7d3bc6bef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The capital of France is Paris\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "input_ids = inputs[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48a7703-93f2-427a-92dd-4650c24ed8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, labels=input_ids)\n",
    "\n",
    "my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "y_one_hot=F.one_hot(input_ids, num_classes=model.config.vocab_size)\n",
    "correct_next_token_probs = (my_probs[:,:-1]*y_one_hot[:,1:]).sum(-1) #I'm sure there's waaay more efficient ways to do this\n",
    "my_loss=-torch.log(correct_next_token_probs).mean()\n",
    "print(my_loss.item(), outputs.loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0affa34f-2533-4a06-aa89-eb3430149250",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, labels=input_ids)\n",
    "\n",
    "my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "y_one_hot=F.one_hot(input_ids, num_classes=model.config.vocab_size)\n",
    "correct_next_token_probs = (my_probs[:,:-1]*y_one_hot[:,1:]).sum(-1) #I'm sure there's waaay more efficient ways to do this\n",
    "my_loss=-torch.log(correct_next_token_probs).mean()\n",
    "\n",
    "paris_only_loss=-np.log(my_probs[0, 5, 12366].item())\n",
    "print(my_loss.item(), outputs.loss.item(), paris_only_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c2a14-78dc-425e-9bcf-481bfbebe430",
   "metadata": {},
   "outputs": [],
   "source": [
    "sI=np.argsort(my_probs[0,5, :].detach().cpu().float().numpy())[::-1]\n",
    "for i in sI[:10]:\n",
    "    print(i, round(my_probs[0, 5, i].item(),5), tokenizer.decode([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9796958-4034-4f8f-83a5-d821772fdf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix='pretrained_'\n",
    "filtered_params = [(name, p) for name, p in model.named_parameters() if p.requires_grad]\n",
    "# layers_name='all'\n",
    "\n",
    "layers_name='first_6'\n",
    "filtered_params = filtered_params[1:86] \n",
    "\n",
    "# layers_name='last_8'\n",
    "# filtered_params = filtered_params[73:] #Last 8 layers - some nice structue, but yeah more parabolic than I would like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea30fa-363c-47e3-95b2-f9a0a168a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [o[0] for o in filtered_params[1:(13*14+1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e1f11-af00-41f8-9a75-d4d82243ce58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f8b8ef-d6d4-46e1-96d6-8771630dfe1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3e3ade-7422-43c2-9adb-67fd9ad7b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seeds_pairs=[[o, o+100] for o in range(25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6fc7d-f758-48f7-8fe5-f8077126e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for random_seed_1, random_seed_2 in random_seeds_pairs:\n",
    "    print(random_seed_1, random_seed_2)\n",
    "\n",
    "    # Generate and normalize random directions\n",
    "    direction1 = get_random_directions(filtered_params, seed=random_seed_1)\n",
    "    direction2 = get_random_directions(filtered_params, seed=random_seed_2)\n",
    "    \n",
    "    direction1 = normalize_direction(direction1, filtered_params)\n",
    "    direction2 = normalize_direction(direction2, filtered_params)\n",
    "    \n",
    "    original_params = OrderedDict()\n",
    "    for name, param in filtered_params:\n",
    "        original_params[name] = param.data.clone()\n",
    "    \n",
    "    alphas=np.linspace(-2.5, 2.5, num_points)\n",
    "    betas=np.linspace(-2.5, 2.5, num_points)\n",
    "    \n",
    "    losses=[]\n",
    "    \n",
    "    model.eval();\n",
    "    with torch.no_grad():\n",
    "        for i, alpha in enumerate(tqdm(alphas)):\n",
    "            losses.append([])\n",
    "            for j, beta in enumerate(betas):\n",
    "                for name, param in model.named_parameters():\n",
    "                    if name in direction1:\n",
    "                        param.data = original_params[name] + alpha * direction1[name] + beta*direction2[name]\n",
    "                \n",
    "                outputs = model(input_ids, labels=input_ids)\n",
    "                my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "                paris_only_loss=-np.log(my_probs[0, 5, 12366].item()) #Just Paris\n",
    "                # losses[-1].append(paris_only_loss)\n",
    "                losses[-1].append(outputs.loss.item()) #all 5 losses averaged\n",
    "        \n",
    "        for name, param in model.named_parameters(): # Restore original shifted parameters\n",
    "            if name in original_params: \n",
    "                param.data.copy_(original_params[name])\n",
    "        losses=np.array(losses)\n",
    "    \n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    contourf = ax.contourf(alphas, betas, losses, 20, cmap='viridis', alpha=0.8)\n",
    "    contour = ax.contour(alphas, betas, losses, 30, colors='white', linewidths=0.5)\n",
    "    plt.savefig(output_dir+'/'+layers_name+'_'+str(random_seed_1)+'_'+str(random_seed_2)+'.png')\n",
    "    np.save(output_dir +'/'+layers_name+'_'+str(random_seed_1)+'_'+str(random_seed_2), losses) #Save loss landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425c223-ba34-413a-9e62-9a67638296a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ced4ea-efa9-4e46-b6ac-a4983e94859e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec4961-bac8-47fc-9dcf-3862d46df5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa59df24-dbaa-49db-9c87-0a4cb29f1725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a003afd-a67c-4eeb-ab84-23668e94a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9dd18f-4d0d-43e6-b584-5f8dec0801fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b066ea7b-e74a-4b4f-a3cc-908034684db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05f6670-7aaa-4c5c-b843-b849d5576506",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "contourf = ax.contourf(alphas, betas, losses, 20, cmap='viridis', alpha=0.8)\n",
    "contour = ax.contour(alphas, betas, losses, 30, colors='white', linewidths=0.5)\n",
    "# plt.savefig(output_dir +'/'+str(step).zfill(3)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad22f86-03d5-4443-a818-08d545fca89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(output_dir +'/'+str(step).zfill(3), losses) #Save loss landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658446a3-d621-40da-9f4f-c6b764b71c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77ae55-4c31-4867-aca3-2d065b690843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e8059-6094-4ac6-b3e2-48d4d359b3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2727ee-c045-4aa1-a55c-cb4c269c81e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e141dbd8-f450-42a0-bb23-db4d3b3e515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # with torch.no_grad(): #Check current outputs\n",
    "    #     outputs = model(input_ids, labels=input_ids)\n",
    "    #     my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "    #     sI=np.argsort(my_probs[0,5, :].detach().cpu().float().numpy())[::-1]\n",
    "    #     current_outs=[[12366,  round(my_probs[0, 5, 12366].item(), 7), ' Paris']] #Put paris at top\n",
    "    #     for i in sI[:10]:\n",
    "    #         current_outs.append([i, round(my_probs[0, 5, i].item(),7), tokenizer.decode([i])])\n",
    "    #     model_outputs.append(current_outs)\n",
    "    #     print(step, 'loss=', -np.log(my_probs[0, 5, 12366].item()), current_outs[0], current_outs[1])\n",
    "\n",
    "    # if step>=delayed_viz_start: #Do I want to compute loss landscape at this step?\n",
    "    #     with torch.no_grad():\n",
    "    #         for i, alpha in enumerate(tqdm(alphas_shifted)):\n",
    "    #             losses.append([])\n",
    "    #             for j, beta in enumerate(betas_shifted):\n",
    "    #                 for name, param in model.named_parameters():\n",
    "    #                     if name in direction1:\n",
    "    #                         param.data = original_params_shifted[name] + alpha * direction1[name] + beta*direction2[name]\n",
    "                    \n",
    "    #                 outputs = model(input_ids, labels=input_ids)\n",
    "    #                 my_probs=F.softmax(outputs.logits, dim=-1)\n",
    "    #                 paris_only_loss=-np.log(my_probs[0, 5, 12366].item()) #Just Paris\n",
    "    #                 losses[-1].append(paris_only_loss)\n",
    "            \n",
    "    #         for name, param in model.named_parameters(): # Restore original shifted parameters\n",
    "    #             if name in original_params: \n",
    "    #                 param.data.copy_(original_params_shifted[name])\n",
    "    #     losses=np.array(losses)\n",
    "    #     np.save(output_dir +'/'+str(step).zfill(3), losses) #Save loss landscape\n",
    "        \n",
    "    #     plt.clf()\n",
    "    #     fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    #     contourf = ax.contourf(alphas, betas, losses, 20, cmap='viridis', alpha=0.8)\n",
    "    #     contour = ax.contour(alphas, betas, losses, 30, colors='white', linewidths=0.5)\n",
    "    #     plt.scatter(beta_shift, alpha_shift, c='m')\n",
    "    #     plt.savefig(output_dir +'/'+str(step).zfill(3)+'.png')\n",
    "\n",
    "    # model.train()\n",
    "    # optimizer.zero_grad()\n",
    "    # outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "    # loss = outputs.loss #Ok not just paris loss here -> not sure how much I'm worried about that\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "\n",
    "    # #After training I need to replace original_params_shifted with the new trained values\n",
    "    # original_params_shifted = OrderedDict()\n",
    "    # for name, param in filtered_params:\n",
    "    #     original_params_shifted[name] = param.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff9693-e4f3-4103-9959-4c23ae6f0620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c80cdd6-00d7-4ad7-a71a-30c80f9dc171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da3abf-ee0a-4c95-8c0f-5314160571d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250bcdc0-3acc-4704-97ec-f95fa73c0fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d8d0ee-f445-4d04-8719-d9bc2b677031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e052151-acee-4468-8ca3-809ed9e5c333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476aad31-079a-457f-84d0-f17d22320e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69462656-caa3-483e-b98c-096f3d0d9aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d965c98-9b4a-40fe-b909-8abd90935729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2dda5e-11ab-4a8a-9b6f-de26127e22ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c4637-b8f1-4998-b333-fa16381103b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de2c35c-a46a-4cfe-8634-d97cd0dc7750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d478fc9e-5313-4415-9671-e5c153201d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a53746a-c9e9-4650-b7aa-b2047cdaf6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50092866-1431-44a5-86cb-c4ac22d08e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c305e72-627b-4342-b358-3265849cebff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
