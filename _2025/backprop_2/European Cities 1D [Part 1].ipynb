{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43d6531-a496-442a-ba46-dd3dd28c3e15",
   "metadata": {},
   "source": [
    "## European Cities 1D [Part 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeea083a-de2d-4f90-b2b9-7f5cb342315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "paris_coords = np.array([\n",
    "    [48.8575, 2.3514], #Center of Paris\n",
    "    [48.8584, 2.2945], # Eiffel Tower\n",
    "    [48.8530, 2.3499], #Notre Dame\n",
    "    [48.8606,  2.3376], #Louvre\n",
    "    [48.8606, 2.3522]  #Centre Pompidou\n",
    "])\n",
    "\n",
    "madrid_coords = np.array([\n",
    "    [40.4167, -3.7033],   # Center of Madrid\n",
    "    [40.4153, -3.6835],   # Retiro Park \n",
    "    [40.4180, -3.7143],   # Royal Palace \n",
    "    [40.4138, -3.6921],   # Prado Museum \n",
    "    [40.4169, -3.7033]   # Puerta del Sol \n",
    "])\n",
    "\n",
    "berlin_coords = np.array([\n",
    "    [52.5200, 13.4050], # Center of Berlin\n",
    "    [52.5163, 13.3777],   # Brandenburg Gate \n",
    "    [52.5169, 13.4019],   # Museum Island \n",
    "    [52.5074, 13.3904],   # Checkpoint Charlie \n",
    "    [52.5251, 13.3694]   # Berlin Central Station \n",
    "])\n",
    "\n",
    "colors=['c', 'y', 'm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d0126-86dc-4878-acdb-1dbfe0c9a3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ec18db-8745-4efb-882b-bb94cd62c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random_seed=52\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f7781c4-68c6-4e52-826a-52063002f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (15, 1)\n",
      "Shape of y: (15,)\n"
     ]
    }
   ],
   "source": [
    "# Combine data into one matrix X and labels y\n",
    "X_raw = np.vstack([madrid_coords, paris_coords, berlin_coords]) #, brussels_coords, vienna_coords])\n",
    "y = np.array([0, 0, 0, 0, 0,  #  Madrid labels (0)\n",
    "              1, 1, 1, 1, 1,  #  Paris labels (1)\n",
    "              2, 2, 2, 2, 2]) #, # Berlin labels (2)\n",
    "              #3, 3, 3, 3, 3, 3, 3, \n",
    "              #4, 4, 4, 4, 4, 4, 4]) \n",
    "\n",
    "# Let's use only longitude as input for the simple model\n",
    "X_lon = X_raw[:, 1].reshape(-1, 1)  # Extract longitude and reshape to column vector\n",
    "\n",
    "# Normalize data (simple scaling by dividing by 100, I guess I could do 10)\n",
    "X = X_lon # / 100 - Simple longitude only problem does not seem to require normalization, that's interesting!\n",
    "\n",
    "# Alternative normalization (uncomment to use)\n",
    "# mean = np.mean(X_lon)\n",
    "# std = np.std(X_lon)\n",
    "# X = (X_lon - mean) / std\n",
    "\n",
    "rI=np.arange(len(y))\n",
    "np.random.shuffle(rI)\n",
    "X=X[rI,:]\n",
    "y=y[rI]\n",
    "X_raw=X_raw[rI,:]\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d81d0a-a31e-409d-9f9f-3085a0e75aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyGPSModel(nn.Module):\n",
    "    def __init__(self, input_size=1, output_size=3):\n",
    "        super(TinyGPSModel, self).__init__()\n",
    "        self.output = nn.Linear(input_size, output_size) #, bias=False)  # 3 cities\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e9da523-dd7a-4316-8424-fe5ef72f05b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = TinyGPSModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "#I can manually initialize and still learns real good? yeah seems like it!\n",
    "with torch.no_grad():\n",
    "    model.output.weight[0,0]=1.0\n",
    "    model.output.weight[1,0]=0.0\n",
    "    model.output.weight[2,0]=-1.0\n",
    "    model.output.bias[0]=0\n",
    "    model.output.bias[1]=0\n",
    "    model.output.bias[2]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b503b219-18f2-484b-bb34-ffdebc0ff401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.3514,  0.0000, -2.3514])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits=model(torch.tensor([2.3514])).detach() #Center of Paris\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9dded99-9063-4eca-ba9c-aa2372e7c630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9055, 0.0862, 0.0082])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Softmax(0)(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a47156ff-bd45-45d4-9fbf-28833ae5dde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4510851013124895"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(0.0862)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29c2c773-7c47-413b-b440-c762b8f1281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.output.weight[0,0]=1.0\n",
    "    model.output.weight[1,0]=0.1\n",
    "    model.output.weight[2,0]=-1.0\n",
    "    model.output.bias[0]=0\n",
    "    model.output.bias[1]=0\n",
    "    model.output.bias[2]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bab1d40c-fb12-41ae-8de5-fa57c7c07535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.3514,  0.2351, -2.3514])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits=model(torch.tensor([2.3514])).detach() #Center of Paris\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d168c6f0-ce52-4d89-946a-daa8ca804874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8853, 0.1067, 0.0080])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Softmax(0)(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cd31e08-fdce-45bb-bbe7-5eb60e1ea126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = TinyGPSModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "#I can manually initialize and still learns real good? yeah seems like it!\n",
    "with torch.no_grad():\n",
    "    model.output.weight[0,0]=1.0\n",
    "    model.output.weight[1,0]=0.0\n",
    "    model.output.weight[2,0]=-1.0\n",
    "    model.output.bias[0]=0\n",
    "    model.output.bias[1]=0\n",
    "    model.output.bias[2]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "449103d9-ed20-45cb-b6e6-96ade52f9f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.3514])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=14 #Center of Paris\n",
    "X[i%len(y)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "444c248a-7733-46c3-bdf0-15821eab5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(torch.tensor(X[i%len(y)]).float())\n",
    "loss = criterion(outputs, torch.tensor(y[i%len(y)])) \n",
    "loss.backward()  # backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ed1ba83-9af7-4d00-ad73-1bb32ef4c859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1293],\n",
       "        [-2.1486],\n",
       "        [ 0.0193]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "873c68ba-f9ca-4f65-9494-cc9912c71d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9055, -0.9138,  0.0082])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e1b23ee-ccc2-4875-b8b9-19e8b6ed4ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.14944036"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.0862-1)*2.3522"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485be6e-4c6e-479f-9c39-927fa6dc5768",
   "metadata": {},
   "source": [
    "## Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a378c903-2e8b-4c6e-a214-97ef0df1d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Where to save training heatmaps\n",
    "save_dir='/Users/stephen/Stephencwelch Dropbox/Stephen Welch/welch_labs/backprop2/graphics/to_manim/may_27_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "41c26f7f-3bf6-4546-b3cd-69cdd703f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Swaggin - need to sync with Sam on exact numbers\n",
    "min_long=-7.0\n",
    "max_long=18.0\n",
    "min_lat=36.0\n",
    "max_lat=56.0\n",
    "num_steps=256\n",
    "heatmap_viz_logit_multiplier=8 #Makes things more winner take all for cleaner logit viz\n",
    "heatmaps=[np.zeros((num_steps, num_steps)) for i in range(6)]\n",
    "\n",
    "for i, lat in enumerate(np.linspace(max_lat, min_lat, num_steps)):\n",
    "    for j, long in enumerate(np.linspace(min_long, max_long, num_steps)):\n",
    "        with torch.no_grad():\n",
    "            logits=model(torch.tensor([long], dtype=torch.float)).detach()\n",
    "            yhat=torch.nn.Softmax(0)(heatmap_viz_logit_multiplier*logits).numpy()\n",
    "\n",
    "        for k in range(3):\n",
    "            heatmaps[k][i,j]=logits.numpy()[k]\n",
    "            heatmaps[k+3][i,j]=yhat[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5d35a126-1878-443e-acf8-5a780f9d3a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmaps[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "940baa10-41a4-47f8-8ae8-5f37fde2d962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29ce84c50>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(heatmaps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2f550ac2-c803-4d18-bee7-09e63723a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "def create_transparent_colormap(color='cyan', name='transparent_to_color'):\n",
    "    # Convert color name to RGBA\n",
    "    base_color = mcolors.to_rgba(color)\n",
    "    \n",
    "    # Create colormap: transparent (alpha=0) to full color (alpha=1)\n",
    "    colors = [(base_color[0], base_color[1], base_color[2], 0),  # transparent\n",
    "              (base_color[0], base_color[1], base_color[2], 1)]  # full color\n",
    "    \n",
    "    n_bins = 256\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(name, colors, N=n_bins)\n",
    "    return cmap\n",
    "\n",
    "# Create the colormap\n",
    "transparent_cyan_cmap = create_transparent_colormap('cyan')\n",
    "transparent_yellow_cmap = create_transparent_colormap('#ffd35a')\n",
    "transparent_green_cmap = create_transparent_colormap('#00a14b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d6de9335-9805-4352-8225-60934a4cd9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaps=[transparent_cyan_cmap, transparent_yellow_cmap, transparent_green_cmap, transparent_cyan_cmap, transparent_yellow_cmap, transparent_green_cmap]\n",
    "save_names=['_logits_1.png', '_logits_2.png', '_logits_3.png', '_yhat_1.png', '_yhat_2.png', '_yhat_3.png']\n",
    "\n",
    "# for l in range(6):\n",
    "#     plt.clf()\n",
    "#     plt.figure(frameon=False)\n",
    "#     ax = plt.Axes(plt.gcf(), [0., 0., 1., 1.])\n",
    "#     ax.set_axis_off()\n",
    "#     plt.gcf().add_axes(ax)\n",
    "#     plt.imshow(heatmaps[l],  cmap=cmaps[l]) #np.rot90(heatmaps[0])) #Wait and see if I need to rotate or transpose\n",
    "#     plt.savefig(save_dir+save_names[l], bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b1db17-b965-4fcb-9b0f-c5aeee9d45b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "83829580-04d3-4908-bdfb-2feb5b584a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10/9, Loss: 14.2994, 'Accuracy: 0.0000\n",
      "Step 20/19, Loss: 1.0556, 'Accuracy: 0.6667\n",
      "Step 30/29, Loss: 1.1952, 'Accuracy: 0.6667\n",
      "Step 40/39, Loss: 0.1035, 'Accuracy: 0.6667\n",
      "Step 50/49, Loss: 1.0441, 'Accuracy: 0.6667\n",
      "Step 60/59, Loss: 1.0464, 'Accuracy: 0.6667\n",
      "Step 70/69, Loss: 0.0936, 'Accuracy: 0.6667\n",
      "Step 80/79, Loss: 0.9524, 'Accuracy: 0.6667\n",
      "Step 90/89, Loss: 0.9651, 'Accuracy: 0.6667\n",
      "Step 100/99, Loss: 0.0893, 'Accuracy: 0.6667\n",
      "Step 110/109, Loss: 0.8899, 'Accuracy: 0.6667\n",
      "Step 120/119, Loss: 0.9052, 'Accuracy: 0.6667\n",
      "Step 130/129, Loss: 0.0862, 'Accuracy: 0.6667\n",
      "Step 140/139, Loss: 0.8393, 'Accuracy: 0.6667\n",
      "Step 150/149, Loss: 0.8554, 'Accuracy: 0.6667\n",
      "Step 160/159, Loss: 0.0837, 'Accuracy: 0.6667\n",
      "Step 170/169, Loss: 0.7955, 'Accuracy: 0.7333\n",
      "Step 180/179, Loss: 0.8116, 'Accuracy: 0.6667\n",
      "Step 190/189, Loss: 0.0814, 'Accuracy: 0.6667\n",
      "Step 200/199, Loss: 0.7563, 'Accuracy: 1.0000\n",
      "Step 210/209, Loss: 0.7721, 'Accuracy: 1.0000\n",
      "Step 220/219, Loss: 0.0793, 'Accuracy: 0.6667\n",
      "Step 230/229, Loss: 0.7206, 'Accuracy: 1.0000\n",
      "Step 240/239, Loss: 0.7360, 'Accuracy: 1.0000\n",
      "Step 250/249, Loss: 0.0773, 'Accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = TinyGPSModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "#I can manually initialize and still learns real good? yeah seems like it!\n",
    "with torch.no_grad():\n",
    "    model.output.weight[0,0]=1.0\n",
    "    model.output.weight[1,0]=0.0\n",
    "    model.output.weight[2,0]=-1.0\n",
    "    model.output.bias[0]=0\n",
    "    model.output.bias[1]=0\n",
    "    model.output.bias[2]=0\n",
    "\n",
    "weights=[]\n",
    "grads=[]\n",
    "xs=[]\n",
    "ys=[]\n",
    "logitss=[]\n",
    "yhats=[]\n",
    "\n",
    "# Training loop\n",
    "for i in range(250):\n",
    "    xs.append(X_raw[i%len(y)])\n",
    "    ys.append(y[i%len(y)])\n",
    "    weights.append(np.concatenate([model.output.weight.detach().numpy().ravel(), model.output.bias.detach().numpy().ravel()]))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Stochastic - i think this is a better starting point pedagogically. \n",
    "    outputs = model(torch.tensor(X[i%len(y)]).float())\n",
    "    loss = criterion(outputs, torch.tensor(y[i%len(y)])) \n",
    "\n",
    "    logitss.append(outputs.detach().numpy())\n",
    "    yhats.append(torch.nn.Softmax(0)(outputs.detach()).numpy())\n",
    "\n",
    "    #Heatmaps\n",
    "    heatmaps=[np.zeros((num_steps, num_steps)) for i in range(6)]\n",
    "    for j, lat in enumerate(np.linspace(max_lat, min_lat, num_steps)):\n",
    "        for k, long in enumerate(np.linspace(min_long, max_long, num_steps)):\n",
    "            with torch.no_grad():\n",
    "                logits=model(torch.tensor([long], dtype=torch.float)).detach()\n",
    "                yhat=torch.nn.Softmax(0)(heatmap_viz_logit_multiplier*logits).numpy()\n",
    "    \n",
    "            for l in range(3):\n",
    "                heatmaps[l][j, k]=logits.numpy()[l]\n",
    "                heatmaps[l+3][j,k]=yhat[l]\n",
    "\n",
    "    for l in range(6):\n",
    "        plt.clf()\n",
    "        plt.figure(frameon=False)\n",
    "        ax = plt.Axes(plt.gcf(), [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        plt.gcf().add_axes(ax)\n",
    "        plt.imshow(heatmaps[l],  cmap=cmaps[l]) #np.rot90(heatmaps[0])) #Wait and see if I need to rotate or transpose\n",
    "        plt.savefig(save_dir+'/'+str(i)+save_names[l], bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    loss.backward()  # backpropagation\n",
    "    grads.append(np.concatenate([model.output.weight.grad.detach().numpy().ravel(), model.output.bias.grad.detach().numpy().ravel()]))\n",
    "    optimizer.step() #\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            logits=model(torch.tensor(X, dtype=torch.float)) \n",
    "            accuracy=(torch.argmax(logits, dim=1)==torch.tensor(y)).sum().item()/len(y)\n",
    "        print(f\"Step {i+1}/{i}, Loss: {loss.item():.4f}, 'Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "weights=np.array(weights)\n",
    "grads=np.array(grads)\n",
    "xs=np.array(xs)\n",
    "ys=np.array(ys)\n",
    "logitss=np.array(logitss)\n",
    "yhats=np.array(yhats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48db04ac-6002-4516-a7cf-ef3207f28aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_data=np.hstack((xs, ys.reshape(-1, 1), weights, grads, logitss, yhats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5af12dc7-d6a8-45d9-87fc-a9be5a95c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Users/stephen/Stephencwelch Dropbox/Stephen Welch/welch_labs/backprop2/hackin/cities_1d_1', all_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39d58962-4aae-4c7a-ba98-95d6be88c60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.25200000e+01,  1.34050000e+01,  2.00000000e+00,  9.05050039e-01,\n",
       "        2.31314786e-02, -9.28181529e-01,  1.09423082e-02,  8.64033960e-03,\n",
       "       -1.95826497e-02,  1.34049025e+01,  9.81709891e-05, -1.34049997e+01,\n",
       "        9.99992728e-01,  7.32346052e-06, -1.00000000e+00,  1.21431379e+01,\n",
       "        3.18717808e-01, -1.24618559e+01,  9.99992728e-01,  7.32346325e-06,\n",
       "        2.06150218e-11])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_training_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3494f1c-0360-4bd0-a05a-019f01c5b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs=all_training_data[:,:2]\n",
    "ys=all_training_data[:,2]\n",
    "weights=all_training_data[:,3:9]\n",
    "grads=all_training_data[:,9:15]\n",
    "logits=all_training_data[:,15:18]\n",
    "yhats=all_training_data[:, 18:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "889b2d9b-ff07-454e-9b85-dd84e5e65e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52.52 , 13.405])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "088f5931-301a-44c8-ba28-edbd08a95c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.90505004,  0.02313148, -0.92818153,  0.01094231,  0.00864034,\n",
       "       -0.01958265])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f2d711a-dd23-42d1-8b0e-abe7f034195e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m logits[\u001b[38;5;241m3\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 0 with size 3"
     ]
    }
   ],
   "source": [
    "logits[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a05bd4-aff2-4693-b217-961c5f8f8de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d349d364-36fa-425e-aa92-a4e76ad63350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd03f3dc-7253-4e1d-8c99-72add1de37eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a84d59f-dd95-4362-adc6-21c9de0fdf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b31e2829-e7a8-4812-ac05-61a07e4779d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72afd84e-736b-491b-9403-680ffd6c4153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16ce6012-a427-44b3-8179-d933ad2d4fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.5847,  0.8062,  0.7785])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits=model(torch.tensor([2.3522])).detach() #Center of Paris\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14b560aa-921c-414a-bdc9-3a501dcb5787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0443, 0.4844, 0.4712])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Softmax(0)(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79de2926-7db3-45dc-a8e4-ddd91db176fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a39684-09fa-46f5-b748-08c9262bdf26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f1aa04-8ee2-48ff-adcf-e7d63f97dd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac88ecd-3053-4f28-a311-c334487ccd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d4046-10f6-47fe-9195-4ad5ac37d3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f818f-79b5-4318-9796-69f82e9641a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fa64bb2-0fa9-44e2-863c-2427862b7205",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.output.weight[0,0]=1.0\n",
    "    model.output.weight[1,0]=0.0\n",
    "    model.output.weight[2,0]=-1.0\n",
    "    model.output.bias[0]=0\n",
    "    model.output.bias[1]=0\n",
    "    model.output.bias[2]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd47a926-5d9e-4473-b61c-e55eabc03b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.],\n",
       "        [ 0.],\n",
       "        [-1.]], requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cd92fc2-de44-41b7-b40a-397e0000ddbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05175a54-5f7e-4a5e-838f-5114b4b777d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f6d49d-5827-46a9-ad30-84eb68e736b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d75f04-b635-4792-bb81-2963307e5932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
