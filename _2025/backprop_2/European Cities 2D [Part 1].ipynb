{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43d6531-a496-442a-ba46-dd3dd28c3e15",
   "metadata": {},
   "source": [
    "## European Cities 2D [Part 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eeea083a-de2d-4f90-b2b9-7f5cb342315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "paris_coords = np.array([\n",
    "    [48.8575, 2.3514], #Center of Paris\n",
    "    [48.8584, 2.2945], # Eiffel Tower\n",
    "    [48.8530, 2.3499], #Notre Dame\n",
    "    [48.8606,  2.3376], #Louvre\n",
    "    [48.8606, 2.3522]  #Centre Pompidou\n",
    "])\n",
    "\n",
    "madrid_coords = np.array([\n",
    "    [40.4167, -3.7033],   # Center of Madrid\n",
    "    [40.4153, -3.6835],   # Retiro Park \n",
    "    [40.4180, -3.7143],   # Royal Palace \n",
    "    [40.4138, -3.6921],   # Prado Museum \n",
    "    [40.4169, -3.7033]   # Puerta del Sol \n",
    "])\n",
    "\n",
    "berlin_coords = np.array([\n",
    "    [52.5200, 13.4050], # Center of Berlin\n",
    "    [52.5163, 13.3777],   # Brandenburg Gate \n",
    "    [52.5169, 13.4019],   # Museum Island \n",
    "    [52.5074, 13.3904],   # Checkpoint Charlie \n",
    "    [52.5251, 13.3694]   # Berlin Central Station \n",
    "])\n",
    "\n",
    "barcelona_coords = np.array([\n",
    "    [41.3874, 2.1686],    # Center of Barcelona\n",
    "    [41.4036, 2.1744],    # Sagrada Familia\n",
    "    [41.3819, 2.1773],    # Gothic Quarter \n",
    "    [41.4145, 2.1527],    # Park GÃ¼ell \n",
    "    [41.3809, 2.1228],    # Camp Nou\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "850d0126-86dc-4878-acdb-1dbfe0c9a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_to_subtract=np.array([48.8575, 2.3514]) #Center of Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a4604e2-29de-4eab-901c-92dcbb4ed5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [28, 2.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b93c71c-8cf0-4309-bbea-c49f1b5e3f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a84c8-04e9-4460-9f55-024cc7332c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c5131c-0d21-4455-bb54-fa700149fbab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826736b3-d22a-4f87-be3f-d462cbd78450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78ec18db-8745-4efb-882b-bb94cd62c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random_seed=25\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f7781c4-68c6-4e52-826a-52063002f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (20, 2)\n",
      "Shape of y: (20,)\n"
     ]
    }
   ],
   "source": [
    "# Combine data into one matrix X and labels y \n",
    "X_raw = np.vstack([madrid_coords, paris_coords, berlin_coords, barcelona_coords]) #, brussels_coords, vienna_coords])\n",
    "y = np.array([0, 0, 0, 0, 0,  #  Madrid labels (0)\n",
    "              1, 1, 1, 1, 1,  #  Paris labels (1)\n",
    "              2, 2, 2, 2, 2, # Berlin labels (2)\n",
    "              3, 3, 3, 3, 3]) # Barcelona Labels \n",
    "              #3, 3, 3, 3, 3, 3, 3, \n",
    "              #4, 4, 4, 4, 4, 4, 4]) \n",
    "\n",
    "# Let's use only longitude as input for the simple model\n",
    "# X_lon = X_raw[:, 1].reshape(-1, 1)  # Extract longitude and reshape to column vector\n",
    "\n",
    "# Normalize data (simple scaling by dividing by 100, I guess I could do 10)\n",
    "X = X_raw # / 100 - Simple longitude only problem does not seem to require normalization, that's interesting!\n",
    "X = X_raw - mean_to_subtract #np.array([28, 2.2]) #Ok looks like I might need to normalize liek this for this one to converge\n",
    "\n",
    "# Alternative normalization (uncomment to use)\n",
    "# mean = np.mean(X_lon)\n",
    "# std = np.std(X_lon)\n",
    "# X = (X_lon - mean) / std\n",
    "\n",
    "rI=np.arange(len(y))\n",
    "np.random.shuffle(rI)\n",
    "X=X[rI,:]\n",
    "y=y[rI]\n",
    "X_raw=X_raw[rI,:]\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea5ad50e-9120-44fd-a4a7-3b5a9cd29f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.6676, 11.0536])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e828128b-bf2a-4db3-9cff-8dd5860b57eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.4437, -6.0657])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.min(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef95d7-b8ba-4809-85ba-b5f78ad1453d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3672b074-db95-4832-9bea-b0dad3022d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9500084-90c3-4cae-ba81-c30bc48978cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5835fe7f-16dc-4d58-8c41-1bc877c83277",
   "metadata": {},
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8d81d0a-a31e-409d-9f9f-3085a0e75aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyGPSModel(nn.Module):\n",
    "    def __init__(self, input_size=2, output_size=4):\n",
    "        super(TinyGPSModel, self).__init__()\n",
    "        self.output = nn.Linear(input_size, output_size) #, bias=False)  # 3 cities\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e9da523-dd7a-4316-8424-fe5ef72f05b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = TinyGPSModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "#I can manually initialize and still learns real good? yeah seems like it!\n",
    "# with torch.no_grad():\n",
    "#     model.output.weight[0,0]=1.0\n",
    "#     model.output.weight[1,0]=0.0\n",
    "#     model.output.weight[2,0]=-1.0\n",
    "#     model.output.bias[0]=0\n",
    "#     model.output.bias[1]=0\n",
    "#     model.output.bias[2]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a378c903-2e8b-4c6e-a214-97ef0df1d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Where to save training heatmaps\n",
    "save_dir='/Users/stephen/Stephencwelch Dropbox/Stephen Welch/welch_labs/backprop2/graphics/to_manim/may_28_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41c26f7f-3bf6-4546-b3cd-69cdd703f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Swaggin - need to sync with Sam on exact numbers\n",
    "min_long=-6.0\n",
    "max_long=17.0\n",
    "min_lat=36.0\n",
    "max_lat=56.0\n",
    "num_steps=256\n",
    "heatmap_viz_logit_multiplier=8 #Makes things more winner take all for cleaner logit viz\n",
    "heatmaps=[np.zeros((num_steps, num_steps)) for i in range(8)]\n",
    "\n",
    "for i, lat in enumerate(np.linspace(max_lat, min_lat, num_steps)):\n",
    "    for j, long in enumerate(np.linspace(min_long, max_long, num_steps)):\n",
    "        with torch.no_grad():\n",
    "            logits=model(torch.tensor([lat, long], dtype=torch.float)).detach()\n",
    "            yhat=torch.nn.Softmax(0)(heatmap_viz_logit_multiplier*logits).numpy()\n",
    "\n",
    "        for k in range(4):\n",
    "            heatmaps[k][i,j]=logits.numpy()[k]\n",
    "            heatmaps[k+3][i,j]=yhat[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfc7321b-2511-4d24-b741-2f7e5b974286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-12.857500000000002, 7.142499999999998)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_lat-mean_to_subtract[0], max_lat-mean_to_subtract[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb971ad7-19a2-47a5-a3fe-d8d5bb060859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-8.3514, 14.6486)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_long-mean_to_subtract[1], max_long-mean_to_subtract[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a373d08-c4a7-4e6e-b140-e99c54e96a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-13, 6, -8, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014cad94-f213-4910-973e-69f248173cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f550ac2-c803-4d18-bee7-09e63723a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "def create_transparent_colormap(color='cyan', name='transparent_to_color'):\n",
    "    # Convert color name to RGBA\n",
    "    base_color = mcolors.to_rgba(color)\n",
    "    \n",
    "    # Create colormap: transparent (alpha=0) to full color (alpha=1)\n",
    "    colors = [(base_color[0], base_color[1], base_color[2], 0),  # transparent\n",
    "              (base_color[0], base_color[1], base_color[2], 1)]  # full color\n",
    "    \n",
    "    n_bins = 256\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(name, colors, N=n_bins)\n",
    "    return cmap\n",
    "\n",
    "# Create the colormap\n",
    "transparent_cyan_cmap = create_transparent_colormap('cyan')\n",
    "transparent_yellow_cmap = create_transparent_colormap('#ffd35a')\n",
    "transparent_green_cmap = create_transparent_colormap('#00a14b')\n",
    "transparent_magenta_cmap = create_transparent_colormap('magenta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6de9335-9805-4352-8225-60934a4cd9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaps=[transparent_cyan_cmap, transparent_yellow_cmap, transparent_green_cmap, transparent_magenta_cmap, \n",
    "       transparent_cyan_cmap, transparent_yellow_cmap, transparent_green_cmap, transparent_magenta_cmap]\n",
    "save_names=['_logits_1.png', '_logits_2.png', '_logits_3.png', '_logits_4.png', \n",
    "            '_yhat_1.png', '_yhat_2.png', '_yhat_3.png', '_yhat_4.png']\n",
    "\n",
    "# for l in range(6):\n",
    "#     plt.clf()\n",
    "#     plt.figure(frameon=False)\n",
    "#     ax = plt.Axes(plt.gcf(), [0., 0., 1., 1.])\n",
    "#     ax.set_axis_off()\n",
    "#     plt.gcf().add_axes(ax)\n",
    "#     plt.imshow(heatmaps[l],  cmap=cmaps[l]) #np.rot90(heatmaps[0])) #Wait and see if I need to rotate or transpose\n",
    "#     plt.savefig(save_dir+save_names[l], bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5b1db17-b965-4fcb-9b0f-c5aeee9d45b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10/9, Loss: 2.3401, 'Accuracy: 0.5000\n",
      "Step 20/19, Loss: 2.5776, 'Accuracy: 0.5000\n",
      "Step 30/29, Loss: 1.6629, 'Accuracy: 0.7500\n",
      "Step 40/39, Loss: 0.0103, 'Accuracy: 0.7500\n",
      "Step 50/49, Loss: 0.8456, 'Accuracy: 1.0000\n",
      "Step 60/59, Loss: 0.0580, 'Accuracy: 1.0000\n",
      "Step 70/69, Loss: 0.4112, 'Accuracy: 1.0000\n",
      "Step 80/79, Loss: 0.0151, 'Accuracy: 1.0000\n",
      "Step 90/89, Loss: 0.2313, 'Accuracy: 1.0000\n",
      "Step 100/99, Loss: 0.0102, 'Accuracy: 1.0000\n",
      "Step 110/109, Loss: 0.1541, 'Accuracy: 1.0000\n",
      "Step 120/119, Loss: 0.0105, 'Accuracy: 1.0000\n",
      "Step 130/129, Loss: 0.1137, 'Accuracy: 1.0000\n",
      "Step 140/139, Loss: 0.0098, 'Accuracy: 1.0000\n",
      "Step 150/149, Loss: 0.0891, 'Accuracy: 1.0000\n",
      "Step 160/159, Loss: 0.0085, 'Accuracy: 1.0000\n",
      "Step 170/169, Loss: 0.0726, 'Accuracy: 1.0000\n",
      "Step 180/179, Loss: 0.0074, 'Accuracy: 1.0000\n",
      "Step 190/189, Loss: 0.0608, 'Accuracy: 1.0000\n",
      "Step 200/199, Loss: 0.0065, 'Accuracy: 1.0000\n",
      "Step 210/209, Loss: 0.0519, 'Accuracy: 1.0000\n",
      "Step 220/219, Loss: 0.0058, 'Accuracy: 1.0000\n",
      "Step 230/229, Loss: 0.0450, 'Accuracy: 1.0000\n",
      "Step 240/239, Loss: 0.0052, 'Accuracy: 1.0000\n",
      "Step 250/249, Loss: 0.0395, 'Accuracy: 1.0000\n",
      "Step 260/259, Loss: 0.0047, 'Accuracy: 1.0000\n",
      "Step 270/269, Loss: 0.0351, 'Accuracy: 1.0000\n",
      "Step 280/279, Loss: 0.0042, 'Accuracy: 1.0000\n",
      "Step 290/289, Loss: 0.0314, 'Accuracy: 1.0000\n",
      "Step 300/299, Loss: 0.0038, 'Accuracy: 1.0000\n",
      "Step 310/309, Loss: 0.0283, 'Accuracy: 1.0000\n",
      "Step 320/319, Loss: 0.0035, 'Accuracy: 1.0000\n",
      "Step 330/329, Loss: 0.0257, 'Accuracy: 1.0000\n",
      "Step 340/339, Loss: 0.0032, 'Accuracy: 1.0000\n",
      "Step 350/349, Loss: 0.0234, 'Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = TinyGPSModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "#I can manually initialize and still learns real good? yeah seems like it!\n",
    "# with torch.no_grad():\n",
    "#     model.output.weight[0,0]=1.0\n",
    "#     model.output.weight[1,0]=0.0\n",
    "#     model.output.weight[2,0]=-1.0\n",
    "#     model.output.bias[0]=0\n",
    "#     model.output.bias[1]=0\n",
    "#     model.output.bias[2]=0\n",
    "\n",
    "weights=[]\n",
    "grads=[]\n",
    "xs=[]\n",
    "ys=[]\n",
    "logitss=[]\n",
    "yhats=[]\n",
    "\n",
    "# Training loop\n",
    "for i in range(350):\n",
    "    xs.append(X_raw[i%len(y)])\n",
    "    ys.append(y[i%len(y)])\n",
    "    weights.append(np.concatenate([model.output.weight.detach().numpy().ravel(), model.output.bias.detach().numpy().ravel()]))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Stochastic - i think this is a better starting point pedagogically. \n",
    "    outputs = model(torch.tensor(X[i%len(y)]).float())\n",
    "    loss = criterion(outputs, torch.tensor(y[i%len(y)])) \n",
    "\n",
    "    logitss.append(outputs.detach().numpy())\n",
    "    yhats.append(torch.nn.Softmax(0)(outputs.detach()).numpy())\n",
    "    \n",
    "    loss.backward()  # backpropagation\n",
    "    grads.append(np.concatenate([model.output.weight.grad.detach().numpy().ravel(), model.output.bias.grad.detach().numpy().ravel()]))\n",
    "    optimizer.step() #\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            logits=model(torch.tensor(X, dtype=torch.float)) \n",
    "            accuracy=(torch.argmax(logits, dim=1)==torch.tensor(y)).sum().item()/len(y)\n",
    "        print(f\"Step {i+1}/{i}, Loss: {loss.item():.4f}, 'Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "weights=np.array(weights)\n",
    "grads=np.array(grads)\n",
    "xs=np.array(xs)\n",
    "ys=np.array(ys)\n",
    "logitss=np.array(logitss)\n",
    "yhats=np.array(yhats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6070f7c-f5fb-493e-996f-d1abfbe79f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83829580-04d3-4908-bdfb-2feb5b584a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10/9, Loss: 1.3858, 'Accuracy: 0.7500\n",
      "Step 20/19, Loss: 0.1424, 'Accuracy: 0.7500\n",
      "Step 30/29, Loss: 1.0455, 'Accuracy: 0.7500\n",
      "Step 40/39, Loss: 0.0178, 'Accuracy: 1.0000\n",
      "Step 50/49, Loss: 0.7605, 'Accuracy: 1.0000\n",
      "Step 60/59, Loss: 0.0174, 'Accuracy: 1.0000\n",
      "Step 70/69, Loss: 0.5511, 'Accuracy: 1.0000\n",
      "Step 80/79, Loss: 0.0148, 'Accuracy: 1.0000\n",
      "Step 90/89, Loss: 0.4075, 'Accuracy: 1.0000\n",
      "Step 100/99, Loss: 0.0105, 'Accuracy: 1.0000\n",
      "Step 110/109, Loss: 0.3102, 'Accuracy: 1.0000\n",
      "Step 120/119, Loss: 0.0084, 'Accuracy: 1.0000\n",
      "Step 130/129, Loss: 0.2433, 'Accuracy: 1.0000\n",
      "Step 140/139, Loss: 0.0071, 'Accuracy: 1.0000\n",
      "Step 150/149, Loss: 0.1960, 'Accuracy: 1.0000\n",
      "Step 160/159, Loss: 0.0061, 'Accuracy: 1.0000\n",
      "Step 170/169, Loss: 0.1616, 'Accuracy: 1.0000\n",
      "Step 180/179, Loss: 0.0052, 'Accuracy: 1.0000\n",
      "Step 190/189, Loss: 0.1359, 'Accuracy: 1.0000\n",
      "Step 200/199, Loss: 0.0046, 'Accuracy: 1.0000\n",
      "Step 210/209, Loss: 0.1162, 'Accuracy: 1.0000\n",
      "Step 220/219, Loss: 0.0041, 'Accuracy: 1.0000\n",
      "Step 230/229, Loss: 0.1007, 'Accuracy: 1.0000\n",
      "Step 240/239, Loss: 0.0036, 'Accuracy: 1.0000\n",
      "Step 250/249, Loss: 0.0882, 'Accuracy: 1.0000\n",
      "Step 260/259, Loss: 0.0033, 'Accuracy: 1.0000\n",
      "Step 270/269, Loss: 0.0781, 'Accuracy: 1.0000\n",
      "Step 280/279, Loss: 0.0030, 'Accuracy: 1.0000\n",
      "Step 290/289, Loss: 0.0697, 'Accuracy: 1.0000\n",
      "Step 300/299, Loss: 0.0027, 'Accuracy: 1.0000\n",
      "Step 310/309, Loss: 0.0627, 'Accuracy: 1.0000\n",
      "Step 320/319, Loss: 0.0025, 'Accuracy: 1.0000\n",
      "Step 330/329, Loss: 0.0568, 'Accuracy: 1.0000\n",
      "Step 340/339, Loss: 0.0023, 'Accuracy: 1.0000\n",
      "Step 350/349, Loss: 0.0517, 'Accuracy: 1.0000\n",
      "Step 360/359, Loss: 0.0021, 'Accuracy: 1.0000\n",
      "Step 370/369, Loss: 0.0473, 'Accuracy: 1.0000\n",
      "Step 380/379, Loss: 0.0020, 'Accuracy: 1.0000\n",
      "Step 390/389, Loss: 0.0435, 'Accuracy: 1.0000\n",
      "Step 400/399, Loss: 0.0018, 'Accuracy: 1.0000\n",
      "Step 410/409, Loss: 0.0402, 'Accuracy: 1.0000\n",
      "Step 420/419, Loss: 0.0017, 'Accuracy: 1.0000\n",
      "Step 430/429, Loss: 0.0372, 'Accuracy: 1.0000\n",
      "Step 440/439, Loss: 0.0016, 'Accuracy: 1.0000\n",
      "Step 450/449, Loss: 0.0346, 'Accuracy: 1.0000\n",
      "Step 460/459, Loss: 0.0015, 'Accuracy: 1.0000\n",
      "Step 470/469, Loss: 0.0323, 'Accuracy: 1.0000\n",
      "Step 480/479, Loss: 0.0014, 'Accuracy: 1.0000\n",
      "Step 490/489, Loss: 0.0302, 'Accuracy: 1.0000\n",
      "Step 500/499, Loss: 0.0013, 'Accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = TinyGPSModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.03)\n",
    "\n",
    "#I can manually initialize and still learns real good? yeah seems like it!\n",
    "# with torch.no_grad():\n",
    "#     model.output.weight[0,0]=1.0\n",
    "#     model.output.weight[1,0]=0.0\n",
    "#     model.output.weight[2,0]=-1.0\n",
    "#     model.output.bias[0]=0\n",
    "#     model.output.bias[1]=0\n",
    "#     model.output.bias[2]=0\n",
    "\n",
    "weights=[]\n",
    "grads=[]\n",
    "xs=[]\n",
    "ys=[]\n",
    "logitss=[]\n",
    "yhats=[]\n",
    "\n",
    "# Training loop\n",
    "for i in range(500):\n",
    "    xs.append(X_raw[i%len(y)])\n",
    "    ys.append(y[i%len(y)])\n",
    "    weights.append(np.concatenate([model.output.weight.detach().numpy().ravel(), model.output.bias.detach().numpy().ravel()]))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Stochastic - i think this is a better starting point pedagogically. \n",
    "    outputs = model(torch.tensor(X[i%len(y)]).float())\n",
    "    loss = criterion(outputs, torch.tensor(y[i%len(y)])) \n",
    "\n",
    "    logitss.append(outputs.detach().numpy())\n",
    "    yhats.append(torch.nn.Softmax(0)(outputs.detach()).numpy())\n",
    "\n",
    "    #Heatmaps\n",
    "    heatmaps=[np.zeros((num_steps, num_steps)) for i in range(8)]\n",
    "    for j, lat in enumerate(np.linspace(max_lat, min_lat, num_steps)):\n",
    "        for k, long in enumerate(np.linspace(min_long, max_long, num_steps)):\n",
    "            with torch.no_grad():\n",
    "                coords_norm=np.array([lat, long])-mean_to_subtract\n",
    "                logits=model(torch.tensor(coords_norm.ravel(), dtype=torch.float)).detach()\n",
    "                yhat=torch.nn.Softmax(0)(heatmap_viz_logit_multiplier*logits).numpy()\n",
    "    \n",
    "            for l in range(4):\n",
    "                heatmaps[l][j, k]=logits.numpy()[l]\n",
    "                heatmaps[l+4][j,k]=yhat[l]\n",
    "\n",
    "    for l in range(8):\n",
    "        plt.clf()\n",
    "        plt.figure(frameon=False)\n",
    "        ax = plt.Axes(plt.gcf(), [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        plt.gcf().add_axes(ax)\n",
    "        plt.imshow(heatmaps[l],  cmap=cmaps[l]) #np.rot90(heatmaps[0])) #Wait and see if I need to rotate or transpose\n",
    "        plt.savefig(save_dir+'/'+str(i)+save_names[l], bbox_inches='tight', pad_inches=0, dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    loss.backward()  # backpropagation\n",
    "    grads.append(np.concatenate([model.output.weight.grad.detach().numpy().ravel(), model.output.bias.grad.detach().numpy().ravel()]))\n",
    "    optimizer.step() #\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            logits=model(torch.tensor(X, dtype=torch.float)) \n",
    "            accuracy=(torch.argmax(logits, dim=1)==torch.tensor(y)).sum().item()/len(y)\n",
    "        print(f\"Step {i+1}/{i}, Loss: {loss.item():.4f}, 'Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "weights=np.array(weights)\n",
    "grads=np.array(grads)\n",
    "xs=np.array(xs)\n",
    "ys=np.array(ys)\n",
    "logitss=np.array(logitss)\n",
    "yhats=np.array(yhats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7229ec72-fe15-41bb-ac8a-d2eb15bdeb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-24.69661   ,  -6.039481  ,   6.041276  ,  -1.5216051 ],\n",
       "       [-24.670286  ,  -6.011381  ,   6.038615  ,  -1.532564  ],\n",
       "       [  9.720504  ,  -0.9818263 ,  -8.172711  ,   3.0570273 ],\n",
       "       [-24.725891  ,  -6.0406933 ,   6.054416  ,  -1.5273451 ],\n",
       "       [ -2.1891336 ,   2.9525757 ,  -1.3279425 ,  -1.9197239 ],\n",
       "       [ -2.2206638 ,  -7.006975  ,  -4.6881056 ,   4.0168843 ],\n",
       "       [ -2.2654593 ,  -7.0491247 ,  -4.6816573 ,   4.0321503 ],\n",
       "       [  9.697978  ,  -0.9974375 ,  -8.167577  ,   3.0613718 ],\n",
       "       [  9.674975  ,  -1.01548   ,  -8.163045  ,   3.0670614 ],\n",
       "       [ -2.3025289 ,   2.8755128 ,  -1.3015772 ,  -1.8987647 ],\n",
       "       [  9.6574745 ,  -1.0242581 ,  -8.15792   ,   3.0684366 ],\n",
       "       [ -2.3053987 ,   2.879754  ,  -1.298812  ,  -1.9019293 ],\n",
       "       [-24.652952  ,  -5.9889517 ,   6.0381927 ,  -1.542123  ],\n",
       "       [ -2.306899  ,   2.8829694 ,  -1.2970282 ,  -1.9041792 ],\n",
       "       [ -2.1610386 ,  -7.015114  ,  -4.718457  ,   4.034902  ],\n",
       "       [ -2.2723193 ,  -7.082327  ,  -4.689733  ,   4.0504503 ],\n",
       "       [ -2.2770765 ,   2.9013402 ,  -1.3046048 ,  -1.9085597 ],\n",
       "       [-24.71969   ,  -6.0410137 ,   6.0514383 ,  -1.5257856 ],\n",
       "       [ -2.254311  ,  -7.0638895 ,  -4.691819  ,   4.043422  ],\n",
       "       [  9.697987  ,  -0.99716663,  -8.167489  ,   3.0612116 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48db04ac-6002-4516-a7cf-ef3207f28aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_data=np.hstack((xs, ys.reshape(-1, 1), weights, grads, logitss, yhats))\n",
    "np.save('/Users/stephen/Stephencwelch Dropbox/Stephen Welch/welch_labs/backprop2/hackin/cities_2d_2', all_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e00d3cfe-8bca-4de1-bffa-aa798506737a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 35)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62d9da08-cf0e-422b-bcb3-a55dbf1eac1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3367a0d3-d3cd-45f9-9200-fccba653532a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9df1cae0-37bd-4099-ac92-1900d4748814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c91d6a8-7396-45c5-a92e-0bd2d77d72cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dbf7fce-877f-4679-95e5-757fa95328ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e28aaadd-8c29-4167-b41a-85f231bc6ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edb18ebc-0c55-481d-8200-0d70b577388e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04314625, -2.042639  ,  1.361917  , -1.2582749 ,  0.4415128 ,\n",
       "        0.5189429 , -0.8032285 ,  0.3000297 ], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output.weight.detach().numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3d75f04-b635-4792-bb81-2963307e5932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04314625, -2.042639  ],\n",
       "       [ 1.361917  , -1.2582749 ],\n",
       "       [ 0.4415128 ,  0.5189429 ],\n",
       "       [-0.8032285 ,  0.3000297 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d475a614-5a76-45c0-b841-7633b4a9fff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
