{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b65957bf-387e-4ce6-bc51-7f5ef494021f",
   "metadata": {},
   "source": [
    "## Data Augmentation Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7ca496b-c6cb-46e3-97d4-c64cded58f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "\n",
    "\n",
    "class AlexNetAugmentation:\n",
    "    \"\"\"\n",
    "    Implements AlexNet-style data augmentation:\n",
    "    1. Resize to 256x256\n",
    "    2. Extract 224x224 patches (5 locations: 4 corners + center)\n",
    "    3. Horizontal flips (doubles to 10 versions)\n",
    "    4. PCA color augmentation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pca_eigenvectors=None, pca_eigenvalues=None, pca_std=0.1):\n",
    "        self.resize_size = 256\n",
    "        self.crop_size = 224\n",
    "        self.pca_eigenvectors = pca_eigenvectors\n",
    "        self.pca_eigenvalues = pca_eigenvalues\n",
    "        self.pca_std = pca_std  # Standard deviation for color augmentation\n",
    "        \n",
    "    def compute_pca_from_images(self, image_paths, sample_size=1000):\n",
    "        \"\"\"\n",
    "        Compute PCA on RGB pixel values from a sample of images.\n",
    "        \"\"\"\n",
    "        print(f\"Computing PCA from {min(sample_size, len(image_paths))} images...\")\n",
    "        \n",
    "        pixels = []\n",
    "        sample_paths = np.random.choice(image_paths, \n",
    "                                       min(sample_size, len(image_paths)), \n",
    "                                       replace=False)\n",
    "        \n",
    "        for img_path in sample_paths:\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img_array = np.array(img).reshape(-1, 3) / 255.0\n",
    "                pixels.append(img_array)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Combine all pixels\n",
    "        all_pixels = np.vstack(pixels)\n",
    "        \n",
    "        # Compute covariance matrix\n",
    "        cov_matrix = np.cov(all_pixels.T)\n",
    "        \n",
    "        # Compute eigenvalues and eigenvectors\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "        \n",
    "        # Sort by eigenvalue magnitude\n",
    "        idx = eigenvalues.argsort()[::-1]\n",
    "        eigenvalues = eigenvalues[idx]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        \n",
    "        self.pca_eigenvalues = eigenvalues.real\n",
    "        self.pca_eigenvectors = eigenvectors.real\n",
    "        \n",
    "        print(f\"PCA computed. Eigenvalues: {self.pca_eigenvalues}\")\n",
    "        \n",
    "    def apply_pca_augmentation(self, img_tensor):\n",
    "        \"\"\"\n",
    "        Apply PCA color augmentation to image tensor.\n",
    "        img_tensor: CHW format, range [0, 1]\n",
    "        \"\"\"\n",
    "        if self.pca_eigenvectors is None or self.pca_eigenvalues is None:\n",
    "            return img_tensor\n",
    "        \n",
    "        # Generate random alphas from N(0, pca_std)\n",
    "        alphas = np.random.normal(0, self.pca_std, 3)\n",
    "        \n",
    "        # Compute the color offset\n",
    "        delta = np.dot(self.pca_eigenvectors, \n",
    "                      alphas * self.pca_eigenvalues).astype(np.float32)\n",
    "        \n",
    "        # Debug output\n",
    "        if np.random.random() < 0.01:  # Print occasionally\n",
    "            print(f\"  PCA augmentation - alphas: {alphas}, delta: {delta}\")\n",
    "        \n",
    "        # Add to each pixel (broadcast across spatial dimensions)\n",
    "        img_array = img_tensor.numpy()\n",
    "        for c in range(3):\n",
    "            img_array[c] += delta[c]\n",
    "        \n",
    "        # Clip to valid range\n",
    "        img_array = np.clip(img_array, 0, 1)\n",
    "        \n",
    "        return torch.from_numpy(img_array)\n",
    "    \n",
    "    def get_five_crops_and_flips(self, img_tensor):\n",
    "        \"\"\"\n",
    "        Extract 5 crops (4 corners + center) and their horizontal flips.\n",
    "        img_tensor: already resized to 256x256 and converted to tensor\n",
    "        Returns 10 image tensors.\n",
    "        \"\"\"\n",
    "        crops = []\n",
    "        \n",
    "        # Top-left\n",
    "        crops.append(F.crop(img_tensor, 0, 0, self.crop_size, self.crop_size))\n",
    "        \n",
    "        # Top-right\n",
    "        crops.append(F.crop(img_tensor, 0, self.resize_size - self.crop_size, \n",
    "                           self.crop_size, self.crop_size))\n",
    "        \n",
    "        # Bottom-left\n",
    "        crops.append(F.crop(img_tensor, self.resize_size - self.crop_size, 0, \n",
    "                           self.crop_size, self.crop_size))\n",
    "        \n",
    "        # Bottom-right\n",
    "        crops.append(F.crop(img_tensor, self.resize_size - self.crop_size, \n",
    "                           self.resize_size - self.crop_size, \n",
    "                           self.crop_size, self.crop_size))\n",
    "        \n",
    "        # Center\n",
    "        center_offset = (self.resize_size - self.crop_size) // 2\n",
    "        crops.append(F.crop(img_tensor, center_offset, center_offset, \n",
    "                           self.crop_size, self.crop_size))\n",
    "        \n",
    "        # Add horizontal flips\n",
    "        augmented = []\n",
    "        for crop in crops:\n",
    "            augmented.append(crop)  # Original\n",
    "            augmented.append(F.hflip(crop))  # Flipped\n",
    "        \n",
    "        return augmented\n",
    "    \n",
    "    def augment_image(self, img_path):\n",
    "        \"\"\"\n",
    "        Apply full augmentation pipeline to a single image.\n",
    "        Returns 10 augmented versions, each with independent color augmentation.\n",
    "        \"\"\"\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Resize to 256x256\n",
    "        img = F.resize(img, self.resize_size)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        img_tensor = F.to_tensor(img)\n",
    "        \n",
    "        all_augmented = []\n",
    "        \n",
    "        # Generate 10 augmented versions, each with independent color augmentation\n",
    "        # Get 5 crop positions (will be doubled with flips)\n",
    "        crop_positions = [\n",
    "            (0, 0),  # Top-left\n",
    "            (0, self.resize_size - self.crop_size),  # Top-right\n",
    "            (self.resize_size - self.crop_size, 0),  # Bottom-left\n",
    "            (self.resize_size - self.crop_size, self.resize_size - self.crop_size),  # Bottom-right\n",
    "            ((self.resize_size - self.crop_size) // 2, (self.resize_size - self.crop_size) // 2)  # Center\n",
    "        ]\n",
    "        \n",
    "        for top, left in crop_positions+crop_positions:\n",
    "            for flip in [False, True]:\n",
    "                # Apply independent color augmentation to the full image\n",
    "                color_augmented = self.apply_pca_augmentation(img_tensor.clone())\n",
    "                \n",
    "                # Extract the crop\n",
    "                crop = F.crop(color_augmented, top, left, self.crop_size, self.crop_size)\n",
    "                \n",
    "                # Apply horizontal flip if needed\n",
    "                if flip:\n",
    "                    crop = F.hflip(crop)\n",
    "                \n",
    "                all_augmented.append(crop)\n",
    "        \n",
    "        return all_augmented\n",
    "\n",
    "\n",
    "def process_directory(input_dir, output_dir, compute_pca=True, sample_size=1000, pca_std=0.1):\n",
    "    \"\"\"\n",
    "    Process all images in input directory and save augmented versions.\n",
    "    \"\"\"\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get all image files\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
    "    image_files = [f for f in input_path.rglob('*') \n",
    "                   if f.suffix.lower() in image_extensions]\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images in {input_dir}\")\n",
    "    \n",
    "    # Initialize augmentation\n",
    "    augmentor = AlexNetAugmentation(pca_std=pca_std)\n",
    "    \n",
    "    # Compute PCA if requested\n",
    "    if compute_pca:\n",
    "        augmentor.compute_pca_from_images([str(f) for f in image_files], \n",
    "                                         sample_size=sample_size)\n",
    "    else:\n",
    "        print(\"PCA color augmentation disabled\")\n",
    "    \n",
    "    # Process each image\n",
    "    for idx, img_path in enumerate(image_files):\n",
    "        try:\n",
    "            print(f\"Processing {idx+1}/{len(image_files)}: {img_path.name}\")\n",
    "            \n",
    "            # Get augmented versions (10 per image, each with independent color aug)\n",
    "            augmented_images = augmentor.augment_image(str(img_path))\n",
    "            \n",
    "            # Save each augmented version\n",
    "            stem = img_path.stem\n",
    "            for aug_idx, aug_img in enumerate(augmented_images):\n",
    "                # Convert tensor back to PIL Image\n",
    "                aug_img_pil = F.to_pil_image(aug_img)\n",
    "                \n",
    "                # Save with descriptive filename\n",
    "                output_filename = f\"{stem}_aug{aug_idx:02d}.png\"\n",
    "                output_filepath = output_path / output_filename\n",
    "                aug_img_pil.save(output_filepath)\n",
    "            \n",
    "            print(f\"  Saved {len(augmented_images)} augmented versions\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nDone! Augmented images saved to {output_dir}\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(\n",
    "#         description='AlexNet-style data augmentation pipeline'\n",
    "#     )\n",
    "#     parser.add_argument('input_dir', type=str, \n",
    "#                        help='Directory containing input images')\n",
    "#     parser.add_argument('output_dir', type=str, \n",
    "#                        help='Directory to save augmented images')\n",
    "#     parser.add_argument('--no-pca', action='store_true',\n",
    "#                        help='Disable PCA color augmentation')\n",
    "#     parser.add_argument('--pca-samples', type=int, default=1000,\n",
    "#                        help='Number of images to sample for PCA computation (default: 1000)')\n",
    "#     parser.add_argument('--pca-std', type=float, default=0.1,\n",
    "#                        help='Standard deviation for PCA color augmentation (default: 0.1, increase for stronger color variations)')\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "#     process_directory(args.input_dir, args.output_dir, \n",
    "#                      compute_pca=not args.no_pca,\n",
    "#                      sample_size=args.pca_samples,\n",
    "#                      pca_std=args.pca_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13ab4f53-bea5-4e4e-8243-fbe2649c6ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 images in /Users/stephen/Stephencwelch Dropbox/welch_labs/double_descent/hackin/imagenet_favorites\n",
      "Computing PCA from 12 images...\n",
      "PCA computed. Eigenvalues: [0.19004357 0.0330579  0.00299923]\n",
      "Processing 1/12: n02099601_185.JPEG\n",
      "  Saved 20 augmented versions\n",
      "Processing 2/12: n02123045_474.JPEG\n",
      "  Saved 20 augmented versions\n",
      "Processing 3/12: n02123045_507.JPEG\n",
      "  PCA augmentation - alphas: [ 0.33379083  0.27998214 -0.15854916], delta: [-0.0444839  -0.03545243 -0.02956644]\n",
      "  Saved 20 augmented versions\n",
      "Processing 4/12: n02687172_1299.JPEG\n",
      "  Saved 20 augmented versions\n",
      "Processing 5/12: n01751748_1216.JPEG\n",
      "  PCA augmentation - alphas: [-0.37019333 -0.70501712 -0.30939888], delta: [0.05817369 0.03969678 0.02309894]\n",
      "  Saved 20 augmented versions\n",
      "Processing 6/12: n02123045_1462.JPEG\n",
      "  Saved 20 augmented versions\n",
      "Processing 7/12: n02099601_1299.JPEG\n",
      "  Saved 20 augmented versions\n",
      "Processing 8/12: n02687172_137.JPEG\n",
      "  Saved 20 augmented versions\n",
      "Processing 9/12: n01751748_43.JPEG\n",
      "  Saved 20 augmented versions\n",
      "Processing 10/12: n02099601_89.JPEG\n",
      "  Saved 20 augmented versions\n",
      "Processing 11/12: n01751748_221.JPEG\n",
      "  PCA augmentation - alphas: [2.24896751 0.26925001 1.94565325], delta: [-0.25804153 -0.24956776 -0.23219837]\n",
      "  Saved 20 augmented versions\n",
      "Processing 12/12: n02687172_1204.JPEG\n",
      "  Saved 20 augmented versions\n",
      "\n",
      "Done! Augmented images saved to /Users/stephen/Stephencwelch Dropbox/welch_labs/double_descent/hackin/imagenet_favorites_aug\n"
     ]
    }
   ],
   "source": [
    "input_dir='/Users/stephen/Stephencwelch Dropbox/welch_labs/double_descent/hackin/imagenet_favorites'\n",
    "output_dir='/Users/stephen/Stephencwelch Dropbox/welch_labs/double_descent/hackin/imagenet_favorites_aug'\n",
    "\n",
    "process_directory(input_dir, output_dir, compute_pca=True, pca_std=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467be17-5456-4c14-ac32-1abe0405ac58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60debdf-1f96-47ea-8f39-cc8de2540ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df5456-f8fe-4e55-a390-9771c32ce7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f3237-ea6d-4b57-bb54-3f39ea35ecd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f40b16-41d4-4ab1-abc5-5644702ef9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d4c178-9b23-4b28-86b9-76b081114eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01989315-40ba-4ae4-bcdc-5e6529df86e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ac057-8d01-475a-b9bf-cd2f6d849251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
